# -*- coding: utf-8 -*-
# AI Hub ë©´ì ‘ ë°ì´í„° ìµœì¢… ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (ìµœì í™” ë²„ì „)
# 3ë‹¨ê³„: ì ìˆ˜ CSVë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì í™”ëœ ë¶„ì„ ë° ì—‘ì…€ ìƒì„±

import os
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import sys
import warnings
warnings.filterwarnings('ignore')  # pandas ê²½ê³  ì–µì œ

def find_latest_scores_file():
    """ê°€ì¥ ìµœê·¼ ì ìˆ˜ íŒŒì¼ ì°¾ê¸°"""
    scores_files = list(Path(".").glob("interview_scores_*.csv"))
    if not scores_files:
        return None
    
    # íŒŒì¼ ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹  íŒŒì¼ ì°¾ê¸°
    latest_file = max(scores_files, key=os.path.getctime)
    return str(latest_file)

def create_optimized_analysis_excel(df, output_excel):
    """ìµœì í™”ëœ ë¶„ì„ ê²°ê³¼ ì—‘ì…€ íŒŒì¼ ìƒì„±"""
    print(f"ğŸ’¾ ì—‘ì…€ íŒŒì¼ ìƒì„± ì¤‘: {output_excel}")
    
    score_columns = ['confidence_score', 'fluency_score', 'stability_score', 'clarity_score', 'overall_score']
    
    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì—‘ì…€ ì‘ì„±
    with pd.ExcelWriter(output_excel, engine='openpyxl', options={'remove_timezone': True}) as writer:
        
        # ì‹œíŠ¸ 1: ì „ì²´ ê²°ê³¼ (ìƒ˜í”Œë§ëœ ë°ì´í„°ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
        print("  ğŸ“Š ì „ì²´ ê²°ê³¼ ì‹œíŠ¸ ìƒì„±...")
        if len(df) > 10000:  # 10000ê°œ ì´ìƒì´ë©´ ìƒ˜í”Œë§
            sample_df = df.sample(n=10000, random_state=42).copy()
            sample_df.to_excel(writer, sheet_name='ì „ì²´_ë¶„ì„ê²°ê³¼_ìƒ˜í”Œ', index=False)
            print(f"    âš ï¸ ë°ì´í„°ê°€ ë§ì•„ 10000ê°œ ìƒ˜í”Œë§í•˜ì—¬ ì €ì¥")
        else:
            df.to_excel(writer, sheet_name='ì „ì²´_ë¶„ì„ê²°ê³¼', index=False)
        
        # ì‹œíŠ¸ 2: ìš”ì•½ í†µê³„ (ë²¡í„°í™”ëœ ê³„ì‚°)
        print("  ğŸ“ˆ ìš”ì•½ í†µê³„ ì‹œíŠ¸ ìƒì„±...")
        if all(col in df.columns for col in score_columns):
            summary_stats = df[score_columns].describe().round(2)
            summary_stats.to_excel(writer, sheet_name='ìš”ì•½_í†µê³„')
        
        # ì‹œíŠ¸ 3-5: ê·¸ë£¹ë³„ ë¶„ì„ (íš¨ìœ¨ì ì¸ groupby)
        group_analyses = [
            ('occupation', 'ì§êµ°ë³„_ë¶„ì„'),
            ('gender', 'ì„±ë³„_ë¶„ì„'),
            ('ageRange', 'ì—°ë ¹ëŒ€ë³„_ë¶„ì„')
        ]
        
        for group_col, sheet_name in group_analyses:
            if group_col in df.columns:
                print(f"  ğŸ‘¥ {sheet_name} ì‹œíŠ¸ ìƒì„±...")
                try:
                    # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê·¸ë£¹ë°”ì´ ì—°ì‚°
                    grouped = df.groupby(group_col, observed=True)[score_columns]
                    analysis = grouped.agg(['count', 'mean', 'std']).round(2)
                    
                    # ë¹ˆ ê·¸ë£¹ ì œê±°
                    analysis = analysis[analysis.iloc[:, 0] > 0]  # count > 0ì¸ ê·¸ë£¹ë§Œ
                    
                    analysis.to_excel(writer, sheet_name=sheet_name)
                except Exception as e:
                    print(f"    âš ï¸ {sheet_name} ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì‹œíŠ¸ 6-7: ìƒìœ„/í•˜ìœ„ í¼ì„¼íƒ€ì¼
        print("  ğŸ† ìƒìœ„/í•˜ìœ„ í¼ì„¼íƒ€ì¼ ì‹œíŠ¸ ìƒì„±...")
        try:
            # ë²¡í„°í™”ëœ ì •ë ¬ ë° ì„ íƒ
            sorted_indices = np.argsort(df['overall_score'].values)
            n_total = len(sorted_indices)
            
            # ìƒìœ„ 10%
            top_10_indices = sorted_indices[-int(n_total * 0.1):]
            top_10_df = df.iloc[top_10_indices].copy()
            top_10_df.to_excel(writer, sheet_name='ìƒìœ„_10í¼ì„¼íŠ¸', index=False)
            
            # í•˜ìœ„ 10%
            bottom_10_indices = sorted_indices[:int(n_total * 0.1)]
            bottom_10_df = df.iloc[bottom_10_indices].copy()
            bottom_10_df.to_excel(writer, sheet_name='í•˜ìœ„_10í¼ì„¼íŠ¸', index=False)
            
        except Exception as e:
            print(f"    âš ï¸ ìƒìœ„/í•˜ìœ„ í¼ì„¼íƒ€ì¼ ì‹œíŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ì‹œíŠ¸ 8: ìŒì„± íŠ¹ì„± í†µê³„
        print("  ğŸ™ï¸ ìŒì„± íŠ¹ì„± í†µê³„ ì‹œíŠ¸ ìƒì„±...")
        prosodic_features = ['f0_mean', 'f0_std', 'jitter', 'shimmer', 'voiced_ratio', 
                           'intensity_mean', 'spectral_centroid_mean', 'duration', 'wpm']
        
        available_features = [col for col in prosodic_features if col in df.columns]
        if available_features:
            try:
                feature_stats = df[available_features].describe().round(4)
                feature_stats.to_excel(writer, sheet_name='ìŒì„±íŠ¹ì„±_í†µê³„')
                
                # ìƒê´€ê´€ê³„ ë¶„ì„ (ìƒ˜í”Œë§í•˜ì—¬ ë©”ëª¨ë¦¬ ì ˆì•½)
                if len(df) > 5000:
                    corr_sample = df[available_features].sample(n=5000, random_state=42)
                else:
                    corr_sample = df[available_features]
                
                correlation = corr_sample.corr().round(3)
                correlation.to_excel(writer, sheet_name='íŠ¹ì„±_ìƒê´€ê´€ê³„')
                
            except Exception as e:
                print(f"    âš ï¸ ìŒì„± íŠ¹ì„± í†µê³„ ìƒì„± ì‹¤íŒ¨: {e}")
    
    print(f"âœ… ì—‘ì…€ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_excel}")

def print_optimized_analysis_summary(df):
    """ìµœì í™”ëœ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("="*50)
    
    # ê¸°ë³¸ í†µê³„ (ë²¡í„°í™”ëœ ê³„ì‚°)
    overall_scores = df['overall_score'].values
    n_files = len(df)
    
    print(f"ì´ ë¶„ì„ íŒŒì¼ ìˆ˜: {n_files:,}ê°œ")
    print(f"í‰ê·  ì¢…í•© ì ìˆ˜: {np.mean(overall_scores):.1f}ì ")
    print(f"ìµœê³  ì ìˆ˜: {np.max(overall_scores):.1f}ì ")
    print(f"ìµœì € ì ìˆ˜: {np.min(overall_scores):.1f}ì ")
    print(f"í‘œì¤€í¸ì°¨: {np.std(overall_scores):.1f}")
    print(f"ì¤‘ìœ„ê°’: {np.median(overall_scores):.1f}ì ")
    
    # ì ìˆ˜ ë¶„í¬ (ë²¡í„°í™”ëœ ê³„ì‚°)
    print(f"\nğŸ“ˆ ì ìˆ˜ ë¶„í¬")
    print("-"*30)
    bins = [(90, 100, "ìš°ìˆ˜"), (80, 89, "ì–‘í˜¸"), (70, 79, "ë³´í†µ"), (60, 69, "ê°œì„ í•„ìš”"), (0, 59, "ì§‘ì¤‘ì—°ìŠµ")]
    
    for min_val, max_val, label in bins:
        mask = (overall_scores >= min_val) & (overall_scores <= max_val)
        count = np.sum(mask)
        percentage = (count / n_files) * 100
        print(f"{label} ({min_val}-{max_val}ì ): {count:,}ê°œ ({percentage:.1f}%)")
    
    # ê·¸ë£¹ë³„ ìš”ì•½ (íš¨ìœ¨ì ì¸ groupby)
    group_summaries = [
        ('occupation', 'ğŸ’¼ ì§êµ°ë³„ í‰ê·  ì ìˆ˜'),
        ('gender', 'ğŸ‘¥ ì„±ë³„ í‰ê·  ì ìˆ˜'),
        ('ageRange', 'ğŸ“… ì—°ë ¹ëŒ€ë³„ í‰ê·  ì ìˆ˜')
    ]
    
    for group_col, title in group_summaries:
        if group_col in df.columns and df[group_col].nunique() > 1:
            print(f"\n{title}")
            print("-"*30)
            
            try:
                # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê·¸ë£¹ í†µê³„
                grouped = df.groupby(group_col, observed=True)['overall_score']
                stats = grouped.agg(['mean', 'count']).round(1)
                stats = stats.sort_values('mean', ascending=False)
                
                # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ (ë©”ëª¨ë¦¬ ì ˆì•½)
                for group_name, row in stats.head(10).iterrows():
                    print(f"{group_name}: {row['mean']:.1f}ì  ({int(row['count']):,}ê°œ íŒŒì¼)")
                
                if len(stats) > 10:
                    print(f"... ì™¸ {len(stats) - 10}ê°œ ê·¸ë£¹")
                    
            except Exception as e:
                print(f"  âš ï¸ {group_col} í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    # ì„±ëŠ¥ ì§€í‘œ (ìˆëŠ” ê²½ìš°ë§Œ)
    performance_metrics = [
        ('wpm', 'âš¡ ë§í•˜ê¸° ì†ë„ (WPM)', ''),
        ('duration', 'ğŸµ ìŒì„± ê¸¸ì´', 'ì´ˆ'),
        ('jitter', 'ğŸ™ï¸ Jitter', ''),
        ('shimmer', 'ğŸ™ï¸ Shimmer', ''),
        ('voiced_ratio', 'ğŸ—£ï¸ Voiced Ratio', '')
    ]
    
    for col, title, unit in performance_metrics:
        if col in df.columns:
            values = df[col].values
            valid_values = values[~np.isnan(values)]  # NaN ì œê±°
            
            if len(valid_values) > 0:
                print(f"\n{title}")
                print("-"*30)
                print(f"í‰ê· : {np.mean(valid_values):.3f}{unit}")
                print(f"ìµœê³ : {np.max(valid_values):.3f}{unit}")
                print(f"ìµœì €: {np.min(valid_values):.3f}{unit}")
                
                if col == 'js_success' and col in df.columns:
                    success_rate = np.mean(df[col]) * 100
                    print(f"Jitter/Shimmer ê³„ì‚° ì„±ê³µë¥ : {success_rate:.1f}%")

def load_and_validate_data(scores_file):
    """ìµœì í™”ëœ ë°ì´í„° ë¡œë”© ë° ê²€ì¦"""
    try:
        print(f"ğŸ“ ì ìˆ˜ íŒŒì¼ ë¡œë”©: {scores_file}")
        
        # ì²­í¬ ë‹¨ìœ„ë¡œ ë¡œë”© (ë©”ëª¨ë¦¬ íš¨ìœ¨)
        chunk_size = 10000
        chunks = []
        
        for chunk in pd.read_csv(scores_file, encoding='utf-8-sig', chunksize=chunk_size):
            chunks.append(chunk)
        
        df = pd.concat(chunks, ignore_index=True)
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ íŒŒì¼")
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        # ì¹´í…Œê³ ë¦¬ ë°ì´í„° ë³€í™˜
        categorical_cols = ['occupation', 'gender', 'ageRange', 'experience']
        for col in categorical_cols:
            if col in df.columns:
                df[col] = df[col].astype('category')
        
        # ìˆ˜ì¹˜í˜• ë°ì´í„° ë‹¤ìš´ìºìŠ¤íŒ…
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if df[col].dtype == 'float64':
                df[col] = pd.to_numeric(df[col], downcast='float')
            elif df[col].dtype == 'int64':
                df[col] = pd.to_numeric(df[col], downcast='integer')
        
        print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
        
        return df
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def main():
    """ìµœì í™”ëœ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    now = datetime.now().strftime("%Y%m%d_%H%M%S")
    print("ğŸ¯ AI Hub ë©´ì ‘ ë°ì´í„° ìµœì¢… ë¶„ì„ ì‹œì‘ (ìµœì í™” ë²„ì „)")
    print("="*60)
    
    # 1. ìµœì‹  ì ìˆ˜ íŒŒì¼ ì°¾ê¸°
    scores_file = find_latest_scores_file()
    if not scores_file:
        print("âŒ ì ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € ë‹¤ìŒ ìˆœì„œë¡œ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("1. extract_features_optimized.py")
        print("2. calculate_scores_optimized.py") 
        input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")
        return
    
    print(f"ğŸ“ ì ìˆ˜ íŒŒì¼: {scores_file}")
    
    # 2. ìµœì í™”ëœ ë°ì´í„° ë¡œë“œ
    df = load_and_validate_data(scores_file)
    if df is None:
        input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")
        return
    
    # 3. ê¸°ë³¸ ê²€ì¦
    required_score_cols = ['confidence_score', 'fluency_score', 'stability_score', 'clarity_score', 'overall_score']
    missing_cols = [col for col in required_score_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ í•„ìˆ˜ ì ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")
        return
    
    # 4. ìµœì í™”ëœ ì—‘ì…€ íŒŒì¼ ìƒì„±
    output_excel = f"AI_Hub_ë©´ì ‘ë¶„ì„ê²°ê³¼_{now}.xlsx"
    
    try:
        start_time = time.time()
        create_optimized_analysis_excel(df, output_excel)
        excel_time = time.time() - start_time
        
        # 5. ìµœì í™”ëœ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print_optimized_analysis_summary(df)
        
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! (ì—‘ì…€ ìƒì„±: {excel_time:.1f}ì´ˆ)")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {output_excel}")
        print(f"ğŸ“‹ ì—‘ì…€ íŒŒì¼ì— ìµœëŒ€ 9ê°œ ì‹œíŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(" 1. ì „ì²´_ë¶„ì„ê²°ê³¼ - ëª¨ë“  íŒŒì¼ì˜ ìƒì„¸ ì ìˆ˜ ë° íŠ¹ì„±")
        print(" 2. ìš”ì•½_í†µê³„ - ì ìˆ˜ ê¸°ë³¸ í†µê³„ëŸ‰")
        print(" 3. ì§êµ°ë³„_ë¶„ì„ - ì§ì—…êµ°ë³„ ë¹„êµ")
        print(" 4. ì„±ë³„_ë¶„ì„ - ì„±ë³„ ë¹„êµ") 
        print(" 5. ì—°ë ¹ëŒ€ë³„_ë¶„ì„ - ì—°ë ¹ëŒ€ë³„ ë¹„êµ")
        print(" 6. ìƒìœ„_10í¼ì„¼íŠ¸ - ìš°ìˆ˜ ì‚¬ë¡€")
        print(" 7. í•˜ìœ„_10í¼ì„¼íŠ¸ - ê°œì„  í•„ìš” ì‚¬ë¡€")
        print(" 8. ìŒì„±íŠ¹ì„±_í†µê³„ - prosodic features í†µê³„")
        print(" 9. íŠ¹ì„±_ìƒê´€ê´€ê³„ - íŠ¹ì„± ê°„ ìƒê´€ê´€ê³„")
        
        # 6. ì—‘ì…€ íŒŒì¼ ì—´ê¸° ì œì•ˆ
        print(f"\nğŸ’¡ ì—‘ì…€ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì—´ê¹Œìš”?")
        open_excel = input("ì—‘ì…€ ì—´ê¸° (y/n): ").strip().lower()
        if open_excel in ['y', 'yes', 'ì˜ˆ']:
            try:
                os.startfile(output_excel)
                print("âœ… ì—‘ì…€ íŒŒì¼ì„ ì—´ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ ìë™ìœ¼ë¡œ ì—‘ì…€ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                print(f" ìˆ˜ë™ìœ¼ë¡œ {output_excel} íŒŒì¼ì„ ì—´ì–´ì£¼ì„¸ìš”.")
                
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("\nìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        import traceback
        traceback.print_exc()
    
    finally:
        print(f"\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì£¼ì„¸ìš”...")

if __name__ == "__main__":
    import time  # time ëª¨ë“ˆ import ì¶”ê°€
    main()