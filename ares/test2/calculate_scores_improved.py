# -*- coding: utf-8 -*-

# AI Hub ë©´ì ‘ ë°ì´í„° ì ìˆ˜ ê³„ì‚° ìŠ¤í¬ë¦½íŠ¸ (ê°œì„ ëœ ì •ê·œí™” ë²„ì „)

# 2ë‹¨ê³„: ì¶”ì¶œëœ featuresë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë²¡í„°í™”ëœ ì ìˆ˜ ê³„ì‚° + ì •ê·œí™”

import time
import os
import pandas as pd
import numpy as np
from datetime import datetime

# ì „ì—­ ìƒìˆ˜ë¡œ ì„±ë³„ ê¸°ì¤€ê°’ ì •ì˜ (ë°˜ë³µ í˜¸ì¶œ ìµœì†Œí™”)
GENDER_NORMS = {
    'MALE': {
        'intensity': 58.0,
        'f0_mean': 120.0,
        'spectral_centroid': 1400.0,
        'jitter': 0.008,
        'shimmer': 0.025
    },
    'FEMALE': {
        'intensity': 55.0,
        'f0_mean': 200.0,
        'spectral_centroid': 1800.0,
        'jitter': 0.009,
        'shimmer': 0.028
    },
    'unknown': {
        'intensity': 56.5,
        'f0_mean': 160.0,
        'spectral_centroid': 1600.0,
        'jitter': 0.0085,
        'shimmer': 0.0265
    }
}

def vectorized_sigmoid(values, center=0, steepness=1.0, min_val=0.0, max_val=1.0):
    """ë²¡í„°í™”ëœ ì‹œê·¸ëª¨ì´ë“œ ë³€í™˜ í•¨ìˆ˜"""
    try:
        # ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
        exponent = -steepness * (values - center)
        exponent = np.clip(exponent, -500, 500)  # exp ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
        sigmoid_vals = 1.0 / (1.0 + np.exp(exponent))
        scaled_vals = min_val + (max_val - min_val) * sigmoid_vals
        return scaled_vals.astype(np.float64)
    except:
        return np.full_like(values, (min_val + max_val) / 2, dtype=np.float64)

def vectorized_gaussian(values, optimal, tolerance, min_score=0.0, max_score=1.0):
    """ë²¡í„°í™”ëœ ê°€ìš°ì‹œì•ˆ ì ìˆ˜ ê³„ì‚°"""
    try:
        exponent = -0.5 * ((values - optimal) / tolerance) ** 2
        exponent = np.clip(exponent, -500, 0)  # exp ì˜¤ë²„í”Œë¡œìš° ë°©ì§€
        gaussian_vals = np.exp(exponent)
        scaled_scores = min_score + (max_score - min_score) * gaussian_vals
        return scaled_scores.astype(np.float64)
    except:
        return np.full_like(values, min_score, dtype=np.float64)

def robust_normalize_scores(scores, target_min=0, target_max=100, target_mean=50, target_std=15):
    """
    ê²¬ê³ í•œ ì ìˆ˜ ì •ê·œí™” í•¨ìˆ˜ (scipy ì˜ì¡´ì„± ì—†ìŒ)
    
    Parameters:
    - scores: ì›ë³¸ ì ìˆ˜ ë°°ì—´
    - target_min, target_max: ëª©í‘œ ìµœì†Ÿê°’, ìµœëŒ“ê°’  
    - target_mean, target_std: ëª©í‘œ í‰ê· , í‘œì¤€í¸ì°¨
    
    Returns:
    - normalized_scores: ì •ê·œí™”ëœ ì ìˆ˜ ë°°ì—´
    """
    scores = np.array(scores)
    
    if len(scores) == 0:
        return scores
    
    # 1ë‹¨ê³„: ë°±ë¶„ìœ„ ê¸°ë°˜ ê·¹ê°’ ì œê±° (2%-98% ë²”ìœ„)
    p2 = np.percentile(scores, 2)
    p98 = np.percentile(scores, 98)
    clipped_scores = np.clip(scores, p2, p98)
    
    # 2ë‹¨ê³„: Min-Max ì •ê·œí™”ë¡œ 0-1 ë²”ìœ„ ë³€í™˜
    score_min, score_max = clipped_scores.min(), clipped_scores.max()
    
    if score_max - score_min > 1e-6:  # ê±°ì˜ ë™ì¼í•œ ê°’ë“¤ ì²˜ë¦¬
        normalized_01 = (clipped_scores - score_min) / (score_max - score_min)
    else:
        normalized_01 = np.full_like(clipped_scores, 0.5)
    
    # 3ë‹¨ê³„: ìˆœìœ„ ê¸°ë°˜ ê· ë“± ë¶„í¬ ë³€í™˜ (ë” ê· ë“±í•œ ë¶„í¬ ìƒì„±)
    # ê° ì ìˆ˜ì˜ ìˆœìœ„ë¥¼ êµ¬í•´ì„œ ê· ë“± ë¶„í¬ë¡œ ë³€í™˜
    ranks = np.argsort(np.argsort(normalized_01))
    uniform_scores = (ranks + 0.5) / len(ranks)  # 0-1 ê· ë“± ë¶„í¬
    
    # 4ë‹¨ê³„: ì •ê·œë¶„í¬ ê·¼ì‚¬ (Box-Muller ë³€í™˜ì˜ ê°„ë‹¨í•œ ë²„ì „)
    # ê· ë“±ë¶„í¬ë¥¼ ì •ê·œë¶„í¬ë¡œ ë³€í™˜ (inverse normal CDF ê·¼ì‚¬)
    u = uniform_scores
    u = np.clip(u, 0.0001, 0.9999)  # ê·¹ê°’ ë°©ì§€
    
    # ì •ê·œë¶„í¬ì˜ ì—­í•¨ìˆ˜ ê·¼ì‚¬ (Beasley-Springer-Moro ë°©ë²•ì˜ ë‹¨ìˆœí™”)
    c0 = 2.515517
    c1 = 0.802853
    c2 = 0.010328
    d1 = 1.432788
    d2 = 0.189269
    d3 = 0.001308
    
    # u > 0.5ì¸ ê²½ìš°ì™€ u <= 0.5ì¸ ê²½ìš° ì²˜ë¦¬
    mask = u > 0.5
    t = np.where(mask, np.sqrt(-2.0 * np.log(1.0 - u)), np.sqrt(-2.0 * np.log(u)))
    
    numerator = c0 + c1 * t + c2 * t * t
    denominator = 1.0 + d1 * t + d2 * t * t + d3 * t * t * t
    z_scores = np.where(mask, 1.0, -1.0) * (t - numerator / denominator)
    
    # 5ë‹¨ê³„: ëª©í‘œ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¡œ ìŠ¤ì¼€ì¼ë§
    final_scores = z_scores * target_std + target_mean
    
    # 6ë‹¨ê³„: ë¶€ë“œëŸ¬ìš´ ë²”ìœ„ ì¡°ì • (tanh ì‚¬ìš©)
    range_center = (target_min + target_max) / 2
    range_half = (target_max - target_min) / 2
    
    # ê·¹ê°’ì„ ë¶€ë“œëŸ½ê²Œ ì¡°ì •
    normalized_input = (final_scores - range_center) / range_half
    # tanhë¡œ -1 ~ +1 ë²”ìœ„ë¡œ ë¶€ë“œëŸ½ê²Œ ì œí•œ
    soft_clipped = np.tanh(normalized_input) * range_half + range_center
    
    return soft_clipped

def calculate_all_scores_vectorized(df):
    """ì „ì²´ DataFrameì— ëŒ€í•œ ë²¡í„°í™”ëœ ì ìˆ˜ ê³„ì‚° (ì •ê·œí™” ì ìš©)"""
    print("ğŸš€ ë²¡í„°í™”ëœ ì ìˆ˜ ê³„ì‚° ì‹œì‘...")
    n_samples = len(df)
    
    # ì„±ë³„ë³„ ê¸°ì¤€ê°’ ë§¤í•‘ (ë²¡í„°í™”)
    gender_intensity_norms = df['gender'].map(
        lambda x: GENDER_NORMS.get(x, GENDER_NORMS['unknown'])['intensity']
    ).values
    
    gender_spectral_norms = df['gender'].map(
        lambda x: GENDER_NORMS.get(x, GENDER_NORMS['unknown'])['spectral_centroid']
    ).values
    
    # ============ ìì‹ ê° ì ìˆ˜ (ë²¡í„°í™”) ============
    print(" ğŸ“Š ìì‹ ê° ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™”...")
    
    # 1. ìŒì„± ê°•ë„ ê¸°ë°˜ (50%)
    intensity_norm = df['intensity_mean'].values / gender_intensity_norms
    intensity_scores = vectorized_sigmoid(intensity_norm, center=1.0, steepness=2.0) * 100
    
    # 2. í”¼ì¹˜ ì•ˆì •ì„± (30%)
    f0_cv = df['f0_std'].values / np.maximum(df['f0_mean'].values, 1.0)
    f0_stability_scores = vectorized_gaussian(f0_cv, optimal=0.15, tolerance=0.08) * 100
    
    # 3. ìŒì„± í’ˆì§ˆ (20%) - Jitter/Shimmer
    jitter_scores = np.maximum(0, 100 - df['jitter'].values * 10000)
    shimmer_scores = np.maximum(0, 100 - df['shimmer'].values * 100)
    quality_scores = (jitter_scores + shimmer_scores) / 2
    
    confidence_scores_raw = (intensity_scores * 0.5 + 
                           f0_stability_scores * 0.3 + 
                           quality_scores * 0.2)
    
    # ì •ê·œí™” ì ìš©
    confidence_scores = robust_normalize_scores(confidence_scores_raw)
    
    # ============ ìœ ì°½ì„± ì ìˆ˜ (ë²¡í„°í™”) ============
    print(" ğŸ—£ï¸ ìœ ì°½ì„± ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™”...")
    
    # 1. ë§í•˜ê¸° ì†ë„ (50%)
    wpm_values = df['wpm'].values
    speed_scores = np.where(
        wpm_values > 0,
        vectorized_gaussian(wpm_values, optimal=160, tolerance=30) * 100,
        70.0
    )
    
    # 2. ìŒì„± ì—°ì†ì„± (30%)
    voiced_scores = vectorized_gaussian(df['voiced_ratio'].values, optimal=0.45, tolerance=0.15) * 100
    
    # 3. ìŠ¤í™íŠ¸ëŸ´ ì•ˆì •ì„± (20%)
    spectral_stability_scores = np.maximum(0, 100 - df['zcr_mean'].values * 300)
    
    fluency_scores_raw = (speed_scores * 0.5 + 
                         voiced_scores * 0.3 + 
                         spectral_stability_scores * 0.2)
    
    # ì •ê·œí™” ì ìš©
    fluency_scores = robust_normalize_scores(fluency_scores_raw)
    
    # ============ ì•ˆì •ì„± ì ìˆ˜ (ë²¡í„°í™”) ============
    print(" ğŸ¯ ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™”...")
    
    # 1. í”¼ì¹˜ ë³€ë™ ì¼ê´€ì„± (60%)
    pitch_stability_scores = vectorized_gaussian(f0_cv, optimal=0.12, tolerance=0.08) * 100
    
    # 2. ê°•ë„ ì¼ê´€ì„± (40%)
    intensity_cv = df['intensity_std'].values / np.maximum(df['intensity_mean'].values, 1.0)
    intensity_stability_scores = vectorized_gaussian(intensity_cv, optimal=0.2, tolerance=0.1) * 100
    
    stability_scores_raw = (pitch_stability_scores * 0.6 + intensity_stability_scores * 0.4)
    
    # ì •ê·œí™” ì ìš©
    stability_scores = robust_normalize_scores(stability_scores_raw)
    
    # ============ ëª…ë£Œì„± ì ìˆ˜ (ë²¡í„°í™”) ============
    print(" ğŸ”Š ëª…ë£Œì„± ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™”...")
    
    # 1. ìŠ¤í™íŠ¸ëŸ´ ëª…ë£Œì„± (50%)
    spectral_scores = vectorized_gaussian(
        df['spectral_centroid_mean'].values,
        optimal=gender_spectral_norms,
        tolerance=600
    ) * 100
    
    # 2. ìŒì„± ëŒ€ì—­í­ (30%)
    bandwidth_scores = vectorized_sigmoid(
        df['spectral_bandwidth_mean'].values,
        center=1200,
        steepness=0.002
    ) * 100
    
    # 3. MFCC ì¼ê´€ì„± (20%)
    mfcc_consistency_scores = np.maximum(0, 100 - df['mfcc_std'].values * 15)
    
    clarity_scores_raw = (spectral_scores * 0.5 + 
                         bandwidth_scores * 0.3 + 
                         mfcc_consistency_scores * 0.2)
    
    # ì •ê·œí™” ì ìš©
    clarity_scores = robust_normalize_scores(clarity_scores_raw)
    
    # ============ ì¢…í•© ì ìˆ˜ (ê°€ì¤‘í‰ê· , ì •ê·œí™” ì ìš©) ============
    print(" ğŸ† ì¢…í•© ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™”...")
    overall_scores_raw = (confidence_scores * 0.3 + 
                         fluency_scores * 0.3 + 
                         stability_scores * 0.2 + 
                         clarity_scores * 0.2)
    
    # ì¢…í•© ì ìˆ˜ë„ ì •ê·œí™” (ë” ë¶€ë“œëŸ¬ìš´ ì„¤ì •)
    overall_scores = robust_normalize_scores(overall_scores_raw, target_mean=50, target_std=12)
    
    print("âœ… ë²¡í„°í™”ëœ ì ìˆ˜ ê³„ì‚° ë° ì •ê·œí™” ì™„ë£Œ")
    
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜
    scores_df = pd.DataFrame({
        'confidence_score': np.round(confidence_scores, 2),
        'fluency_score': np.round(fluency_scores, 2),
        'stability_score': np.round(stability_scores, 2),
        'clarity_score': np.round(clarity_scores, 2),
        'overall_score': np.round(overall_scores, 2)
    })
    
    return scores_df

class OptimizedScoreCalculator:
    """ìµœì í™”ëœ ì ìˆ˜ ê³„ì‚°ê¸° (ì •ê·œí™” ì ìš©)"""
    
    def __init__(self, features_csv_path):
        self.features_csv_path = features_csv_path
        self.df = None
    
    def load_features(self):
        """íŠ¹ì„± CSV ë¡œë“œ ë° ê²€ì¦"""
        try:
            self.df = pd.read_csv(self.features_csv_path, encoding='utf-8-sig')
            print(f"âœ… íŠ¹ì„± ë¡œë“œ ì™„ë£Œ: {len(self.df)}ê°œ íŒŒì¼, {len(self.df.columns)}ê°œ íŠ¹ì„±")
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['f0_mean', 'f0_std', 'intensity_mean', 'intensity_std',
                           'jitter', 'shimmer', 'voiced_ratio', 'spectral_centroid_mean',
                           'spectral_bandwidth_mean', 'zcr_mean', 'mfcc_std', 'wpm', 'gender']
            
            missing_cols = [col for col in required_cols if col not in self.df.columns]
            if missing_cols:
                print(f"âš ï¸ ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_cols}")
                return False
            
            # ë°ì´í„° íƒ€ì… ìµœì í™”
            numeric_cols = ['f0_mean', 'f0_std', 'intensity_mean', 'intensity_std',
                          'jitter', 'shimmer', 'voiced_ratio', 'spectral_centroid_mean',
                          'spectral_bandwidth_mean', 'zcr_mean', 'mfcc_std', 'wpm']
            
            for col in numeric_cols:
                if col in self.df.columns:
                    self.df[col] = pd.to_numeric(self.df[col], errors='coerce')
            
            # NaN ê°’ ì²˜ë¦¬
            self.df = self.df.fillna({
                'f0_mean': 150.0, 'f0_std': 30.0, 'wpm': 0.0,
                'intensity_mean': 55.0, 'intensity_std': 8.0,
                'jitter': 0.01, 'shimmer': 0.03, 'voiced_ratio': 0.5,
                'spectral_centroid_mean': 1500.0, 'spectral_bandwidth_mean': 1200.0,
                'zcr_mean': 0.1, 'mfcc_std': 5.0, 'gender': 'unknown'
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ íŠ¹ì„± ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def calculate_scores(self):
        """ë²¡í„°í™”ëœ ì ìˆ˜ ê³„ì‚°"""
        if self.df is None:
            if not self.load_features():
                return None
        
        start_time = time.time()
        print(f"ğŸš€ {len(self.df)}ê°œ íŒŒì¼ ì ìˆ˜ ê³„ì‚° ì‹œì‘...")
        
        # ë²¡í„°í™”ëœ ì ìˆ˜ ê³„ì‚°
        scores_df = calculate_all_scores_vectorized(self.df)
        
        # ì›ë³¸ ë°ì´í„°ì™€ ì ìˆ˜ í•©ì¹˜ê¸°
        result_df = pd.concat([self.df, scores_df], axis=1)
        
        elapsed = time.time() - start_time
        print(f"âœ… ì ìˆ˜ ê³„ì‚° ì™„ë£Œ: {elapsed:.2f}ì´ˆ ({len(self.df)/elapsed:.1f}íŒŒì¼/ì´ˆ)")
        
        return result_df
    
    def save_results(self, df, output_path):
        """ìµœì í™”ëœ ê²°ê³¼ ì €ì¥"""
        try:
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì €ì¥
            df.to_csv(output_path, index=False, encoding='utf-8-sig', chunksize=1000)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
            
            # ê¸°ë³¸ í†µê³„ (ë²¡í„°í™”ëœ ê³„ì‚°)
            score_columns = ['confidence_score', 'fluency_score', 'stability_score', 'clarity_score', 'overall_score']
            stats = df[score_columns].describe().round(2)
            print(f"\nğŸ“Š ì •ê·œí™”ëœ ì ìˆ˜ í†µê³„:")
            print(stats)
            
            # ëª©í‘œ ë‹¬ì„± í™•ì¸
            print(f"\nğŸ¯ ì •ê·œí™” ëª©í‘œ ë‹¬ì„±ë„:")
            for col in score_columns:
                data = df[col]
                range_usage = (data.max() - data.min()) / 100 * 100
                print(f"  â€¢ {col}:")
                print(f"    - ë²”ìœ„: {data.min():.1f} ~ {data.max():.1f} (í™œìš©ë„: {range_usage:.1f}%)")
                print(f"    - í‰ê· : {data.mean():.1f} (ëª©í‘œ: 50)")
                print(f"    - í‘œì¤€í¸ì°¨: {data.std():.1f} (ëª©í‘œ: 15)")
            
            # ê·¸ë£¹ë³„ í†µê³„ (groupby ìµœì í™”)
            if 'occupation' in df.columns:
                print(f"\nğŸ’¼ ì§êµ°ë³„ í‰ê·  ì ìˆ˜:")
                occ_stats = df.groupby('occupation', observed=True)['overall_score'].agg(['count', 'mean', 'std']).round(2)
                print(occ_stats.head(10))  # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
            
            if 'gender' in df.columns:
                print(f"\nğŸ‘¥ ì„±ë³„ í‰ê·  ì ìˆ˜:")
                gender_stats = df.groupby('gender', observed=True)['overall_score'].agg(['count', 'mean', 'std']).round(2)
                print(gender_stats)
                
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ AI Hub ë©´ì ‘ ë°ì´í„° ì ìˆ˜ ê³„ì‚° ì‹œì‘ (ì •ê·œí™” ê°œì„  ë²„ì „)")
    print("="*60)
    print("ğŸ“ˆ ì •ê·œí™” ëª©í‘œ:")
    print("  â€¢ ê° ì ìˆ˜ ë²”ìœ„: 0-100ì ")
    print("  â€¢ í‰ê· : 50ì , í‘œì¤€í¸ì°¨: 15ì ")
    print("  â€¢ ì •ê·œë¶„í¬ì— ê°€ê¹Œìš´ ê· ë“±í•œ ë¶„í¬")
    print("="*60)
    
    # ì…ë ¥/ì¶œë ¥ íŒŒì¼ ì„¤ì •
    features_csv = "extracted_features.csv"
    now = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_csv = f"interview_scores_{now}_normalized.csv"
    
    if not os.path.exists(features_csv):
        print(f"âŒ íŠ¹ì„± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {features_csv}")
        print("ë¨¼ì € extract_features_optimized.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")
        return
    
    # ì ìˆ˜ ê³„ì‚°
    calculator = OptimizedScoreCalculator(features_csv)
    results_df = calculator.calculate_scores()
    
    if results_df is not None:
        calculator.save_results(results_df, output_csv)
        print(f"\nğŸ‰ ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚° ì™„ë£Œ!")
        print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_csv}")
        print(f"ğŸ“Š ì´ {len(results_df)}ê°œ íŒŒì¼ ë¶„ì„")
        
        # ìš”ì•½ (ë²¡í„°í™”ëœ í†µê³„)
        overall_scores = results_df['overall_score'].values
        print(f"\nğŸ“ˆ ìµœì¢… ìš”ì•½:")
        print(f"â€¢ í‰ê·  ì¢…í•© ì ìˆ˜: {np.mean(overall_scores):.1f}ì ")
        print(f"â€¢ ìµœê³  ì ìˆ˜: {np.max(overall_scores):.1f}ì ")
        print(f"â€¢ ìµœì € ì ìˆ˜: {np.min(overall_scores):.1f}ì ")
        print(f"â€¢ í‘œì¤€í¸ì°¨: {np.std(overall_scores):.1f}ì ")
        print(f"â€¢ 0-100 ë²”ìœ„ í™œìš©ë„: {((overall_scores.max() - overall_scores.min()) / 100 * 100):.1f}%")
        
        # ë¶„í¬ í’ˆì§ˆ í™•ì¸
        p25, p50, p75 = np.percentile(overall_scores, [25, 50, 75])
        print(f"â€¢ 25% êµ¬ê°„: {p25:.1f}ì ")
        print(f"â€¢ 50% êµ¬ê°„(ì¤‘ê°„ê°’): {p50:.1f}ì ") 
        print(f"â€¢ 75% êµ¬ê°„: {p75:.1f}ì ")
        
    else:
        print("âŒ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨")
    
    input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")

if __name__ == "__main__":
    main()