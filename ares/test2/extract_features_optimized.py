# -*- coding: utf-8 -*-
# AI Hub ë©´ì ‘ ë°ì´í„° Feature ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸ (ìµœì í™” ë²„ì „)
# 1ë‹¨ê³„: ëª¨ë“  prosodic featuresë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ CSVë¡œ ì €ì¥

import os
import json
import numpy as np
import pandas as pd
import parselmouth
import librosa
from pathlib import Path
import time

def optimized_jitter_shimmer(y, sr, f0_values):
    """ìµœì í™”ëœ Jitter/Shimmer ê³„ì‚°"""
    try:
        if len(f0_values) < 3:
            return 0.01, 0.03, False
        
        # 1. ë²¡í„°í™”ëœ Jitter ê³„ì‚°
        periods = 1.0 / f0_values
        period_diffs = np.abs(np.diff(periods))
        jitter = np.mean(period_diffs) / np.mean(periods[:-1]) if np.mean(periods[:-1]) > 0 else 0.01
        
        # 2. Librosa RMS í™œìš©í•œ Shimmer ê³„ì‚°
        rms = librosa.feature.rms(y=y, frame_length=int(sr*0.025), hop_length=int(sr*0.01))[0]
        if len(rms) > 1:
            rms_diffs = np.abs(np.diff(rms))
            shimmer = np.mean(rms_diffs) / np.mean(rms[:-1]) if np.mean(rms[:-1]) > 0 else 0.03
        else:
            shimmer = 0.03
        
        # ìœ íš¨ì„± ê²€ì‚¬
        jitter = np.clip(jitter, 0.001, 1.0) if not np.isnan(jitter) else 0.01
        shimmer = np.clip(shimmer, 0.001, 1.0) if not np.isnan(shimmer) else 0.03
            
        return float(jitter), float(shimmer), True
        
    except Exception as e:
        print(f"    J/S ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.01, 0.03, False

def optimized_voiced_ratio(y, sr):
    """ìµœì í™”ëœ ë³µí•© ì¡°ê±´ ê¸°ë°˜ ìœ ì„±ìŒ ë¹„ìœ¨ ê³„ì‚°"""
    try:
        # í•œë²ˆì— ëª¨ë“  íŠ¹ì„± ê³„ì‚° (hop_length í†µì¼)
        hop_length = 512
        features = librosa.feature.spectral_centroid(y=y, sr=sr, hop_length=hop_length)[0]
        energy = librosa.feature.rms(y=y, hop_length=hop_length)[0]
        zcr = librosa.feature.zero_crossing_rate(y, hop_length=hop_length)[0]
        
        # ë²¡í„°í™”ëœ ì„ê³„ê°’ ê³„ì‚° ë° ì¡°ê±´ ì ìš©
        energy_thresh = np.percentile(energy, 20)
        zcr_thresh = np.percentile(zcr, 80)
        centroid_thresh = np.percentile(features, 50)
        
        # ë³µí•© ì¡°ê±´ì„ ë²¡í„° ì—°ì‚°ìœ¼ë¡œ
        voiced_mask = (energy > energy_thresh) & (zcr < zcr_thresh) & (features < centroid_thresh)
        voiced_ratio = np.mean(voiced_mask)
        
        return float(voiced_ratio)
        
    except Exception as e:
        print(f"    Voiced ratio ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.7

def extract_prosodic_features_optimized(audio_path):
    """ìµœì í™”ëœ ë‹¨ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ prosodic features ì¶”ì¶œ"""
    try:
        print(f"ğŸµ íŠ¹ì„± ì¶”ì¶œ: {os.path.basename(audio_path)}")
        
        # 1. Parselmouth - í”¼ì¹˜ì™€ ê°•ë„ë§Œ ì¶”ì¶œ
        sound = parselmouth.Sound(audio_path)
        
        # í”¼ì¹˜ ë¶„ì„
        pitch = sound.to_pitch_ac(time_step=0.01, pitch_floor=75, pitch_ceiling=500)
        f0_values = pitch.selected_array['frequency']
        f0_values = f0_values[f0_values > 0]
        
        # ê°•ë„ ë¶„ì„
        intensity = sound.to_intensity(minimum_pitch=75)
        intensity_values = intensity.values.T.flatten()
        
        # 2. Librosa - í•œë²ˆì— ì˜¤ë””ì˜¤ ë¡œë“œ
        y, sr = librosa.load(audio_path, sr=16000)
        duration = len(y) / sr
        
        # 3. STFT í•œë²ˆ ê³„ì‚° í›„ ì¬ì‚¬ìš©
        S = np.abs(librosa.stft(y, hop_length=512))
        
        # 4. ìŠ¤í™íŠ¸ëŸ´ íŠ¹ì„±ë“¤ì„ STFTì—ì„œ ê³„ì‚°
        frequencies = librosa.fft_frequencies(sr=sr)
        spectral_centroid = np.sum(frequencies[:, np.newaxis] * S, axis=0) / (np.sum(S, axis=0) + 1e-8)
        spectral_bandwidth = np.sqrt(np.sum(((frequencies[:, np.newaxis] - spectral_centroid) ** 2) * S, axis=0) / (np.sum(S, axis=0) + 1e-8))
        
        # 5. ë‚˜ë¨¸ì§€ íŠ¹ì„±ë“¤
        zcr = librosa.feature.zero_crossing_rate(y, hop_length=512)[0]
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=512)
        
        # 6. ìµœì í™”ëœ ìˆ˜ë™ ê³„ì‚°
        jitter, shimmer, js_success = optimized_jitter_shimmer(y, sr, f0_values)
        voiced_ratio = optimized_voiced_ratio(y, sr)
        
        return {
            # íŒŒì¼ ì •ë³´
            'file_name': os.path.basename(audio_path),
            
            # í”¼ì¹˜ ê´€ë ¨ (ë²¡í„°í™” ì—°ì‚°)
            'f0_mean': float(np.mean(f0_values)) if len(f0_values) > 0 else 0.0,
            'f0_std': float(np.std(f0_values)) if len(f0_values) > 0 else 0.0,
            'f0_range': float(np.ptp(f0_values)) if len(f0_values) > 0 else 0.0,  # np.ptp = max-min
            'f0_median': float(np.median(f0_values)) if len(f0_values) > 0 else 0.0,
            'f0_count': len(f0_values),
            
            # ìŒì„± í’ˆì§ˆ
            'jitter': jitter,
            'shimmer': shimmer,
            'js_success': js_success,
            
            # ê°•ë„ (ë²¡í„°í™”)
            'intensity_mean': float(np.mean(intensity_values)),
            'intensity_std': float(np.std(intensity_values)),
            'intensity_range': float(np.ptp(intensity_values)),
            
            # ìŠ¤í™íŠ¸ëŸ´ (STFT ì¬ì‚¬ìš©)
            'spectral_centroid_mean': float(np.mean(spectral_centroid)),
            'spectral_bandwidth_mean': float(np.mean(spectral_bandwidth)),
            'zcr_mean': float(np.mean(zcr)),
            
            # MFCC (ë²¡í„°í™”)
            'mfcc_mean': float(np.mean(mfcc)),
            'mfcc_std': float(np.std(mfcc)),
            
            # ì‹œê°„ì  íŠ¹ì„±
            'duration': duration,
            'voiced_ratio': voiced_ratio
        }
        
    except Exception as e:
        print(f"âŒ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨ {os.path.basename(audio_path)}: {e}")
        return None

def load_metadata_from_json_fast(json_path):
    """ìµœì í™”ëœ JSON ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # ê²½ë¡œ ìµœì í™” - ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ê²½ë¡œë¶€í„° ì‹œë„
        answer = data.get('dataSet', {}).get('answer', {}).get('raw', {})
        answer_text = answer.get('text', "")
        word_count = answer.get('wordCount', 0)
        
        # duration ì¶”ì¶œ ìµœì í™”
        duration_ms = 0
        if 'rawDataInfo' in data and 'answer' in data['rawDataInfo']:
            duration_ms = data['rawDataInfo']['answer'].get('duration', 0)
        else:
            duration_ms = data.get('dataSet', {}).get('rawDataInfo', {}).get('answer', {}).get('duration', 0)
        
        # ë©”íƒ€ë°ì´í„°
        info = data.get('dataSet', {}).get('info', {})
        
        # WPM ê³„ì‚° ìµœì í™”
        duration_minutes = duration_ms / 60000 if duration_ms > 0 else 0
        wpm = word_count / duration_minutes if duration_minutes > 0 else 0
        
        return {
            'transcript': answer_text,
            'word_count': word_count,
            'duration_ms': duration_ms,
            'duration_sec': duration_ms / 1000,
            'wpm': wpm,
            'occupation': info.get('occupation', 'unknown'),
            'gender': info.get('gender', 'unknown'),
            'ageRange': info.get('ageRange', 'unknown'),
            'experience': info.get('experience', 'unknown')
        }
        
    except Exception as e:
        print(f"âŒ JSON ì½ê¸° ì‹¤íŒ¨ {os.path.basename(json_path)}: {e}")
        return {
            'transcript': "", 'word_count': 0, 'duration_ms': 0, 'duration_sec': 0, 'wpm': 0,
            'occupation': 'unknown', 'gender': 'unknown', 'ageRange': 'unknown', 'experience': 'unknown'
        }

class OptimizedFeatureExtractor:
    """ìµœì í™”ëœ AI Hub ë°ì´í„° Feature ì¶”ì¶œê¸°"""
    
    def __init__(self, folder_path):
        self.folder_path = Path(folder_path)
        self.results = []
    
    def find_audio_json_pairs(self):
        """WAV-JSON ìŒ ì°¾ê¸° (ìºì‹± ì ìš©)"""
        wav_files = sorted(self.folder_path.glob("ckmk_a*.wav"))  # ì •ë ¬ë¡œ ì¼ê´€ì„± í™•ë³´
        pairs = []
        
        for wav_path in wav_files:
            stem = wav_path.stem.replace("ckmk_a_", "")
            json_path = self.folder_path / f"ckmk_d_{stem}.json"
            
            if json_path.exists():
                pairs.append((wav_path, json_path))
            # ê²½ê³  ë©”ì‹œì§€ ì¤„ì„ (ë„ˆë¬´ ë§ìœ¼ë©´ ë¡œê·¸ ë¶€ë‹´)
        
        print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ: {len(pairs)}ê°œ íŒŒì¼")
        return pairs
    
    def process_single_file(self, wav_path, json_path):
        """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ìµœì í™”"""
        # 1. ì˜¤ë””ì˜¤ íŠ¹ì„± ì¶”ì¶œ
        audio_features = extract_prosodic_features_optimized(str(wav_path))
        if not audio_features:
            return None
        
        # 2. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        metadata = load_metadata_from_json_fast(json_path)
        
        # 3. ê²°í•© (ë”•ì…”ë„ˆë¦¬ merge ìµœì í™”)
        return {**audio_features, **metadata}
    
    def extract_all_features(self):
        """ë°°ì¹˜ íŠ¹ì„± ì¶”ì¶œ ìµœì í™”"""
        pairs = self.find_audio_json_pairs()
        
        print(f"ğŸš€ {len(pairs)}ê°œ íŒŒì¼ íŠ¹ì„± ì¶”ì¶œ ì‹œì‘...")
        start_time = time.time()
        
        # ì§„í–‰ë¥  í‘œì‹œ ìµœì í™” (10ê°œë§ˆë‹¤ -> 50ê°œë§ˆë‹¤)
        for i, (wav_path, json_path) in enumerate(pairs):
            result = self.process_single_file(wav_path, json_path)
            if result:
                self.results.append(result)
            
            # ì§„í–‰ë¥  í‘œì‹œ ê°„ê²© ëŠ˜ë¦¼
            if (i + 1) % 50 == 0:
                elapsed = time.time() - start_time
                rate = (i + 1) / elapsed
                remaining = (len(pairs) - i - 1) / rate
                print(f"ğŸ“Š ì§„í–‰ë¥ : {i+1}/{len(pairs)} ({(i+1)/len(pairs)*100:.1f}%) - {rate:.1f}íŒŒì¼/ì´ˆ, ì˜ˆìƒì”ì—¬: {remaining/60:.1f}ë¶„")
        
        elapsed = time.time() - start_time
        print(f"âœ… íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {len(self.results)}ê°œ íŒŒì¼ - {elapsed:.1f}ì´ˆ ì†Œìš” ({len(self.results)/elapsed:.1f}íŒŒì¼/ì´ˆ)")
        
        return pd.DataFrame(self.results)
    
    def save_features(self, df, output_path):
        """íŠ¹ì„±ì„ CSVë¡œ ì €ì¥"""
        try:
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ íŠ¹ì„± ì €ì¥ ì™„ë£Œ: {output_path}")
            print(f"ğŸ“Š ì´ {len(df)}ê°œ íŒŒì¼, {len(df.columns)}ê°œ íŠ¹ì„±")
            
            # ê¸°ë³¸ í†µê³„
            print(f"\nğŸ“ˆ ì¶”ì¶œëœ íŠ¹ì„± ìš”ì•½:")
            print(f"â€¢ í‰ê·  ìŒì„± ê¸¸ì´: {df['duration'].mean():.1f}ì´ˆ")
            print(f"â€¢ í‰ê·  WPM: {df['wpm'].mean():.1f}")
            print(f"â€¢ Jitter/Shimmer ì„±ê³µë¥ : {df['js_success'].sum()}/{len(df)} ({df['js_success'].mean()*100:.1f}%)")
            
            # ì„±ëŠ¥ í†µê³„
            avg_jitter = df['jitter'].mean()
            avg_shimmer = df['shimmer'].mean()
            avg_voiced = df['voiced_ratio'].mean()
            print(f"â€¢ í‰ê·  Jitter: {avg_jitter:.4f}, í‰ê·  Shimmer: {avg_shimmer:.4f}")
            print(f"â€¢ í‰ê·  Voiced Ratio: {avg_voiced:.3f}")
            
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ AI Hub ë©´ì ‘ ë°ì´í„° íŠ¹ì„± ì¶”ì¶œ ì‹œì‘ (ìµœì í™” ë²„ì „)")
    print("="*60)
    
    # í´ë” ê²½ë¡œ (ê³ ì •)
    folder_path = r"D:\ë©´ì ‘data\129.ì±„ìš©ë©´ì ‘ ì¸í„°ë·° ë°ì´í„°\01-1.ì •ì‹ê°œë°©ë°ì´í„°\norm"
    output_csv = "extracted_features.csv"
    
    if not os.path.exists(folder_path):
        print(f"âŒ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder_path}")
        input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")
        return
    
    # íŠ¹ì„± ì¶”ì¶œ
    extractor = OptimizedFeatureExtractor(folder_path)
    features_df = extractor.extract_all_features()
    
    if len(features_df) > 0:
        extractor.save_features(features_df, output_csv)
        print(f"\nğŸ‰ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ!")
        print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_csv}")
    else:
        print("âŒ ì¶”ì¶œëœ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    input("ì—”í„° í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œ...")

if __name__ == "__main__":
    main()