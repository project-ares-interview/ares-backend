# ares/api/views/v1/analyze.py
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from django.conf import settings
import pandas as pd
import numpy as np
import os
import random
from pathlib import Path
from django.http import JsonResponse

# New import for the percentile service
from ares.api.services.percentile_service import percentile_service
# New import for the AI advisor service
from ares.api.services.openai_advisor import advisor as ai_advisor


class GenerateAIAdviceView(APIView):
    """
    API view to generate AI-based interview advice.
    """
    authentication_classes = []
    permission_classes = []

    def post(self, request):
        """
        Generates advice based on the provided analysis data.
        """
        analysis_data = request.data
        if not analysis_data:
            return Response(
                {'error': 'Analysis data was not provided.'},
                status=status.HTTP_400_BAD_REQUEST
            )
        
        try:
            # Use the imported advisor instance to generate advice
            advice_result = ai_advisor.generate_advice(analysis_data)
            return Response(advice_result, status=status.HTTP_200_OK)
        except Exception as e:
            return Response(
                {'error': f'An unexpected error occurred while generating advice: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class PercentileAnalysisView(APIView):
    """
    API view to calculate and return score percentiles based on filters.
    """
    authentication_classes = []
    permission_classes = []

    def get(self, request):
        """
        Calculates percentiles for given scores based on query parameters.
        
        Query Params:
        - Scores (required): e.g., confidence_score=85, fluency_score=92
        - Filters (optional): e.g., gender=MALE, ageRange=-34, occupation=ICT
          (Filters can have multiple values, e.g., &occupation=ICT&occupation=RND)
        """
        try:
            # 1. Parse scores from query parameters
            score_columns = ['confidence_score', 'fluency_score', 'stability_score', 'clarity_score', 'overall_score']
            user_scores = {}
            for score in score_columns:
                value = request.query_params.get(score)
                if value is not None:
                    try:
                        user_scores[score] = float(value)
                    except (ValueError, TypeError):
                        return Response(
                            {'error': f'Invalid value for score: {score}. Must be a number.'},
                            status=status.HTTP_400_BAD_REQUEST
                        )
            
            if not user_scores:
                return Response(
                    {'error': 'At least one score parameter is required.'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # 2. Parse filters from query parameters
            filter_keys = ['gender', 'ageRange', 'occupation']
            filters = {}
            for key in filter_keys:
                values = request.query_params.getlist(key)
                if values:
                    filters[key] = values

            # 3. Calculate percentiles using the service
            percentiles = percentile_service.get_percentiles(user_scores, filters)

            return Response(percentiles, status=status.HTTP_200_OK)

        except Exception as e:
            # In a real scenario, you might want to log this error.
            return Response(
                {'error': f'An unexpected error occurred during percentile analysis: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class ScoreAnalyzer:
    def __init__(self):
        self.df = None
        self.score_columns = ['confidence_score', 'fluency_score', 'stability_score', 'clarity_score', 'overall_score']
        self.score_names = {
            'confidence_score': 'ìì‹ ê°',
            'fluency_score': 'ìœ ì°½ì„±',
            'stability_score': 'ì•ˆì •ì„±',
            'clarity_score': 'ëª…ë£Œì„±',
            'overall_score': 'ì¢…í•©'
        }
        self.load_latest_csv()

    def load_latest_csv(self):
        """ê°€ì¥ ìµœì‹ ì˜ interview_scores CSV íŒŒì¼ ë¡œë“œ"""
        try:
            # ares/data/ ë””ë ‰í† ë¦¬ì—ì„œ interview_scoresë¡œ ì‹œì‘í•˜ëŠ” CSV íŒŒì¼ë“¤ ì°¾ê¸°
            data_dir = Path('ares/data')
            csv_paths = [str(p) for p in data_dir.glob('interview_scores_*.csv')]

            if not csv_paths:
                print("âŒ interview_scores CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False

            # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ (íŒŒì¼ëª…ì˜ ë‚ ì§œ/ì‹œê°„ ê¸°ì¤€)
            latest_file = sorted(csv_paths)[-1]
            self.df = pd.read_csv(latest_file, encoding='utf-8-sig')
            print(f"âœ… CSV ë¡œë“œ ì™„ë£Œ: {latest_file} ({len(self.df)}ê°œ ë°ì´í„°)")

            # ì ìˆ˜ ì»¬ëŸ¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            missing_cols = [col for col in self.score_columns if col not in self.df.columns]
            if missing_cols:
                print(f"âš ï¸ ëˆ„ë½ëœ ì ìˆ˜ ì»¬ëŸ¼: {missing_cols}")
                return False

            return True

        except Exception as e:
            print(f"âŒ CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def calculate_percentile(self, score, score_type, filters=None):
        """íŠ¹ì • ì ìˆ˜ì˜ ë°±ë¶„ìœ„ ê³„ì‚°"""
        if self.df is None or score_type not in self.score_columns:
            return None

        # í•„í„°ë§ ì ìš©
        filtered_df = self.df.copy()
        if filters:
            for filter_type, filter_value in filters.items():
                if filter_type in filtered_df.columns:
                    filtered_df = filtered_df[filtered_df[filter_type] == filter_value]

        score_data = filtered_df[score_type].dropna()
        if len(score_data) == 0:
            return None

        percentile = (score_data < score).sum() / len(score_data) * 100
        return round(percentile, 1)

    def get_score_distribution(self, score_type, filters=None):
        """ì ìˆ˜ ë¶„í¬ ë°ì´í„° ë°˜í™˜"""
        if self.df is None or score_type not in self.score_columns:
            return None

        # í•„í„°ë§ ì ìš©
        filtered_df = self.df.copy()
        if filters:
            for filter_type, filter_value in filters.items():
                if filter_type in filtered_df.columns:
                    filtered_df = filtered_df[filtered_df[filter_type] == filter_value]

        score_data = filtered_df[score_type].dropna()
        if len(score_data) == 0:
            return None

        # íˆìŠ¤í† ê·¸ë¨ ë°ì´í„° ìƒì„± (20ê°œ êµ¬ê°„)
        hist, bin_edges = np.histogram(score_data, bins=20, range=(0, 100))

        # êµ¬ê°„ ì¤‘ì•™ê°’ ê³„ì‚°
        bin_centers = [(bin_edges[i] + bin_edges[i+1]) / 2 for i in range(len(bin_edges)-1)]

        return {
            'bins': bin_centers,
            'counts': hist.tolist(),
            'total_count': len(score_data),
            'mean': float(score_data.mean()),
            'std': float(score_data.std()),
            'min': float(score_data.min()),
            'max': float(score_data.max())
        }

# ì „ì—­ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
analyzer = ScoreAnalyzer()

class AnalyzeView(APIView):
    """ë©´ì ‘ ì ìˆ˜ ë¶„ì„ API ë·°"""

    authentication_classes = []
    permission_classes = []

    def get(self, request):
        """ì ìˆ˜ ë¶„ì„ ìˆ˜í–‰"""
        try:
            # ğŸ² ë”ë¯¸ ë°ì´í„° ìƒì„± (í•˜ë“œì½”ë”©)
            dummy_scores = {
                'confidence_score': random.randint(0, 100),
                'fluency_score': random.randint(0, 100),
                'stability_score': random.randint(0, 100),
                'clarity_score': random.randint(0, 100),
                'overall_score': random.randint(0, 100)
            }

            # ğŸ² ë”ë¯¸ ë°ëª¨ê·¸ë˜í”½ ë°ì´í„°
            dummy_demographics = {
                'gender': random.choice(['MALE', 'FEMALE']),
                'ageRange': random.choice(['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€']),
                'occupation': random.choice(['ê°œë°œì', 'ë””ìì´ë„ˆ', 'ë§ˆì¼€í„°', 'ê¸°íšì', 'ì˜ì—…'])
            }

            print(f"ğŸ² ìƒì„±ëœ ë”ë¯¸ ì ìˆ˜: {dummy_scores}")
            print(f"ğŸ² ìƒì„±ëœ ë”ë¯¸ ë°ëª¨ê·¸ë˜í”½: {dummy_demographics}")

            # ë¶„ì„ê¸°ê°€ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ì—ëŸ¬ ë°˜í™˜
            if analyzer.df is None:
                return Response({
                    'error': 'CSV ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. interview_scores_*.csv íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.'
                }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

            results = {}

            for score_type, score in dummy_scores.items():
                # ì „ì²´ ë°ì´í„° ê¸°ì¤€ ë°±ë¶„ìœ„
                overall_percentile = analyzer.calculate_percentile(score, score_type)
                overall_distribution = analyzer.get_score_distribution(score_type)

                result_data = {
                    'score': score,
                    'overall_percentile': overall_percentile,
                    'overall_distribution': overall_distribution,
                    'name': analyzer.score_names[score_type],
                    'demographic_results': {}
                }

                # ë°ëª¨ê·¸ë˜í”½ í•„í„°ë³„ ë°±ë¶„ìœ„ ê³„ì‚°
                filtered_percentile = analyzer.calculate_percentile(score, score_type, dummy_demographics)
                filtered_distribution = analyzer.get_score_distribution(score_type, dummy_demographics)

                if filtered_percentile is not None:
                    result_data['filtered_percentile'] = filtered_percentile
                if filtered_distribution is not None:
                    result_data['filtered_distribution'] = filtered_distribution
                result_data['filters'] = dummy_demographics

                results[score_type] = result_data

            return Response(results, status=status.HTTP_200_OK)

        except Exception as e:
            return Response({
                'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)