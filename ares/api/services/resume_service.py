# ares/api/services/resume_service.py
from __future__ import annotations
from typing import Dict, Any, List, Tuple
from dataclasses import dataclass
import json, argparse, sys

from ares.api.utils.ai_utils import chat
from ares.api.utils.common_utils import get_logger, chunk_text
from ares.api.utils.search_utils import search_ncs_hybrid, format_ncs_context
from ares.api.services.ncs_service import summarize_top_ncs
from ares.api.utils.ai_utils import chat_complete

_log = get_logger("resume")

__all__ = [
    "analyze_resume_or_cover",
    "compare_documents",
    "analyze_research_alignment",
    "analyze_all",
]

@dataclass
class GenConfig:
    # ì²­í¬ë§
    chunk_size: int = 8000
    chunk_overlap: int = 600
    max_chunks_analyze: int = 8  # ê³¼ë„í•œ ë¶„í•  ë°©ì§€

    # í† í° í•œë„
    max_tokens_deep: int = 1100
    max_tokens_cmp: int = 900
    max_tokens_align: int = 900

    # ì˜¨ë„
    t_deep: float = 0.2
    t_cmp: float = 0.2
    t_align: float = 0.3

    # ì•ˆì „ ê°€ë“œ
    max_docs_compare: int = 6
    max_chars_per_doc: int = 8000
    max_jd_chars: int = 8000
    max_resume_chars: int = 9000
    max_research_chars: int = 6000

    # ë¡œê¹…
    debug_log_prompts: bool = False
CFG = GenConfig()

def _safe_chat(msgs: List[Dict[str,str]], temperature: float, max_tokens: int, default: str="") -> str:
    try:
        out = chat_complete(
            messages=msgs,
            temperature=temperature,
            max_tokens=max_tokens,
            max_cont=2,               # í•„ìš”ì‹œ 1~3 ì‚¬ì´ì—ì„œ ì¡°ì •
            require_sentinel=False,   # í•„ìš”í•˜ë©´ Trueë¡œ
        )
        return out or default
    except Exception as e:
        _log.warning(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return default

def _inject_company_ctx(prompt: str, meta: Dict[str, Any] | None) -> str:
    if not meta: return prompt
    def _s(x): return (x or "").strip()
    comp = _s(meta.get("name", ""))
    div = _s(meta.get("department", ""))
    role = _s(meta.get("job_title", ""))
    loc = _s(meta.get("location", ""))
    kpis = ", ".join([_s(x) for x in meta.get("kpi", []) if _s(x)])[:200]
    skills = ", ".join([_s(x) for x in meta.get("requirements", []) if _s(x)])[:200]
    ctx = (f"[íšŒì‚¬ ì»¨í…ìŠ¤íŠ¸]\n" 
           f"- íšŒì‚¬: {comp or 'ë¯¸ìƒ'} | ë¶€ì„œ/ì§ë¬´: {div or '-'} / {role or '-'} | ê·¼ë¬´ì§€: {loc or '-'}\n" 
           f"- KPI: {kpis or '-'} | ìŠ¤í‚¬: {skills or '-'}\n\n")
    return ctx + prompt

# ---------- í”„ë¡¬í”„íŠ¸(ì‹œìŠ¤í…œ) ----------
SYS_DEEP = (
    "ë„ˆëŠ” ëŒ€ê¸°ì—… ì±„ìš©ë‹´ë‹¹ì+ì»¤ë¦¬ì–´ì½”ì¹˜ë‹¤. ë¬¸ì„œë¥¼ JD ê¸°ì¤€ìœ¼ë¡œ í‰ê°€Â·êµì •í•œë‹¤. "
    "ëª©í‘œ: ë§¤ì¹­ë„ í–¥ìƒ, ì •ëŸ‰ ê·¼ê±° ê°•í™”, ATS í†µê³¼ ê°€ëŠ¥ì„± ì œê³ . "
    "ì¶œë ¥ì€ í•œêµ­ì–´, ì„¹ì…˜/ë¶ˆë¦¿ ìœ„ì£¼, ì¦‰ì‹œ ë°˜ì˜ ê°€ëŠ¥í•œ êµ¬ì²´ ì˜ˆì‹œ í¬í•¨. "
    "ê¸ˆì§€ì–´: 'ì—´ì‹¬íˆ','ìµœëŒ€í•œ','ë§ì´'. ê°€ëŠ¥í•˜ë©´ ìˆ˜ì¹˜/ê¸°ê°„/ê·œëª¨/ì˜í–¥ ëª…ì‹œ."
)
SYS_CMP = (
    "ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. ì—¬ëŸ¬ ë¬¸ì„œì˜ ì¼ê´€ì„±Â·ì •í•©ì„±ì„ ì ê²€/ì •ë ¬í•œë‹¤. "
    "ìˆ˜ì¹˜/ê¸°ê°„/ì—­í• /ì„±ê³¼ ëª¨ìˆœ ì œê±°, ìŠ¤í† ë¦¬ë¼ì¸ ì •ëˆ, í†µì¼ëœ í‘œí˜„ ì˜ˆë¬¸ ì œì‹œ. í•œêµ­ì–´ ë¶ˆë¦¿."
)
SYS_ALIGN = (
    "ë„ˆëŠ” ì»¤ë¦¬ì–´ì½”ì¹˜ë‹¤. JD â†” ë¦¬ì„œì¹˜ ì •í•©ì„±ì„ ì ê²€í•´ ì°¨ë³„í™” í¬ì¸íŠ¸/ë¯¸ìŠ¤ë§¤ì¹˜ ë¦¬ìŠ¤í¬/ì§€ì›ì„œ ë¬¸ì¥ ì˜ˆì‹œë¥¼ ì œì‹œí•œë‹¤. í•œêµ­ì–´ ë¶ˆë¦¿."
)

# ---------- ë‚´ë¶€ ìœ í‹¸ ----------
def _dbg(title: str, msgs: List[Dict[str, str]]):
    if not CFG.debug_log_prompts: 
        return
    try:
        _log.debug(f"=== {title} ===\n" + json.dumps(msgs, ensure_ascii=False, indent=2)[:12000])
    except Exception:
        pass

def _label_section(i: int, total: int, content: str) -> str:
    h = f"### [ë¶„í•  {i}/{total}]\n"
    return h + (content.strip() if content else "")

def _build_ncs_report(meta: Dict[str, Any] | None, jd_ctx: str, top: int = 6) -> Tuple[str, Dict]:
    try:
        job_title = ((meta or {}).get("job_title") or "").strip() or "ì„¤ë¹„ ê´€ë¦¬"
        jd_snip = (jd_ctx or "")[:4000]
        query = f"{job_title}\n{jd_snip}"

        agg = summarize_top_ncs(job_title, jd_snip, top=top) or []
        hits = search_ncs_hybrid(query, top=top) or []
        ctx_lines = format_ncs_context(hits, max_len=1000)

        structured_context = {"ncs": hits, "ncs_query": query}

        if not agg and not ctx_lines: 
            return "", structured_context

        lines = [f"## ğŸ§© NCS ìš”ì•½ (Top {top})", f"- ì§ˆì˜: `{job_title}`", ""]
        for i, it in enumerate(agg, 1):
            title = (it.get("ability_name") or it.get("ability_code") or f"Ability-{i}")
            lines.append(f"**{i}. {title}**")
            els = it.get("elements") or []
            if els:
                lines.append("  - ìš”ì†Œ: " + ", ".join(els[:5]))
            samples = it.get("criteria_samples") or []
            for s in samples[:3]:
                lines.append(f"  - ê¸°ì¤€: {s}")

        if ctx_lines:
            lines.append("<details><summary>NCS ì»¨í…ìŠ¤íŠ¸(ì›ë¬¸ ì¼ë¶€)</summary>\n\n")
            lines.append(ctx_lines)
            lines.append("\n</details>\n")

        report_string = "\n".join(lines).strip()
        return report_string, structured_context
    except Exception as e:
        _log.warning(f"NCS ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "NCS ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", {}

# ---------- ê³µê°œ API ----------
def analyze_all(jd_text: str, resume_text: str, research_text: str, company_meta: Dict[str, Any]) -> Dict[str, Any]:
    """
    JD, ì´ë ¥ì„œ, ë¦¬ì„œì¹˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ 4ê°€ì§€ ì¢…í•© ë¶„ì„ì„ ê°œë³„ ìˆ˜í–‰í•˜ì—¬ ìƒì„¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. ì‹¬ì¸µ ë¶„ì„ (ì´ë ¥ì„œ/ìì†Œì„œ ê¸°ì¤€)
    deep_out = analyze_resume_or_cover(resume_text, jd_text=jd_text, meta=company_meta)

    # 2. êµì°¨ ë¶„ì„ (JDì™€ ì´ë ¥ì„œ ë¹„êµ)
    named_texts = {"JD": jd_text, "ì´ë ¥ì„œ": resume_text}
    cmp_out = compare_documents(named_texts, meta=company_meta)

    # 3. ì •í•©ì„± ì ê²€ (ë¦¬ì„œì¹˜ ìë£Œê°€ ìˆì„ ê²½ìš°)
    aln_out = ""
    if (research_text or "").strip():
        aln_out = analyze_research_alignment(jd_text, resume_text, research_text=research_text, meta=company_meta)

    # 4. NCS ìš”ì•½ ë° êµ¬ì¡°í™”ëœ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    ncs_out, ncs_ctx = _build_ncs_report(company_meta, jd_text, top=6)

    return {
        "ì‹¬ì¸µë¶„ì„": deep_out,
        "êµì°¨ë¶„ì„": cmp_out,
        "ì •í•©ì„±ì ê²€": aln_out,
        "NCSìš”ì•½": ncs_out,
        "ncs_context": ncs_ctx,  # êµ¬ì¡°í™”ëœ NCS ë°ì´í„° ì¶”ê°€
    }

def analyze_resume_or_cover(text: str, jd_text: str = "", meta: Dict[str, Any] | None = None) -> str:
    text = (text or "").strip()
    jd_text = (jd_text or "").strip()

    if not text and not jd_text:
        return "ì…ë ¥ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì´ë ¥ì„œ/ìì†Œì„œ ë³¸ë¬¸ ë˜ëŠ” JDë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."

    chunks: List[str] = list(chunk_text(text, CFG.chunk_size, CFG.chunk_overlap)) if text else [""]
    if len(chunks) > CFG.max_chunks_analyze:
        _log.warning(f"ì²­í¬ ìˆ˜ ì´ˆê³¼: {len(chunks)} > {CFG.max_chunks_analyze}, ìƒìœ„ë§Œ ë¶„ì„")
        chunks = chunks[:CFG.max_chunks_analyze]

    results: List[str] = []
    total = len(chunks)
    for i, ch in enumerate(chunks, 1):
        usr = _inject_company_ctx(
            f"[ë¬¸ì„œ (ë¶„í•  {i}/{total})]\n{ch}\n\n"
            f"[ì„ íƒì  JD]\n{jd_text[:CFG.max_jd_chars]}\n\n"
            "ìš”êµ¬ ì¶œë ¥:\n"
            "1) í•µì‹¬ ìš”ì•½(ì§ë¬´ì—°ê´€ì„± ì¤‘ì‹¬)\n"
            "2) JD ë§¤ì¹­ë„(ìƒ/ì¤‘/í•˜ + ê·¼ê±°: í‚¤ì›Œë“œ/ê²½í—˜/ì§€í‘œ)\n"
            "3) í‚¤ì›Œë“œ ì»¤ë²„ë¦¬ì§€ í‘œ(ë¹ ì§„ í‚¤ì›Œë“œ í‘œì‹œ)\n"
            "4) STAR ì‚¬ë¡€(ê° S/T/A/R-C 1~2ë¬¸ì¥ í…œí”Œë¦¿)\n"
            "5) ì •ëŸ‰í™” ê°œì„ ì•ˆ(ì§€í‘œ/ê¸°ê°„/ê·œëª¨/ë„êµ¬: ì˜ˆë¬¸)\n"
            "6) ATS ë¦¬ìŠ¤í¬/ìˆ˜ì •ì•ˆ(í˜•ì‹/í‚¤ì›Œë“œ/ì¤‘ë³µ/ê°€ë…ì„±)\n"
            "7) ì²´í¬ë¦¬ìŠ¤íŠ¸(ì œì¶œ ì§ì „ ì ê²€)\n",
            meta
        )
        msgs = [{"role": "system", "content": SYS_DEEP},
                {"role": "user", "content": usr}]
        _dbg("analyze_resume_or_cover prompt", msgs)

        out = _safe_chat(msgs, temperature=CFG.t_deep, max_tokens=CFG.max_tokens_deep, default="")
        if out:
            results.append(_label_section(i, total, out))

    return "\n\n".join(results) if results else "í‰ê°€ ìƒì„± ì‹¤íŒ¨"

def compare_documents(named_texts: Dict[str, str], meta: Dict[str, Any] | None = None) -> str:
    if not named_texts:
        return "ë¹„êµí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒì˜ ë¬¸ì„œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."

    items = list(named_texts.items())[:CFG.max_docs_compare]
    pairs = [f"[{k}]\n{(v or '')[:CFG.max_chars_per_doc]}" for k, v in items]
    joined = "\n\n".join(pairs)

    usr = _inject_company_ctx(
        f"{joined}\n\n"
        "ì¶œë ¥:\n"
        "1) ì¼ê´€ì„± ë¬¸ì œ(ìˆ˜ì¹˜/ê¸°ê°„/ì—­í• /ì„±ê³¼/í‚¤ì›Œë“œ)\n"
        "2) ëª¨ìˆœ/ëˆ„ë½(ì¦ë¹™ ë¶€ì¡±/ì‹œê³„ì—´ ì¶©ëŒ/ì±…ì„Â·ì„±ê³¼ ë¶ˆì¼ì¹˜)\n"
        "3) ì •ë ¬ ê°€ì´ë“œ(ìš°ì„ ìˆœìœ„/í‘œí˜„ í†µì¼/ì‚­ì œÂ·ì¶”ê°€ ê¶Œê³ , ì˜ˆë¬¸)\n"
        "4) ìµœì¢… ì ê²€í‘œ(ì²´í¬ë¦¬ìŠ¤íŠ¸)\n", meta
    )
    msgs = [{"role": "system", "content": SYS_CMP},
            {"role": "user", "content": usr}]
    _dbg("compare_documents prompt", msgs)

    return _safe_chat(msgs, temperature=CFG.t_cmp, max_tokens=CFG.max_tokens_cmp, default="í‰ê°€ ìƒì„± ì‹¤íŒ¨")


def analyze_research_alignment(
    jd_text: str,
    resume_concat: str,
    *, 
    research_text: str = "",
    meta: Dict[str, Any] | None = None
) -> str:
    jd_snip   = (jd_text or "")[:CFG.max_jd_chars]
    rs_snip   = (resume_concat or "")[:CFG.max_resume_chars]
    rsch_snip = (research_text or "")[:CFG.max_research_chars]

    if not jd_snip and not rs_snip and not rsch_snip:
        return "ë¶„ì„ ëŒ€ìƒ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    body = f"[JD]\n{jd_snip}\n\n[ì§€ì›ì„œ í•©ë³¸]\n{rs_snip}\n\n"
    if rsch_snip:
        body += f"[ë¦¬ì„œì¹˜]\n{rsch_snip}\n\n"

    usr = _inject_company_ctx(
        body +
        "ì¶œë ¥:\n"
        "1) í•µì‹¬ ì •í•©ì„±(ìš”êµ¬ì—­ëŸ‰â†”ì§€ì›ì„œ ì£¼ì¥ ì—°ê²°, KPI/ì§€í‘œ ê¸°ì¤€)\n"
        "2) ì°¨ë³„í™” í¬ì¸íŠ¸(íšŒì‚¬Â·ì§ë¬´ í¬ì§€ì…”ë‹)\n"
        "3) ë¯¸ìŠ¤ë§¤ì¹˜ ë¦¬ìŠ¤í¬(í•´ì†Œ ë°©ì•ˆ)\n"
        "4) ë¬¸ì¥ ì˜ˆì‹œ(ì§€ì›ì„œ/ìì†Œì„œìš© 2~3ë¬¸ì¥ í…œí”Œë¦¿)\n",
        meta
    )
    msgs = [{"role": "system", "content": SYS_ALIGN},
            {"role": "user", "content": usr}]
    _dbg("analyze_research_alignment prompt", msgs)

    return _safe_chat(msgs, temperature=CFG.t_align, max_tokens=CFG.max_tokens_align, default="í‰ê°€ ìƒì„± ì‹¤íŒ¨")

# ---------- CLI: ë‹¨ì¼ íŒŒì¼ í…ŒìŠ¤íŠ¸ ----------
def _cli():
    p = argparse.ArgumentParser(description="Resume service quick test")
    sub = p.add_subparsers(dest="cmd", required=True)

    p_deep = sub.add_parser("deep")
    p_deep.add_argument("--text", required=False, default="")
    p_deep.add_argument("--jd", required=False, default="")

    p_cmp = sub.add_parser("compare")
    p_cmp.add_argument("--docs", nargs="+", help="ì´ë¦„=íŒŒì¼ê²½ë¡œ ...")

    p_align = sub.add_parser("align")
    p_align.add_argument("--jd", required=False, default="")
    p_align.add_argument("--resume", required=False, default="")
    p_align.add_argument("--research", required=False, default="")

    args = p.parse_args()
    meta = {}

    if args.cmd == "deep":
        print(analyze_resume_or_cover(args.text, jd_text=args.jd, meta=meta))
    elif args.cmd == "compare":
        import os
        named = {}
        for spec in (args.docs or []):
            if "=" in spec:
                name, path = spec.split("=", 1)
                try:
                    with open(path, "r", encoding="utf-8") as f:
                        named[name] = f.read()
                except Exception as e:
                    _log.warning(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {path} | {e}")
        print(compare_documents(named, meta=meta))
    elif args.cmd == "align":
        print(analyze_research_alignment(args.jd, args.resume, research_text=args.research, meta=meta))

if __name__ == "__main__":
    try:
        _cli()
    except Exception as e:
        _log.error(f"resume_service CLI ì‹¤íŒ¨: {e}")
        sys.exit(1)
