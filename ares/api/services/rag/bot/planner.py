# ares/api/services/rag/bot/planner.py
"""
Interview Planner module for the RAG Interview Bot.

- íšŒì‚¬/ì§ë¬´ RAG ìš”ì•½ + ì´ë ¥/JD/ì—°êµ¬/NCS ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
  ë©´ì ‘ ê³„íš(interview_plan)ì„ ì„¤ê³„í•©ë‹ˆë‹¤.
- ì¶œë ¥ì€ {"interview_plan": [...]} í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
"""

from typing import Any, Dict, List, Optional
import logging

from ares.api.services.prompts import (
    DIFFICULTY_INSTRUCTIONS,
    prompt_interview_designer_v2,
    make_icebreak_question_llm_or_template,
)
from .base import RAGBotBase
from .utils import (
    _truncate,
    normalize_llm_json,
    safe_get_any,
)

logger = logging.getLogger(__name__)

class InterviewPlanner:
    """Designs the interview plan using RAG and LLM prompts."""
    def __init__(self, bot: RAGBotBase):
        self.bot = bot

    def design_interview_plan(self) -> Dict:
        """
        LLMìœ¼ë¡œ ì¸í„°ë·° ê³„íšì„ ì„¤ê³„í•˜ê³ , V2 ìŠ¤í‚¤ë§ˆë¥¼ ë‚´ë¶€ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        if not self.bot.rag_ready:
            return {"error": "RAG system is not ready.", "interview_plan": []}

        print(f"\nğŸ§  Designing custom interview plan for {self.bot.company_name} (Difficulty: {self.bot.difficulty}, Interviewer: {self.bot.interviewer_mode})...")
        try:
            business_info = self.bot._get_company_business_info()
            ncs_info = ""
            ncs_dict = self.bot._ensure_ncs_dict(self.bot.ncs_context)
            if isinstance(ncs_dict.get("ncs"), list):
                ncs_titles = [it.get("title") for it in ncs_dict["ncs"] if isinstance(it, dict) and it.get("title")]
                if ncs_titles:
                    ncs_info = f"\n\nNCS Job Information: {', '.join(ncs_titles[:6])}."

            persona_description = self.bot.persona["persona_description"].replace("{company_name}", self.bot.company_name).replace("{job_title}", self.bot.job_title)
            difficulty_instruction = DIFFICULTY_INSTRUCTIONS.get(self.bot.difficulty, "")

            prompt = (
                prompt_interview_designer_v2
                .replace("{persona_description}", persona_description)
                .replace("{question_style_guide}", self.bot.persona["question_style_guide"])
                .replace("{company_name}", self.bot.company_name)
                .replace("{job_title}", self.bot.job_title)
                .replace("{difficulty_instruction}", difficulty_instruction)
                .replace("{business_info}", business_info)
                .replace("{jd_context}", _truncate(self.bot.jd_context, 1200))
                .replace("{resume_context}", _truncate(self.bot.resume_context, 1200))
                .replace("{research_context}", _truncate(self.bot.research_context, 1200))
                .replace("{ncs_info}", _truncate(ncs_info, 400))
            )

            raw = self.bot._chat_json(prompt, temperature=0.3, max_tokens=3200)
            normalized_data = normalize_llm_json(raw)

            # V2 ì‘ë‹µ("phases")ì„ ë‚´ë¶€ í‘œì¤€ í˜•ì‹("stages")ìœ¼ë¡œ ë³€í™˜
            v2_phases = []
            if isinstance(normalized_data, dict):
                v2_phases = normalized_data.get("phases", [])
            elif isinstance(normalized_data, list):
                # LLMì´ ìµœìƒìœ„ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ ë°˜í™˜í•˜ëŠ” ê²½ìš°ë„ ì²˜ë¦¬
                v2_phases = normalized_data

            if not isinstance(v2_phases, list):
                v2_phases = []

            # `normalize_interview_plan` í•¨ìˆ˜ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ `phase` -> `stage` í‚¤ ë³€ê²½
            transformed_stages = []
            for phase in v2_phases:
                if not isinstance(phase, dict): continue
                new_stage = phase.copy()
                if 'phase' in new_stage:
                    new_stage['stage'] = new_stage.pop('phase')
                transformed_stages.append(new_stage)

            final_plan = {"interview_plan": transformed_stages}

            # ----- ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹ ì§ˆë¬¸ ì¶”ê°€ (V2 ê³„íšì— icebreakerê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„) -----
            try:
                # V2 ê³„íšì— ì´ë¯¸ ì•„ì´ìŠ¤ë¸Œë ˆì´ì»¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                has_icebreaker_in_plan = False
                for stage in final_plan.get("interview_plan", []):
                    if stage.get("stage") == "intro":
                        for item in stage.get("items", []):
                            if item.get("question_type") == "icebreaking":
                                has_icebreaker_in_plan = True
                                break
                    if has_icebreaker_in_plan: break
                
                if not has_icebreaker_in_plan:
                    icebreaker_text = make_icebreak_question_llm_or_template(llm_call=self.bot._chat)
                    icebreaker_question = {
                        "id": "icebreaker-1",
                        "type": "icebreaking",
                        "question": icebreaker_text,
                        "followups": []
                    }
                    # ë³„ë„ í‚¤ì— ì €ì¥ (ê¸°ì¡´ ë¡œì§ í˜¸í™˜)
                    final_plan["icebreakers"] = [icebreaker_question]

            except Exception as ice_e:
                logger.warning(f"Could not generate icebreaker question: {ice_e}")
                final_plan["icebreakers"] = []

            print("âœ… Structured interview plan designed successfully.")
            return final_plan

        except Exception as e:
            error_msg = f"Failed to design interview plan: {e}"
            print(f"âŒ {error_msg}")
            return {"error": error_msg, "interview_plan": []}
