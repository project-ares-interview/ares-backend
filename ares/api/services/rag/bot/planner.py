# ares/api/services/rag/bot/planner.py
"""
Interview Planner module for the RAG Interview Bot.

- íšŒì‚¬/ì§ë¬´ RAG ìš”ì•½ + ì´ë ¥/JD/ì—°êµ¬/NCS ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
  ë©´ì ‘ ê³„íš(interview_plan)ì„ ì„¤ê³„í•©ë‹ˆë‹¤.
- ì¶œë ¥ì€ {"interview_plan": [...]} í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
"""
import json
from typing import Any, Dict, List, Optional
import logging

from ares.api.services.prompts import (
    DIFFICULTY_INSTRUCTIONS,
    prompt_extract_competencies,
    prompt_generate_question,
    prompt_create_rubric,
)
from ares.api.services.company_data import get_company_description
from .base import RAGBotBase
from .utils import (
    _truncate,
    normalize_llm_json,
    safe_get_any,
    _escape_special_chars,
    sanitize_plan_questions,
)

logger = logging.getLogger(__name__)

class InterviewPlanner:
    """Designs the interview plan using a Chain-of-Prompts (CoP) approach."""
    def __init__(self, bot: RAGBotBase):
        self.bot = bot

    def _get_full_contexts(self) -> Dict[str, Any]:
        """ëª¨ë“  í”„ë¡¬í”„íŠ¸ì—ì„œ ê³µí†µì ìœ¼ë¡œ ì‚¬ìš©ë  ì „ì²´ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
        safe_company_name = _escape_special_chars(self.bot.company_name)
        safe_job_title = _escape_special_chars(self.bot.job_title)
        query_text = f"Summarize key business areas, recent performance, major risks for {safe_company_name}, especially related to the {safe_job_title} role."
        business_info = self.bot.summarize_company_context(query_text)

        ideal_candidate_profile = get_company_description(self.bot.company_name)
        if "ì •ë³´ ì—†ìŒ" in ideal_candidate_profile:
            ideal_candidate_profile = "(ë³„ë„ ì¸ì¬ìƒ ì •ë³´ ì—†ìŒ)"

        ncs_info = ""
        ncs_dict = self.bot._ensure_ncs_dict(self.bot.ncs_context)
        if isinstance(ncs_dict.get("ncs"), list):
            ncs_titles = [it.get("title") for it in ncs_dict["ncs"] if isinstance(it, dict) and it.get("title")]
            if ncs_titles:
                ncs_info = f"NCS Job Information: {', '.join(ncs_titles[:6])}."

        persona_description = self.bot.persona["persona_description"].replace("{company_name}", self.bot.company_name).replace("{job_title}", self.bot.job_title)
        difficulty_instruction = DIFFICULTY_INSTRUCTIONS.get(self.bot.difficulty, "")

        return {
            "job_title": self.bot.job_title,
            "jd_context": _truncate(self.bot.jd_context, 8000),
            "resume_context": _truncate(self.bot.resume_context, 8000),
            "persona_description": persona_description,
            "business_info": business_info,
            "ideal_candidate_profile": ideal_candidate_profile,
            "research_context": _truncate(self.bot.research_context, 8000),
            "ncs_info": _truncate(ncs_info, 400),
            "difficulty_instruction": difficulty_instruction,
        }

    def _extract_competencies(self, contexts: Dict[str, Any]) -> List[str]:
        """1ë‹¨ê³„: JDì™€ ì´ë ¥ì„œì—ì„œ ê²€ì¦í•  í•µì‹¬ ì—­ëŸ‰ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        prompt = prompt_extract_competencies.format(**contexts)
        result = self.bot._chat_json(prompt, temperature=0.1, max_tokens=1024)
        normalized = normalize_llm_json(result)
        return normalized.get("competencies_to_verify", [])

    def _generate_question_for_competency(self, competency: str, contexts: Dict[str, Any]) -> Optional[Dict]:
        """2ë‹¨ê³„: ê°œë³„ ì—­ëŸ‰ì— ëŒ€í•œ ì§ˆë¬¸ê³¼ í‰ê°€ í¬ì¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        prompt = prompt_generate_question.format(competency=competency, **contexts)
        result = self.bot._chat_json(prompt, temperature=0.3, max_tokens=1024)
        return normalize_llm_json(result)

    def _create_rubric_for_question(self, question_item: Dict) -> Optional[Dict]:
        """3ë‹¨ê³„: ìƒì„±ëœ ì§ˆë¬¸ì— ëŒ€í•œ í‰ê°€ ê¸°ì¤€(Rubric)ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not question_item or not question_item.get("question"):
            return None
        
        prompt = prompt_create_rubric.format(
            question=question_item["question"],
            expected_points=json.dumps(question_item.get("expected_points", []), ensure_ascii=False)
        )
        result = self.bot._chat_json(prompt, temperature=0.2, max_tokens=1024)
        return normalize_llm_json(result)

    def _assemble_full_plan(self, core_items: List[Dict]) -> Dict:
        """4ë‹¨ê³„: Intro, Core, Wrap-up ë‹¨ê³„ë¥¼ ì¡°í•©í•˜ì—¬ ìµœì¢… ë©´ì ‘ ê³„íšì„ ì™„ì„±í•©ë‹ˆë‹¤."""
        intro_phase = {
            "phase": "intro",
            "items": [
                {
                    "id": "intro-1",
                    "question_type": "icebreaking",
                    "question": "ì˜¤ëŠ˜ ë©´ì ‘ ì¥ì†Œê¹Œì§€ ì˜¤ì‹œëŠ” ê¸¸ì€ í¸ì•ˆí•˜ì…¨ë‚˜ìš”?",
                    "followups": [],
                    "expected_points": ["ê¸´ì¥ ì™„í™”", "ë¶„ìœ„ê¸° ì¡°ì„±"],
                    "rubric": [
                        {"label": "ë§¤ìš°ìš°ìˆ˜", "score": 50, "desc": "í¸ì•ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ë©° ê¸ì •ì ì¸ ë¶„ìœ„ê¸°ë¥¼ ì¡°ì„±í•¨."},
                        {"label": "ë³´í†µ", "score": 30, "desc": "ê°„ë‹¨í•˜ê²Œ ëŒ€ë‹µí•˜ë©° ë¬´ë‚œí•œ ìˆ˜ì¤€ì˜ ìƒí˜¸ì‘ìš©ì„ ë³´ì„."},
                        {"label": "ë¯¸í¡", "score": 10, "desc": "ë‹¨ë‹µí˜•ìœ¼ë¡œ ëŒ€ë‹µí•˜ê±°ë‚˜ ê¸´ì¥í•œ ê¸°ìƒ‰ì´ ì—­ë ¥í•¨."}
                    ]
                },
                {
                    "id": "intro-2",
                    "question_type": "self_intro",
                    "question": "ë¨¼ì €, ì¤€ë¹„í•˜ì‹  ìê¸°ì†Œê°œë¥¼ ë¶€íƒë“œë¦½ë‹ˆë‹¤.",
                    "followups": ["ê°€ì¥ ê°•ì¡°í•˜ê³  ì‹¶ì€ ê²½í—˜ì€ ë¬´ì—‡ì¸ê°€ìš”?", "ê·¸ ê²½í—˜ì´ ì´ ì§ë¬´ì™€ ì–´ë–»ê²Œ ì—°ê²°ëœë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?"],
                    "expected_points": ["ê²½ë ¥ ìš”ì•½", "ì§ë¬´ ê´€ë ¨ ê°•ì ", "ì§€ì› ë™ê¸°"],
                    "rubric": [
                        {"label": "ë§¤ìš°ìš°ìˆ˜", "score": 50, "desc": "ìì‹ ì˜ í•µì‹¬ ê°•ì ê³¼ ê²½í—˜ì„ ì§ë¬´ì™€ ëª…í™•íˆ ì—°ê²°í•˜ì—¬ ê°„ê²°í•˜ê³  ì„¤ë“ë ¥ ìˆê²Œ ì „ë‹¬í•¨."},
                        {"label": "ë³´í†µ", "score": 30, "desc": "ì£¼ìš” ê²½í—˜ì„ ë‚˜ì—´í•˜ì§€ë§Œ, ì§ë¬´ì™€ì˜ ê´€ë ¨ì„±ì´ë‚˜ êµ¬ì²´ì ì¸ ê°•ì  ì–´í•„ì´ ë‹¤ì†Œ ë¶€ì¡±í•¨."},
                        {"label": "ë¯¸í¡", "score": 10, "desc": "ìê¸°ì†Œê°œê°€ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì§§ê³ , ì§ë¬´ì™€ ê´€ë ¨ ì—†ëŠ” ë‚´ìš©ì´ ë§ìŒ."}
                    ]
                }
            ]
        }
        core_phase = {"phase": "core", "items": core_items}
        wrapup_phase = {
            "phase": "wrapup",
            "items": [
                {
                    "question_type": "wrapup",
                    "question": "ë§ˆì§€ë§‰ìœ¼ë¡œ ì €í¬ì—ê²Œ ê¶ê¸ˆí•œ ì ì´ ìˆê±°ë‚˜, í•˜ê³  ì‹¶ì€ ë§ì”€ì´ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ í•´ì£¼ì„¸ìš”.",
                    "followups": [],
                    "expected_points": ["íšŒì‚¬/ì§ë¬´ì— ëŒ€í•œ ê´€ì‹¬ë„", "ì…ì‚¬ ì˜ì§€", "ë§ˆì§€ë§‰ ì–´í•„"],
                    "rubric": [
                        {"label": "ë§¤ìš°ìš°ìˆ˜", "score": 50, "desc": "íšŒì‚¬ì™€ ì§ë¬´ì— ëŒ€í•œ ê¹Šì€ ê´€ì‹¬ì´ ë“œëŸ¬ë‚˜ëŠ”, í†µì°°ë ¥ ìˆëŠ” ì§ˆë¬¸ì„ í•¨."},
                        {"label": "ë³´í†µ", "score": 30, "desc": "ì¼ë°˜ì ì¸ ì§ˆë¬¸(ì—°ë´‰, ë³µì§€ ë“±)ì„ í•˜ê±°ë‚˜ íŠ¹ë³„í•œ ì§ˆë¬¸ì´ ì—†ìŒ."},
                        {"label": "ë¯¸í¡", "score": 10, "desc": "ì§ˆë¬¸ì´ ì „í˜€ ì—†ìœ¼ë©°, ì…ì‚¬ ì˜ì§€ê°€ ë¶€ì¡±í•´ ë³´ì„."}
                    ]
                }
            ]
        }
        
        return {"phases": [intro_phase, core_phase, wrapup_phase]}

    def design_interview_plan(self) -> Dict:
        """
        Chain-of-Prompts (CoP) ë°©ì‹ìœ¼ë¡œ LLMì„ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œí•˜ì—¬ ì¸í„°ë·° ê³„íšì„ ì„¤ê³„í•©ë‹ˆë‹¤.
        """
        if not self.bot.rag_ready:
            return {"error": "RAG system is not ready.", "interview_plan": []}

        print(f"\nğŸ§  Designing custom interview plan for {self.bot.company_name} via CoP...")
        try:
            contexts = self._get_full_contexts()
            
            # 1ë‹¨ê³„: í•µì‹¬ ì—­ëŸ‰ ì¶”ì¶œ
            competencies = self._extract_competencies(contexts)
            if not competencies:
                raise ValueError("Failed to extract competencies from resume and JD.")
            print(f"âœ… Step 1/3: Extracted {len(competencies)} competencies to verify.")

            # 2 & 3ë‹¨ê³„: ê° ì—­ëŸ‰ì— ëŒ€í•œ ì§ˆë¬¸ ë° ë£¨ë¸Œë¦­ ìƒì„±
            core_questions = []
            for i, competency in enumerate(competencies):
                print(f"  - Generating question {i+1}/{len(competencies)} for: {competency}")
                question_item = self._generate_question_for_competency(competency, contexts)
                if question_item:
                    rubric_item = self._create_rubric_for_question(question_item)
                    if rubric_item and "rubric" in rubric_item:
                        question_item.update(rubric_item)
                    core_questions.append(question_item)
            
            if not core_questions:
                raise ValueError("Failed to generate any core questions.")
            print(f"âœ… Step 2/3: Generated {len(core_questions)} core questions.")

            # 4ë‹¨ê³„: ìµœì¢… ê³„íš ì¡°ë¦½
            final_plan_v2 = self._assemble_full_plan(core_questions)
            print("âœ… Step 3/3: Assembled final interview plan.")

            # ìµœì¢… ì¶œë ¥ì„ ìƒˆë¡œìš´ V2 í˜•ì‹ê³¼ í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ì •ê·œí™”ëœ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
            
            # 1. ì •ê·œí™”ëœ í˜•ì‹(normalized_plan) ìƒì„±
            transformed_stages = []
            icebreakers = []
            for phase in final_plan_v2.get("phases", []):
                if not isinstance(phase, dict): continue
                
                # `phase` -> `stage` í‚¤ ë³€ê²½ ë° `items` -> `questions` í‚¤ ë³€ê²½
                new_stage = {
                    "title": phase.get("phase"),
                    "questions": phase.get("items", [])
                }
                
                # ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹ ì§ˆë¬¸ì€ ë³„ë„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬ (í˜¸í™˜ì„±ì„ ìœ„í•´)
                if phase.get("phase") == "intro":
                    non_icebreakers = []
                    for item in new_stage["questions"]:
                        if item.get("question_type") == "icebreaking":
                            icebreakers.append({
                                "id": item.get("id"), "text": item.get("question"),
                                "followups": [], "question_type": "icebreaking"
                            })
                        else:
                            non_icebreakers.append(item)
                    new_stage["questions"] = non_icebreakers
                
                if new_stage["questions"]:
                    transformed_stages.append(new_stage)

            # 2. ìµœì¢… ë°˜í™˜ ê°ì²´ ìƒì„±
            final_plan = {
                "raw_v2_plan": final_plan_v2,
                "normalized_plan": {
                    "icebreakers": icebreakers,
                    "stages": transformed_stages
                }
            }
            
            print("âœ… Structured interview plan designed successfully via CoP.")
            return final_plan

        except Exception as e:
            error_msg = f"Failed to design interview plan via CoP: {e}"
            print(f"âŒ {error_msg}")
            logger.error(error_msg, exc_info=True)
            return {"error": error_msg, "interview_plan": []}
