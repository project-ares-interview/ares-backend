# ares/api/services/rag/final_interview_rag.py
import json
import re
import traceback
from typing import Any

from openai import AzureOpenAI
from unidecode import unidecode
from django.conf import settings

# RAG ì‹œìŠ¤í…œ
from .new_azure_rag_llamaindex import AzureBlobRAGSystem
# ì›¹ ê²€ìƒ‰ ë„êµ¬
from .tool_code import google_search
# í”„ë¡¬í”„íŠ¸
from ares.api.services.prompt import (
    INTERVIEWER_PERSONAS,
    prompt_interview_designer,
    DIFFICULTY_INSTRUCTIONS,
    prompt_resume_analyzer,
    prompt_rag_answer_analysis,
    prompt_rag_json_correction,
    prompt_rag_follow_up_question,
    prompt_rag_final_report,
)
from ares.api.utils.ai_utils import safe_extract_json

def _escape_special_chars(text: str) -> str:
    """Azure AI Search/Lucene ì˜ˆì•½ë¬¸ì ì´ìŠ¤ì¼€ì´í”„"""
    # Lucene ì˜ˆì•½ ë¬¸ì: + - && || ! ( ) { } [ ] ^ " ~ * ? : \
    pattern = r'([+\-&|!(){}\[\]^"~*?:\\])'
    return re.sub(pattern, r'\\\1', text or "")



# [PATCH] final_interview_rag.py ë‚´ë¶€ì— ì¶”ê°€
import unicodedata

def _natural_num(s: str) -> int:
    try:
        # '1ë‹¨ê³„', '2ë‹¨ê³„' ê°™ì€ ì ‘ë¯¸ í…ìŠ¤íŠ¸ ì œê±°í•˜ê³  ìˆ«ìë§Œ
        digits = "".join(ch for ch in s if ch.isdigit())
        return int(digits) if digits else 10**6
    except Exception:
        return 10**6

def _extract_from_korean_schema(plan_data: Any) -> list[dict]:
    """
    ë‹¤ìŒê³¼ ê°™ì€ í•œê¸€ ìŠ¤í‚¤ë§ˆë¥¼ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜:
    {
      "ë©´ì ‘ ê³„íš": {
        "1ë‹¨ê³„": { "ëª©í‘œ": "...", "ì§ˆë¬¸": [ {"ì§ˆë¬¸": "..."}, {"ì§ˆë¬¸": "..."} ] },
        "2ë‹¨ê³„": { ... },
        ...
      }
    }
    ë˜ëŠ” "ë©´ì ‘ ê³„íš" ì—†ì´ ë°”ë¡œ {"1ë‹¨ê³„": {...}} í˜•íƒœë„ ì§€ì›.
    """
    if not isinstance(plan_data, (dict, list)):
        return []

    root = plan_data
    if isinstance(root, dict) and "ë©´ì ‘ ê³„íš" in root and isinstance(root["ë©´ì ‘ ê³„íš"], dict):
        stages_dict = root["ë©´ì ‘ ê³„íš"]
    elif isinstance(root, dict) and any(k.endswith("ë‹¨ê³„") for k in root.keys()):
        stages_dict = root
    else:
        return []

    norm: list[dict] = []
    # ë‹¨ê³„ í‚¤ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ìˆœì„œë¡œ ì •ë ¬: 1ë‹¨ê³„, 2ë‹¨ê³„, ...
    for stage_key in sorted(stages_dict.keys(), key=_natural_num):
        stage_block = stages_dict.get(stage_key, {})
        if not isinstance(stage_block, dict):
            continue
        objective = (stage_block.get("ëª©í‘œ") or stage_block.get("ëª© ì ") or "").strip() or None
        qs_raw = stage_block.get("ì§ˆë¬¸") or []
        qs_list: list[str] = []
        if isinstance(qs_raw, list):
            for item in qs_raw:
                if isinstance(item, str):
                    qs_list.append(item.strip())
                elif isinstance(item, dict):
                    q = item.get("ì§ˆë¬¸") or item.get("question") or item.get("Q")
                    if isinstance(q, str) and q.strip():
                        qs_list.append(q.strip())
        elif isinstance(qs_raw, dict):
            q = qs_raw.get("ì§ˆë¬¸") or qs_raw.get("question")
            if isinstance(q, str) and q.strip():
                qs_list.append(q.strip())

        # ë¬¸ì¥ ê³¼ë‹¤ ì‹œ ì²« ë¬¸ì¥ë§Œ ë³´ì •
        fixed = []
        for q in qs_list:
            q = unicodedata.normalize("NFKC", q)
            if len(q) > 260:
                parts = re.split(r"(?<=[.!?])\s+", q)
                fixed.append(parts[0] if parts and parts[0] else q[:260])
            else:
                fixed.append(q)

        if fixed:
            norm.append({"stage": stage_key, "objective": objective, "questions": fixed})
    return norm


def _debug_print_raw_json(label: str, payload: str):
    try:
        head = payload[:800]
        tail = payload[-400:] if len(payload) > 1200 else ""
        print(f"\n--- {label} RAW JSON (len={len(payload)}) START ---\n{head}")
        if tail:
            print("\n... (snip) ...\n")
            print(tail)
        print(f"--- {label} RAW JSON END ---\n")
    except Exception:
        pass

def _force_json_like(raw: str) -> dict | list | None:
    """
    ë§ˆí¬ë‹¤ìš´/ì„¤ëª…ë¬¸ ì„ì¸ ì‘ë‹µì—ì„œ ê°€ì¥ ë°”ê¹¥ìª½ JSON ë¸”ë¡ì„ ê°•ì œë¡œ ì¶”ì¶œ.
    """
    if not raw:
        return None
    # ì½”ë“œíœìŠ¤ ì œê±°
    raw2 = re.sub(r"^```(?:json)?|```$", "", raw.strip(), flags=re.MULTILINE)
    # ì²« { ... } ë˜ëŠ” [ ... ] ë¸”ë¡ ì‹œë„
    for open_ch, close_ch in [("{", "}"), ("[", "]")]:
        start = raw2.find(open_ch)
        end = raw2.rfind(close_ch)
        if start != -1 and end != -1 and end > start:
            candidate = raw2[start : end + 1]
            try:
                return json.loads(candidate)
            except Exception:
                continue
    return None

# [PATCH] ê¸°ì¡´ _normalize_plan_local í•¨ìˆ˜ ì „ì²´ë¥¼ ì•„ë˜ë¡œ êµì²´
def _normalize_plan_local(plan_data: Any) -> list[dict]:
    """
    ë‹¤ì–‘í•œ ë³€í˜• ìŠ¤í‚¤ë§ˆë¥¼ í‘œì¤€ list[{stage, objective?, questions:[...]}] ë¡œ ì •ê·œí™”.
    - ì˜ë¬¸: plan / interview_plan / questions / question / items
    - êµ­ë¬¸: ë©´ì ‘ ê³„íš / Në‹¨ê³„ / ëª©í‘œ / ì§ˆë¬¸[{ì§ˆë¬¸:"..."}]
    """
    if not plan_data:
        return []

    # str -> JSON ì‹œë„ + ê°•ì œ JSON ë¸”ë¡ ì¶”ì¶œ
    if isinstance(plan_data, str):
        plan_data = safe_extract_json(plan_data, default=None) or _force_json_like(plan_data) or {}

    # 1) í•œêµ­ì–´ ìŠ¤í‚¤ë§ˆ ë¨¼ì € ì‹œë„
    ko_norm = _extract_from_korean_schema(plan_data)
    if ko_norm:
        return ko_norm

    # 2) ì˜ë¬¸/ì¼ë°˜ ìŠ¤í‚¤ë§ˆ
    candidate = (
        plan_data.get("plan")
        if isinstance(plan_data, dict) and "plan" in plan_data
        else plan_data.get("interview_plan")
        if isinstance(plan_data, dict) and "interview_plan" in plan_data
        else plan_data
    )

    if isinstance(candidate, dict):
        # ë‹¨ì¼ ìŠ¤í…Œì´ì§€ or dict ëª¨ìŒ
        if "stage" in candidate and any(k in candidate for k in ("questions", "question", "items")):
            candidate = [candidate]
        else:
            candidate = [v for v in candidate.values() if isinstance(v, dict)]

    if not isinstance(candidate, list):
        return []

    norm: list[dict] = []
    for i, st in enumerate(candidate):
        if not isinstance(st, dict):
            continue
        stage = st.get("stage") or f"Stage {i+1}"
        objective = st.get("objective") or st.get("goal") or st.get("purpose") or st.get("objectives")
        qs = st.get("questions") or st.get("question") or st.get("items") or []
        if isinstance(qs, str):
            qs = [qs]
        qs = [q.strip() for q in qs if isinstance(q, str) and q.strip()]

        fixed_qs = []
        for q in qs:
            if len(q) > 260:
                m = re.split(r"(?<=[.!?])\s+", q)
                fixed_qs.append(m[0] if m and m[0] else q[:260])
            else:
                fixed_qs.append(q)

        if fixed_qs:
            norm.append({"stage": stage, "objective": objective, "questions": fixed_qs})
    return norm


# -----------------------------
# Bot
# -----------------------------
class RAGInterviewBot:
    """RAG + LLM ê¸°ë°˜ êµ¬ì¡°í™” ë©´ì ‘ Bot (í•˜ë“œë‹ ë²„ì „)"""

    def __init__(
        self,
        company_name: str,
        job_title: str,
        container_name: str,
        index_name: str,
        difficulty: str = "normal",
        interviewer_mode: str = "team_lead",
        ncs_context: dict | None = None,
        jd_context: str = "",
        resume_context: str = "",
        research_context: str = "",
        **kwargs,
    ):
        print(f"ğŸ¤– RAG ì „ìš© ì‚¬ì—… ë¶„ì„ ë©´ì ‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë©´ì ‘ê´€: {interviewer_mode})...")
        self.company_name = company_name
        self.job_title = job_title
        self.difficulty = difficulty
        self.interviewer_mode = interviewer_mode
        self.ncs_context = ncs_context or {}
        self.jd_context = jd_context
        self.resume_context = resume_context
        self.research_context = research_context

        self.persona = INTERVIEWER_PERSONAS.get(self.interviewer_mode, INTERVIEWER_PERSONAS["team_lead"])

        self.endpoint = getattr(settings, "AZURE_OPENAI_ENDPOINT", None)
        self.api_key = getattr(settings, "AZURE_OPENAI_KEY", None)
        self.api_version = (
            getattr(settings, "AZURE_OPENAI_API_VERSION", None)
            or getattr(settings, "API_VERSION", None)
            or "2024-08-01-preview"
        )
        self.model = (
            getattr(settings, "AZURE_OPENAI_MODEL", None)
            or getattr(settings, "AZURE_OPENAI_DEPLOYMENT", None)
            or "gpt-4o"
        )

        if not self.endpoint or not self.api_key:
            raise ValueError("Azure OpenAI endpoint/key is not set in Django settings.")

        self.client = AzureOpenAI(
            azure_endpoint=self.endpoint,
            api_key=self.api_key,
            api_version=self.api_version,
        )

        print("\nğŸ“Š Azure ì‚¬ì—… ë¶„ì„ RAG ì‹œìŠ¤í…œ ì—°ë™...")
        self.rag_system = None
        self.rag_ready = False
        try:
            self.rag_system = AzureBlobRAGSystem(container_name=container_name, index_name=index_name)
            blobs = list(self.rag_system.container_client.list_blobs())
            if not blobs:
                print(f"âš ï¸ ê²½ê³ : Azure Blob ì»¨í…Œì´ë„ˆ '{container_name}'ì— ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            print(f"âœ… Azure RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ. {len(blobs)}ê°œì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.")
            print("ğŸ”„ Azure AI Search ì¸ë±ìŠ¤ ìë™ ë™ê¸°í™” ì‹œì‘...")
            self.rag_system.sync_index(company_name_filter=self.company_name)
            self.rag_ready = True

        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨: {e}")

    # -----------------------------
    # ë‚´ë¶€ LLM í˜¸ì¶œ ë˜í¼
    # -----------------------------
    def chat_plain(self, prompt: str) -> str:
        """
        JSON ìŠ¤í‚¤ë§ˆ ê°•ì œ ì—†ì´ 'í‰ë¬¸ 1~2ë¬¸ì¥'ì„ ë°›ì•„ì˜¬ ë•Œ ì‚¬ìš©.
        """
        res = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.4,
            max_tokens=300,
        )
        return (res.choices[0].message.content or "").strip()

    # -----------------------------
    # í”Œëœ ìƒì„±
    # -----------------------------
    def design_interview_plan(self) -> dict:
        """
        RAG ê¸°ë°˜ êµ¬ì¡°í™” ë©´ì ‘ ê³„íš ìƒì„±.
        1ì°¨: í‘œì¤€ í”„ë¡¬í”„íŠ¸ â†’ JSON íŒŒì‹± â†’ ì •ê·œí™”
        2ì°¨: JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìê°€ ë³´ì • or ê°•ì œ JSON ì¶”ì¶œ
        3ì°¨: ì—¬ì „íˆ ë¹„ë©´ 'ë‹¨ê±´ ì˜¤í”„ë‹ ì§ˆë¬¸'ìœ¼ë¡œ ìµœì†Œ í”Œëœ êµ¬ì„±
        """
        if not self.rag_ready:
            return {}

        print(f"\nğŸ§  {self.company_name} ë§ì¶¤ ë©´ì ‘ ê³„íš ì„¤ê³„ ì¤‘ (ë‚œì´ë„: {self.difficulty}, ë©´ì ‘ê´€: {self.interviewer_mode})...")
        try:
            safe_company_name = _escape_special_chars(self.company_name)
            safe_job_title = _escape_special_chars(self.job_title)

            query_text = f"{safe_company_name}ì˜ í•µì‹¬ ì‚¬ì—…, ìµœê·¼ ì‹¤ì , ì£¼ìš” ë¦¬ìŠ¤í¬, ê·¸ë¦¬ê³  {safe_job_title} ì§ë¬´ì™€ ê´€ë ¨ëœ íšŒì‚¬ ì •ë³´ì— ëŒ€í•´ ìš”ì•½í•´ì¤˜."
            print(f"ğŸ” '{self.rag_system.index_name}' ì¸ë±ìŠ¤ì—ì„œ ì§ˆë¬¸ ì²˜ë¦¬: {query_text}")
            business_info = self.rag_system.query(query_text)

            # NCS ìš”ì•½
            ncs_info = ""
            if self.ncs_context.get("ncs"):
                ncs_titles = [item.get("title") for item in self.ncs_context["ncs"] if item.get("title")]
                if ncs_titles:
                    ncs_info = f"\n\nNCS ì§ë¬´ ê´€ë ¨ ì •ë³´: {', '.join(ncs_titles)}."

            difficulty_instruction = DIFFICULTY_INSTRUCTIONS.get(self.difficulty, "")
            prompt = prompt_interview_designer.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                question_style_guide=self.persona["question_style_guide"],
                company_name=self.company_name,
                job_title=self.job_title,
                difficulty_instruction=difficulty_instruction,
                business_info=business_info,
                jd_context=self.jd_context,
                resume_context=self.resume_context,
                research_context=self.research_context,
                ncs_info=ncs_info,
            )

            # 1ì°¨ ì‹œë„
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,
                temperature=0.4,
            )
            raw = response.choices[0].message.content or ""
            parsed = safe_extract_json(raw) or _force_json_like(raw) or {}
            normalized = _normalize_plan_local(parsed)

            # 2ì°¨ ì‹œë„: JSON êµì •
            if not normalized:
                _debug_print_raw_json("PLAN_FIRST_PASS", raw)
                try:
                    correction = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "Return ONLY valid JSON. No markdown or commentary."},
                            {"role": "user", "content": prompt},
                            {"role": "assistant", "content": raw},
                            {"role": "user", "content": prompt_rag_json_correction}
                        ],
                        temperature=0.0,
                        max_tokens=2000,
                    )
                    corrected_raw = correction.choices[0].message.content or ""
                    corrected = safe_extract_json(corrected_raw) or _force_json_like(corrected_raw) or {}
                    normalized = _normalize_plan_local(corrected)
                    if not normalized:
                        _debug_print_raw_json("PLAN_CORRECTION_FAILED", corrected_raw)
                except Exception as e2:
                    print(f"âš ï¸ í”Œëœ JSON êµì • ì‹¤íŒ¨: {e2}")

            # 3ì°¨ ì‹œë„: ë‹¨ê±´ ì˜¤í”„ë‹ìœ¼ë¡œ ìµœì†Œ í”Œëœ êµ¬ì„±
            if not normalized:
                print("â„¹ï¸ í”Œëœ ì •ê·œí™” ê²°ê³¼ê°€ ë¹„ì–´ ë‹¨ê±´ ì˜¤í”„ë‹ ì§ˆë¬¸ìœ¼ë¡œ ìµœì†Œ í”Œëœ êµ¬ì„±.")
                single = self.generate_opening_question(
                    company_name=self.company_name,
                    job_title=self.job_title,
                    difficulty=self.difficulty,
                    context_hint={"business_info": business_info},
                )
                if single:
                    normalized = [{
                        "stage": "Opening",
                        "objective": "ì§€ì›ìì˜ ìƒì‚°ìš´ì˜/ê³µì •ê¸°ìˆ  ê¸°ë³¸ ì—­ëŸ‰ê³¼ ì‚¬ê³ ë°©ì‹ ê²€ì¦",
                        "questions": [single],
                    }]

            print("âœ… êµ¬ì¡°í™” ë©´ì ‘ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ." if normalized else "âš ï¸ êµ¬ì¡°í™” ë©´ì ‘ ê³„íšì´ ë¹„ì–´ìˆìŒ.")
            return {"interview_plan": normalized}

        except Exception as e:
            print(f"âŒ ë©´ì ‘ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            traceback.print_exc()
            return {}

    # -----------------------------
    # ì˜¤í”„ë‹ ë‹¨ê±´ ì§ˆë¬¸ ìƒì„±ê¸° (í´ë°±)
    # -----------------------------
    def generate_opening_question(
        self,
        company_name: str,
        job_title: str,
        difficulty: str,
        context_hint: dict | None = None,
    ) -> str:
        """
        í”Œëœì´ ë¹„ê±°ë‚˜ ì§ˆë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©. í‰ë¬¸ 1ë¬¸ì¥.
        """
        hints = []
        if isinstance(context_hint, dict):
            bi = context_hint.get("business_info")
            if bi:
                # ì•ë¶€ë¶„ë§Œ íŒíŠ¸ë¡œ ì‚¬ìš©
                hints.append(str(bi)[:600])
        ncs_titles = [it.get("title") for it in (self.ncs_context or {}).get("ncs", []) if it.get("title")]
        if ncs_titles:
            hints.append("NCS: " + ", ".join(ncs_titles[:5]))

        prompt = (
            f"[ì—­í• ] ë‹¹ì‹ ì€ {company_name} {job_title} ë©´ì ‘ì˜ {self.interviewer_mode} ë©´ì ‘ê´€\n"
            f"[ë‚œì´ë„] {difficulty}\n"
            "[ìš”ì²­] ì§€ì›ìì˜ ìƒì‚°ìš´ì˜/ê³µì •ê¸°ìˆ  ì—­ëŸ‰ì„ ê²€ì¦í•  'ì˜¤í”„ë‹ ì§ˆë¬¸' 1ë¬¸ì¥ë§Œ ì¶œë ¥.\n"
            "ëª¨í˜¸í•œ í‘œí˜„ì„ í”¼í•˜ê³ , ìˆ˜ì¹˜/ê·¼ê±°/ì‚¬ë¡€ ì œì‹œë¥¼ ìœ ë„í•  ê²ƒ.\n"
            f"[íŒíŠ¸]\n- " + ("\n- ".join(hints) if hints else "(ì—†ìŒ)")
        )
        try:
            text = self.chat_plain(prompt)
            # ë¬¸ì¥ ë ë³´ì •
            text = text.strip().split("\n")[0].strip()
            return text
        except Exception as e:
            print(f"âŒ ë‹¨ê±´ ì˜¤í”„ë‹ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    # -----------------------------
    # ì´ë ¥ì„œ/RAG ë¶„ì„
    # -----------------------------
    def analyze_resume_with_rag(self) -> dict:
        if not self.rag_ready or not self.resume_context:
            return {}
        print(f"\nğŸ“„ RAG ê¸°ë°˜ ì´ë ¥ì„œ ë¶„ì„ ì¤‘ (ë©´ì ‘ê´€: {self.interviewer_mode})...")
        try:
            safe_company_name = _escape_special_chars(self.company_name)
            safe_job_title = _escape_special_chars(self.job_title)
            business_info = self.rag_system.query(
                f"{safe_company_name}ì˜ í•µì‹¬ ì‚¬ì—…, ìµœê·¼ ì‹¤ì , ì£¼ìš” ë¦¬ìŠ¤í¬, ê·¸ë¦¬ê³  {safe_job_title} ì§ë¬´ì™€ ê´€ë ¨ëœ íšŒì‚¬ ì •ë³´ì— ëŒ€í•´ ìš”ì•½í•´ì¤˜."
            )

            prompt = prompt_resume_analyzer.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                company_name=self.company_name,
                job_title=self.job_title,
                business_info=business_info,
                resume_context=self.resume_context,
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1500,
                temperature=0.3,
            )
            result = safe_extract_json(response.choices[0].message.content)
            print("âœ… ì´ë ¥ì„œ-íšŒì‚¬ ì—°ê´€ì„± ë¶„ì„ ì™„ë£Œ.")
            return result
        except Exception as e:
            print(f"âŒ ì´ë ¥ì„œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def analyze_answer_with_rag(self, question: str, answer: str) -> dict:
        if not self.rag_ready:
            return {"error": "RAG ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„"}

        print(f"    (ë‹µë³€ ë¶„ì„ ì¤‘... ë©´ì ‘ê´€: {self.interviewer_mode})")

        try:
            web_result = google_search.search(queries=[f"{self.company_name} {answer}"])
            if not isinstance(web_result, str):
                web_result = json.dumps(web_result, ensure_ascii=False)[:2000]
        except Exception:
            web_result = "ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ"

        safe_answer = _escape_special_chars(answer)
        internal_check = self.rag_system.query(
            f"'{safe_answer}'ë¼ëŠ” ì£¼ì¥ì— ëŒ€í•œ ì‚¬ì‹¤ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì•„ì¤˜."
        )

        analysis_prompt = prompt_rag_answer_analysis.format(
            persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
            evaluation_focus=self.persona["evaluation_focus"],
            company_name=self.company_name,
            question=question,
            answer=answer,
            internal_check=internal_check,
            web_result=web_result,
        )

        raw_json = ""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Respond with ONLY a JSON object that strictly matches the intended structure. No prose, no code fences."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.2,
                max_tokens=2000,
            )
            raw_json = response.choices[0].message.content or ""
            result = safe_extract_json(raw_json)
            if result is not None:
                return result
            raise json.JSONDecodeError("Initial JSON parsing failed, attempting self-correction", raw_json, 0)

        except json.JSONDecodeError as e:
            _debug_print_raw_json("FIRST_PASS_FAILED", raw_json)
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ ({e}), AI ìê°€ êµì • ì‹œë„.")
            try:
                correction_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "Return ONLY valid JSON. No markdown or commentary."},
                        {"role": "user", "content": analysis_prompt},
                        {"role": "assistant", "content": raw_json},
                        {"role": "user", "content": prompt_rag_json_correction}
                    ],
                    temperature=0.0,
                    max_tokens=2000,
                )
                corrected_raw = correction_response.choices[0].message.content or ""
                final_result = safe_extract_json(corrected_raw)
                if final_result is not None:
                    return final_result
                _debug_print_raw_json("CORRECTION_PASS_FAILED", corrected_raw)
                raise json.JSONDecodeError("Failed to parse AI response after self-correction", corrected_raw, 0)
            except Exception as e_corr:
                print(f"âŒ ë‹µë³€ ë¶„ì„ ìµœì¢… ì‹¤íŒ¨: {e_corr}")
                traceback.print_exc()
                return {"error": f"Failed to parse AI response: {e_corr}"}
        except Exception as e_gen:
            print(f"âŒ ë‹µë³€ ë¶„ì„ ì‹¤íŒ¨ (ì¼ë°˜ ì˜¤ë¥˜): {e_gen}")
            traceback.print_exc()
            return {"error": f"Failed to analyze answer: {e_gen}"}

    # -----------------------------
    # ë¦¬í¬íŠ¸/ì¶œë ¥ (CLI)
    # -----------------------------
    def print_individual_analysis(self, analysis: dict, question_num: str):
        if "error" in analysis:
            print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
            return

        print("\n" + "=" * 70)
        print(f"ğŸ“Š [{question_num}] ë‹µë³€ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        print("=" * 70)

        print("\n" + "-" * 30)
        print("âœ… ì£¼ì¥ë³„ ì‚¬ì‹¤ í™•ì¸ (Fact-Checking)")
        checks = analysis.get("claims_checked", []) or analysis.get("fact_checking", [])
        if not checks:
            print("  - í™•ì¸ëœ ì£¼ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for c in checks:
                claim = c.get("claim", "N/A")
                verdict = c.get("verdict") or c.get("verification") or "N/A"
                src = c.get("evidence_source", "")
                rationale = c.get("rationale") or c.get("evidence") or "N/A"
                print(f'  - ì£¼ì¥: "{claim}"')
                print(f'    - íŒì •: {verdict} {f"({src})" if src else ""}')
                print(f'    - ê·¼ê±°: {rationale}')

        print("\n" + "-" * 30)
        print("ğŸ“ ë‚´ìš© ë¶„ì„ (Content Analysis)")
        summary = analysis.get("analysis", "")
        if not summary:
            ca = analysis.get("content_analysis", {})
            if isinstance(ca, dict):
                depth = ca.get("analytical_depth", {})
                insight = ca.get("strategic_insight", {})
                parts = []
                if isinstance(depth, dict):
                    parts.append(f"[ë¶„ì„ ê¹Šì´] {depth.get('assessment','N/A')}: {depth.get('comment','')}")
                if isinstance(insight, dict):
                    parts.append(f"[í†µì°°] {insight.get('assessment','N/A')}: {insight.get('comment','')}")
                summary = " / ".join([p for p in parts if p])
        print(f"  - ìš”ì•½: {summary or 'N/A'}")

        print("\n" + "-" * 30)
        print("ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°± (Actionable Feedback)")
        fb = analysis.get("feedback", "")
        if fb:
            print(f"  - {fb}")
        else:
            af = analysis.get("actionable_feedback", {})
            strengths = af.get("strengths", []) if isinstance(af, dict) else []
            sugg = af.get("suggestions_for_improvement", []) if isinstance(af, dict) else []
            if strengths:
                print("  - ê°•ì :")
                for s in strengths:
                    print(f"    âœ“ {s}")
            if sugg:
                print("  - ê°œì„  ì œì•ˆ:")
                for s in sugg:
                    print(f"    -> {s}")
            if not strengths and not sugg:
                print("  - í”¼ë“œë°± ì—†ìŒ")
        print("=" * 70)

    def generate_follow_up_question(self, original_question: str, answer: str, analysis: dict, stage: str, objective: str) -> str:
        try:
            suggestions_str = ""
            if isinstance(analysis, dict):
                if analysis.get("feedback"):
                    suggestions_str = analysis["feedback"]
                else:
                    af = analysis.get("actionable_feedback", {})
                    hints = []
                    if isinstance(af, dict):
                        hints += af.get("suggestions_for_improvement", [])
                        hints += af.get("strengths", [])
                    suggestions_str = ", ".join(hints[:5])

            prompt = prompt_rag_follow_up_question.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                company_name=self.company_name,
                original_question=original_question,
                answer=answer,
                suggestions=suggestions_str,
                stage=stage,
                objective=objective,
            )
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=300
            )
            result = safe_extract_json(response.choices[0].message.content)
            return (result or {}).get("follow_up_question", "")
        except Exception as e:
            print(f"âŒ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    # -----------------------------
    # CLI ì¸í„°ë·° ì‹œë‚˜ë¦¬ì˜¤
    # -----------------------------
    def conduct_interview(self):
        if not self.rag_ready:
            print("\nâŒ RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë©´ì ‘ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        resume_analysis = self.analyze_resume_with_rag()
        interview_plan_data = self.design_interview_plan()

        plan = (
            interview_plan_data.get("plan")
            or interview_plan_data.get("interview_plan")
            or (interview_plan_data if isinstance(interview_plan_data, list) else None)
        )
        if not plan:
            print("\nâŒ ë©´ì ‘ ê³„íšì„ ìˆ˜ë¦½í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        interview_plan = plan

        print("\n" + "=" * 70)
        print(f"ğŸ¢ {self.company_name} {self.job_title} ì§ë¬´ {self.interviewer_mode} ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")
        print("ë©´ì ‘ì€ ì´ 3ë‹¨ê³„ë¡œ êµ¬ì„±ë˜ë©°, ê° ë‹¨ê³„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.")
        print("ë©´ì ‘ì´ ì¢…ë£Œëœ í›„ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì´ ì œê³µë©ë‹ˆë‹¤.")
        print("=" * 70)

        interview_transcript = []
        interview_stopped = False

        for i, stage_data in enumerate(interview_plan, 1):
            stage_name = stage_data.get("stage", f"ë‹¨ê³„ {i}")
            objectives = stage_data.get("objectives") or stage_data.get("objective")
            if isinstance(objectives, list):
                stage_objective = objectives[0] if objectives else "N/A"
            else:
                stage_objective = objectives or "N/A"
            questions = stage_data.get("questions", [])

            print(f"\n\n--- ë©´ì ‘ ë‹¨ê³„ {i}: {stage_name} ---")
            print(f"ğŸ¯ ì´ë²ˆ ë‹¨ê³„ì˜ ëª©í‘œ: {stage_objective}")

            for q_idx, question in enumerate(questions, 1):
                question_id = f"{i}-{q_idx}"
                print(f"\n--- [ì§ˆë¬¸ {question_id}] ---")
                print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {question}")
                answer = input("ğŸ’¬ ë‹µë³€: ")

                if answer.lower() in ["/quit", "/ì¢…ë£Œ"]:
                    interview_stopped = True
                    break

                analysis = self.analyze_answer_with_rag(question, answer)
                follow_up_question = ""
                follow_up_answer = ""
                if "error" not in analysis:
                    follow_up_question = self.generate_follow_up_question(
                        original_question=question,
                        answer=answer,
                        analysis=analysis,
                        stage=stage_name,
                        objective=stage_objective
                    )
                    if follow_up_question:
                        print("\n--- [ê¼¬ë¦¬ ì§ˆë¬¸] ---")
                        print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {follow_up_question}")
                        follow_up_answer = input("ğŸ’¬ ë‹µë³€: ")

                interview_transcript.append({
                    "question_id": question_id,
                    "stage": stage_name,
                    "objective": stage_objective,
                    "question": question,
                    "answer": answer,
                    "analysis": analysis,
                    "follow_up_question": follow_up_question,
                    "follow_up_answer": follow_up_answer
                })

            if interview_stopped:
                break

        print("\nğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.")

        if interview_transcript:
            self._generate_and_print_reports(interview_transcript, interview_plan_data, resume_analysis)

    def _generate_and_print_reports(self, transcript, plan_data, resume_analysis):
        print("\n\n" + "#" * 70)
        print(" ë©´ì ‘ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸")
        print("#" * 70)

        for item in transcript:
            self.print_individual_analysis(item["analysis"], item["question_id"])

        report = self.generate_final_report(transcript, plan_data, resume_analysis)
        self.print_final_report(report)

    def generate_final_report(self, transcript: list, interview_plan: dict, resume_feedback_analysis: dict) -> dict:
        print("\n\n" + "#" * 70)
        print(f" ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... (ë©´ì ‘ê´€: {self.interviewer_mode})")
        print("#" * 70)

        try:
            conversation_summary = ""
            for item in transcript:
                q_id = item.get("question_id", "N/A")
                analysis_line = ""
                if isinstance(item.get("analysis"), dict):
                    analysis_line = item["analysis"].get("analysis", "")
                    if not analysis_line:
                        ca = item["analysis"].get("content_analysis", {})
                        if isinstance(ca, dict):
                            si = ca.get("strategic_insight", {})
                            if isinstance(si, dict):
                                analysis_line = si.get("assessment", "") or si.get("comment", "")

                conversation_summary += (
                    f"ì§ˆë¬¸ {q_id} ({item.get('stage', 'N/A')}): {item.get('question', '')}\n"
                    f"ë‹µë³€ {q_id}: {item.get('answer', '')[:200]}\n"
                    f"(ê°œë³„ ë¶„ì„ ìš”ì•½: {analysis_line or 'ë¶„ì„ ìš”ì•½ ì—†ìŒ'})\n---\n"
                )

            report_prompt = prompt_rag_final_report.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                final_report_goal=self.persona["final_report_goal"],
                company_name=self.company_name,
                job_title=self.job_title,
                conversation_summary=conversation_summary[:4000],
                interview_plan=json.dumps(interview_plan, ensure_ascii=False)[:4000],
                resume_feedback_analysis=json.dumps(resume_feedback_analysis, ensure_ascii=False)[:4000],
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": report_prompt}],
                temperature=0.3,
                max_tokens=4000,
            )
            report_data = safe_extract_json(response.choices[0].message.content)
            return report_data

        except Exception as e:
            print(f"âŒ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return {}

    def print_final_report(self, report: dict):
        if not report:
            return

        print("\n\n" + "=" * 70)
        print(f"ğŸ… {self.company_name} {self.job_title} ì§€ì›ì ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ (ê´€ì : {self.interviewer_mode})")
        print("=" * 70)

        print("\nâ–  ë©´ì ‘ ê³„íš ë‹¬ì„±ë„ í‰ê°€\n" + "-" * 50)
        print(report.get("assessment_of_plan_achievement", "í‰ê°€ ì •ë³´ ì—†ìŒ."))

        print("\nâ–  ì´í‰ (Overall Summary)\n" + "-" * 50)
        print(report.get("overall_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ."))

        print("\nâ–  í•µì‹¬ ì—­ëŸ‰ ë¶„ì„ (Core Competency Analysis)\n" + "-" * 50)
        for comp in report.get("core_competency_analysis", []):
            print(f"  - {comp.get('competency', 'N/A')}: **{comp.get('assessment', 'N/A')}**")
            print(f"    - ê·¼ê±°: {comp.get('evidence', 'N/A')}")

        print("\nâ–  ì„±ì¥ ê°€ëŠ¥ì„± (Growth Potential)\n" + "-" * 50)
        print(f"  {report.get('growth_potential', 'N/A')}")

        if "resume_feedback" in report:
            print("\nâ–  ì´ë ¥ì„œ í”¼ë“œë°± (Resume Feedback)\n" + "-" * 50)
            feedback = report.get("resume_feedback", {})
            if isinstance(feedback, dict):
                print(f"  - ì§ë¬´ ì í•©ì„±: {feedback.get('job_fit_assessment', 'N/A')}")
                print(f"  - ê°•ì  ë° ê¸°íšŒ: {feedback.get('strengths_and_opportunities', 'N/A')}")
                print(f"  - ê°œì„ ì : {feedback.get('gaps_and_improvements', 'N/A')}")
            else:
                print(f"  {feedback}")

        if "question_by_question_feedback" in report:
            print("\nâ–  ì§ˆë¬¸ë³„ ìƒì„¸ í”¼ë“œë°± (Question-by-Question Feedback)\n" + "-" * 50)
            for item in report.get("question_by_question_feedback", []):
                print(f"  - ì§ˆë¬¸: {item.get('question', 'N/A')}")
                print(f"    - ì§ˆë¬¸ ì˜ë„: {item.get('question_intent', 'N/A')}")
                evaluation = item.get("evaluation", {})
                if isinstance(evaluation, dict):
                    print(f"    - ì ìš©ëœ í”„ë ˆì„ì›Œí¬: {evaluation.get('applied_framework', 'N/A')}")
                    print(f"    - í”¼ë“œë°±: {evaluation.get('feedback', 'N/A')}")
                else:
                    print(f"    - í”¼ë“œë°±: {evaluation}")
                print("    " + "-" * 20)

        print("\n" + "=" * 70)


def main():
    try:
        target_container = "interview-data"
        company_name = input("ë©´ì ‘ì„ ì§„í–‰í•  íšŒì‚¬ ì´ë¦„ (ì˜ˆ: ê¸°ì•„): ")
        safe_company_name_for_index = unidecode(company_name.lower()).replace(" ", "-")
        index_name = f"{safe_company_name_for_index}-report-index"
        job_title = input("ì§€ì› ì§ë¬´ (ì˜ˆ: ìƒì‚° - ìƒì‚°ìš´ì˜ ë° ê³µì •ê¸°ìˆ ): ")
        difficulty = input("ë©´ì ‘ ë‚œì´ë„ (easy, normal, hard): ")
        interviewer_mode = input("ë©´ì ‘ê´€ ëª¨ë“œ (team_lead, executive): ")

        print("\n" + "-" * 40)
        print(f"ëŒ€ìƒ ì»¨í…Œì´ë„ˆ: {target_container}")
        print(f"íšŒì‚¬ ì´ë¦„: {company_name}")
        print(f"AI Search ì¸ë±ìŠ¤: {index_name}")
        print(f"ë‚œì´ë„: {difficulty}")
        print(f"ë©´ì ‘ê´€ ëª¨ë“œ: {interviewer_mode}")
        print("-" * 40)

        bot = RAGInterviewBot(
            company_name=company_name,
            job_title=job_title,
            container_name=target_container,
            index_name=index_name,
            difficulty=difficulty,
            interviewer_mode=interviewer_mode
        )
        bot.conduct_interview()

    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()
