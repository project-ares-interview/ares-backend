import os
import json
import sys
from openai import AzureOpenAI
from unidecode import unidecode
import re
import traceback

# RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from .new_azure_rag_llamaindex import AzureBlobRAGSystem
# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„í¬íŠ¸
from .tool_code import google_search


def _sanitize_json_object(text: str) -> str:
    """ëª¨ë¸ì´ ì„ì–´ ë³´ë‚¸ ë§ˆí¬ë‹¤ìš´/ìŠ¤ë§ˆíŠ¸ì¿¼íŠ¸/ëˆ„ë½ ì‰¼í‘œ ë“±ì„ ì •ë¦¬í•´ JSONì„ ê°•ì œë¡œ ì •ìƒí™”."""
    # ì½”ë“œíœìŠ¤/ë°±í‹± ì œê±°
    text = re.sub(r"```(?:json)?", "", text).replace("```", "")
    # ìŠ¤ë§ˆíŠ¸ ì¿¼íŠ¸ -> ASCII
    text = (
        text
        .replace("â€œ", '"').replace("â€", '"')
        .replace("â€˜", "'").replace("â€™", "'")
    )
    # ê°€ì¥ ë°”ê¹¥ {}ë§Œ ë‚¨ê¸°ê¸° (ë‹¨ìˆœ ê·¸ë¦¬ë””)
    m = re.search(r"\{.*\}", text, re.DOTALL)
    if m:
        text = m.group(0)

    # ì¤„ë°”ê¿ˆ ê²½ê³„ì—ì„œ ëˆ„ë½ëœ ì‰¼í‘œ ë³´ì •: ...}\n"key" â†’ ...},\n"key"
    text = re.sub(r'([}\]0-9eE"\\])\s*[\r\n]+\s*(")', r"\1,\n\2", text)

    # } "key" ì²˜ëŸ¼ ê³µë°±ë§Œ ìˆê³  ì½¤ë§ˆ ì—†ëŠ” ê²½ìš°: } "key" â†’ }"key"
    text = re.sub(r'([}\]])\s*(")', r'\1\2', text)

    # íŠ¸ë ˆì¼ë§ ì½¤ë§ˆ ì œê±°: , } ë˜ëŠ” , ] â†’ } ë˜ëŠ” ]
    text = re.sub(r",\s*([}\]])", r"\1", text)

    # True/False/None â†’ true/false/null (íŒŒì´ì¬ í‘œê¸° ë³´ì •)
    text = re.sub(r"\bTrue\b", "true", text)
    text = re.sub(r"\bFalse\b", "false", text)
    text = re.sub(r"\bNone\b", "null", text)
    return text.strip()


def _debug_print_raw_json(label: str, payload: str):
    """ë””ë²„ê¹… í¸ì˜ë¥¼ ìœ„í•œ ì›ë¬¸ ì¶œë ¥(ì„œë²„ ë¡œê·¸ì—ì„œ í™•ì¸). ê³¼í•˜ê²Œ ê¸¸ë©´ ì•/ë’¤ë§Œ."""
    try:
        head = payload[:800]
        tail = payload[-400:] if len(payload) > 1200 else ""
        print(f"\n--- {label} RAW JSON (len={len(payload)}) START ---\n{head}")
        if tail:
            print("\n... (snip) ...\n")
            print(tail)
        print(f"--- {label} RAW JSON END ---\n")
    except Exception:
        pass


def extract_json_from_response(text: str) -> str:
    """AIì˜ ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ìˆœìˆ˜í•œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ."""
    # 1) ì½”ë“œíœìŠ¤ ë‚´ JSON ìš°ì„ 
    m = re.search(r'```json\s*(\{.*\})\s*```', text, re.DOTALL)
    if m:
        return m.group(1)
    # 2) í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ í° JSON ê°ì²´(ê·¸ë¦¬ë””)
    m = re.search(r'\{.*\}', text, re.DOTALL)
    if m:
        return m.group(0)
    # 3) ì›ë¬¸ ë°˜í™˜ (ìµœí›„ì˜ ìˆ˜ë‹¨)
    return text


class RAGInterviewBot:
    """[ìµœì¢…] í‰ê°€ ê²°ê³¼ë¥¼ ë©´ì ‘ ì¢…ë£Œ í›„ ì¼ê´„ ì œê³µí•˜ëŠ” ë©´ì ‘ ì‹œìŠ¤í…œ"""

    def __init__(self, company_name: str, job_title: str, container_name: str, index_name: str):
        print("ğŸ¤– RAG ì „ìš© ì‚¬ì—… ë¶„ì„ ë©´ì ‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self.company_name = company_name
        self.job_title = job_title

        # API ë²„ì „ í‚¤ ì •í•©ì„±: AZURE_OPENAI_API_VERSION ìš°ì„ , ì—†ìœ¼ë©´ API_VERSION í´ë°±
        api_version = (
            os.getenv('AZURE_OPENAI_API_VERSION')
            or os.getenv('API_VERSION')
            or '2024-08-01-preview'
        )

        self.client = AzureOpenAI(
            azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),
            api_key=os.getenv('AZURE_OPENAI_KEY'),
            api_version=api_version,
        )
        # ë°°í¬/ëª¨ë¸ëª… í‚¤ í˜¸í™˜: MODEL â†’ DEPLOYMENT â†’ ê¸°ë³¸ê°’
        self.model = (
            os.getenv('AZURE_OPENAI_MODEL')
            or os.getenv('AZURE_OPENAI_DEPLOYMENT')
            or 'gpt-4o'
        )

        print("\nğŸ“Š Azure ì‚¬ì—… ë¶„ì„ RAG ì‹œìŠ¤í…œ ì—°ë™...")
        self.rag_system = None
        self.rag_ready = False
        try:
            self.rag_system = AzureBlobRAGSystem(container_name=container_name, index_name=index_name)

            blobs = list(self.rag_system.container_client.list_blobs())
            if not blobs:
                print(f"âš ï¸ ê²½ê³ : Azure Blob ì»¨í…Œì´ë„ˆ '{container_name}'ì— ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            print(f"âœ… Azure RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ. {len(blobs)}ê°œì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.")
            print("ğŸ”„ Azure AI Search ì¸ë±ìŠ¤ ìë™ ë™ê¸°í™” ì‹œì‘...")
            self.rag_system.sync_index(company_name_filter=self.company_name)
            self.rag_ready = True

        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨: {e}")

    def generate_questions(self, num_questions: int = 3) -> list:
        """RAG ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì—… í˜„í™© ì‹¬ì¸µ ì§ˆë¬¸ ìƒì„±"""
        if not self.rag_ready:
            return []
        print(f"\nğŸ§  {self.company_name} ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì¤‘...")
        try:
            business_info = self.rag_system.query(
                f"{self.company_name}ì˜ í•µì‹¬ ì‚¬ì—…, ìµœê·¼ ì‹¤ì , ì£¼ìš” ë¦¬ìŠ¤í¬ì— ëŒ€í•´ ìš”ì•½í•´ì¤˜."
            )

            prompt = f"""
ë‹¹ì‹ ì€ {self.company_name}ì˜ {self.job_title} ì§ë¬´ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì•„ë˜ì˜ ìµœì‹  ì‚¬ì—… í˜„í™© ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì˜ ë¶„ì„ë ¥ê³¼ ì „ëµì  ì‚¬ê³ ë¥¼ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ë‚ ì¹´ë¡œìš´ ì§ˆë¬¸ {num_questions}ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.

[ìµœì‹  ì‚¬ì—… ìš”ì•½]
{business_info}

ì˜ˆì‹œ í˜•ì‹:
{{ "questions": ["ìƒì„±ëœ ì§ˆë¬¸ 1", "ìƒì„±ëœ ì§ˆë¬¸ 2"] }}
            """

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.8,
            )
            result = json.loads(extract_json_from_response(response.choices[0].message.content))
            questions = result.get("questions", [])
            print(f"âœ… {len(questions)}ê°œì˜ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ.")
            return questions
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return [
                f"{self.company_name}ì˜ ì£¼ìš” ê²½ìŸì‚¬ì™€ ë¹„êµí–ˆì„ ë•Œ, ìš°ë¦¬ íšŒì‚¬ê°€ ê°€ì§„ í•µì‹¬ì ì¸ ê¸°ìˆ ì  ìš°ìœ„ëŠ” ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?"
            ]

    def analyze_answer_with_rag(self, question: str, answer: str) -> dict:
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (XAI ê¸°ë°˜, ì ìˆ˜ ì—†ìŒ)"""
        if not self.rag_ready:
            return {"error": "RAG ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„"}

        print("    (ë‹µë³€ ë¶„ì„ ì¤‘...)")

        # ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ì•ˆì „ ë³€í™˜
        try:
            web_result = google_search.search(queries=[f"{self.company_name} {answer}"])
            if not isinstance(web_result, str):
                web_result = json.dumps(web_result, ensure_ascii=False)[:2000]
        except Exception:
            web_result = "ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ"

        internal_check = self.rag_system.query(
            f"'{answer}'ë¼ëŠ” ì£¼ì¥ì— ëŒ€í•œ ì‚¬ì‹¤ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì•„ì¤˜."
        )

        analysis_prompt = f"""
ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì‚¬ì—… ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ìë£Œë¥¼ ì¢…í•©í•˜ì—¬ ì§€ì›ìì˜ ë‹µë³€ì„ ìƒì„¸íˆ í‰ê°€í•´ì£¼ì„¸ìš”.
'ë°ì´í„° ê¸°ë°˜ ì‚¬ì‹¤ ë¶„ì„'ê³¼ 'ë…ì°½ì ì¸ ì „ëµì  í†µì°°ë ¥'ì„ êµ¬ë¶„í•˜ì—¬ í‰ê°€í•˜ê³ , ì ìˆ˜ ëŒ€ì‹  ì„œìˆ í˜•ìœ¼ë¡œ í‰ê°€ ì˜ê²¬ì„ ì œì‹œí•˜ì„¸ìš”.

ë©´ì ‘ ì§ˆë¬¸: {question}
ì§€ì›ì ë‹µë³€: {answer}
---
[ìë£Œ 1] ë‚´ë¶€ ì‚¬ì—… ë°ì´í„°: {internal_check}
[ìë£Œ 2] ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ê²°ê³¼: {web_result}
---
í‰ê°€ ì§€ì¹¨:
1) ì£¼ì¥ë³„ ì‚¬ì‹¤ í™•ì¸: ì§€ì›ìì˜ í•µì‹¬ ì£¼ì¥ì„ 1~2ê°œ ë½‘ì•„ ìë£Œ 1, 2ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤.
2) ë‚´ìš© ë¶„ì„: ë°ì´í„° í™œìš© ëŠ¥ë ¥ê³¼ ë…ì°½ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë…¼ë¦¬ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
3) í”¼ë“œë°±: ê°•ì ê³¼ ê°œì„  ì œì•ˆì„ ì„œìˆ í•©ë‹ˆë‹¤.
        """

        # JSON ìŠ¤í‚¤ë§ˆ(ì•ˆë‚´ìš©, response_format ë¯¸ì‚¬ìš©)
        schema = {
            "name": "answer_analysis",
            "schema": {
                "type": "object",
                "properties": {
                    "fact_checking": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "claim": {"type": "string"},
                                "verification": {"type": "string"},
                                "evidence": {"type": "string"}
                            },
                            "required": ["claim", "verification", "evidence"],
                            "additionalProperties": False
                        }
                    },
                    "content_analysis": {
                        "type": "object",
                        "properties": {
                            "analytical_depth": {
                                "type": "object",
                                "properties": {
                                    "assessment": {"type": "string"},
                                    "comment": {"type": "string"}
                                },
                                "required": ["assessment", "comment"],
                                "additionalProperties": False
                            },
                            "strategic_insight": {
                                "type": "object",
                                "properties": {
                                    "assessment": {"type": "string"},
                                    "comment": {"type": "string"}
                                },
                                "required": ["assessment", "comment"],
                                "additionalProperties": False
                            }
                        },
                        "required": ["analytical_depth", "strategic_insight"],
                        "additionalProperties": False
                    },
                    "actionable_feedback": {
                        "type": "object",
                        "properties": {
                            "strengths": {"type": "array", "items": {"type": "string"}},
                            "suggestions_for_improvement": {"type": "array", "items": {"type": "string"}}
                        },
                        "required": ["strengths", "suggestions_for_improvement"],
                        "additionalProperties": False
                    }
                },
                "required": ["fact_checking", "content_analysis", "actionable_feedback"],
                "additionalProperties": False
            },
            "strict": True
        }

        raw_json = ""
        try:
            # 1ì°¨: JSON í˜•íƒœ ìœ ë„
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Respond with ONLY a JSON object that strictly matches the intended structure. No prose, no code fences."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.2,
                max_tokens=2000,
            )
            raw_json = response.choices[0].message.content or ""
            # ì¼ë¶€ SDKëŠ” dictë¡œ ì¤„ ìˆ˜ ìˆìŒ
            if isinstance(raw_json, dict):
                return raw_json

            # 1ë‹¨ê³„: ê·¸ëŒ€ë¡œ íŒŒì‹±
            try:
                return json.loads(raw_json)
            except json.JSONDecodeError:
                # 1.5ë‹¨ê³„: ì •ê·œí™” í›„ ì¬ì‹œë„
                sanitized = _sanitize_json_object(raw_json)
                return json.loads(sanitized)

        except json.JSONDecodeError as e:
            _debug_print_raw_json("FIRST_PASS", raw_json)
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, AI ìê°€ êµì • ì‹œë„. ì˜¤ë¥˜: {e}")

            correction_prompt = (
                "The previous output did not parse as JSON. Return ONLY a JSON object. "
                "Do not include code fences, markdown, or any explanation. Fix any missing commas or quotes."
            )

            try:
                # 2ì°¨: ìê°€ êµì •
                correction_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "Return ONLY valid JSON. No markdown or commentary."},
                        {"role": "user", "content": analysis_prompt},
                        {"role": "assistant", "content": raw_json},
                        {"role": "user", "content": correction_prompt}
                    ],
                    temperature=0.0,
                    max_tokens=2000,
                )
                corrected_raw = correction_response.choices[0].message.content or ""
                if isinstance(corrected_raw, dict):
                    return corrected_raw
                try:
                    return json.loads(corrected_raw)
                except json.JSONDecodeError:
                    sanitized = _sanitize_json_object(corrected_raw)
                    return json.loads(sanitized)

            except Exception as final_e:
                _debug_print_raw_json("CORRECTION_PASS", raw_json)
                print(f"âŒ ë‹µë³€ ë¶„ì„ ìµœì¢… ì‹¤íŒ¨ (ìˆ˜ì • í›„ì—ë„ ì˜¤ë¥˜): {final_e}")
                return {"error": f"Failed to parse AI response after self-correction: {final_e}"}

        except Exception as e:
            _debug_print_raw_json("UNEXPECTED_ERROR", raw_json)
            print(f"âŒ ë‹µë³€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def print_individual_analysis(self, analysis: dict, question_num: int):
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ í˜•ì‹"""
        if "error" in analysis:
            print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
            return

        print("\n" + "=" * 70)
        print(f"ğŸ“Š [ì§ˆë¬¸ {question_num}] ë‹µë³€ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        print("=" * 70)

        print("\n" + "-" * 30)
        print("âœ… ì£¼ì¥ë³„ ì‚¬ì‹¤ í™•ì¸ (Fact-Checking)")
        fact_checks = analysis.get("fact_checking", [])
        if not fact_checks:
            print("  - í™•ì¸ëœ ì£¼ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for check in fact_checks:
                print(f'  - ì£¼ì¥: "{check.get("claim", "N/A")}"')
                print(f"    - ê²€ì¦: {check.get('verification', 'N/A')}")
                print(f"    - ê·¼ê±°: {check.get('evidence', 'N/A')}")

        print("\n" + "-" * 30)
        print("ğŸ“ ë‚´ìš© ë¶„ì„ (Content Analysis)")
        content = analysis.get("content_analysis", {})
        depth = content.get("analytical_depth", {})
        insight = content.get("strategic_insight", {})
        print(f"  - ë°ì´í„° ë¶„ì„ ê¹Šì´: {depth.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {depth.get('comment', 'N/A')}")
        print(f"  - ì „ëµì  í†µì°°ë ¥: {insight.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {insight.get('comment', 'N/A')}")

        print("\n" + "-" * 30)
        print("ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°± (Actionable Feedback)")
        feedback = analysis.get("actionable_feedback", {})
        strengths = feedback.get("strengths", [])
        suggestions = feedback.get("suggestions_for_improvement", [])
        if strengths:
            print("  - ê°•ì :")
            for s in strengths:
                print(f"    âœ“ {s}")
        if suggestions:
            print("  - ê°œì„  ì œì•ˆ:")
            for s in suggestions:
                print(f"    -> {s}")
        print("=" * 70)

    def generate_follow_up_question(self, original_question: str, answer: str, analysis: dict) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±"""
        try:
            suggestions = analysis.get("actionable_feedback", {}).get("suggestions_for_improvement", [])
            prompt = (
                "ê¸°ì¡´ ì§ˆë¬¸: " + original_question + "\n"
                "ì§€ì›ì ë‹µë³€: " + answer + "\n"
                "ë‹µë³€ì— ëŒ€í•œ AI ë¶„ì„ ë‚´ìš©(ê°œì„  ì œì•ˆ): " + ", ".join(suggestions) + "\n\n"
                "ìœ„ ìƒí™©ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì˜ ë…¼ë¦¬ë¥¼ ë” ê¹Šê²Œ íŒŒê³ ë“¤ê¸° ìœ„í•œ í•µì‹¬ ê¼¬ë¦¬ ì§ˆë¬¸ 1ê°œë§Œ "
                "JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”. (ì˜ˆ: {\"follow_up_question\": \"ìƒì„±ëœ ê¼¬ë¦¬ ì§ˆë¬¸\"})"
            )
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=300
            )
            result = json.loads(extract_json_from_response(response.choices[0].message.content))
            return result.get("follow_up_question", "")
        except Exception as e:
            print(f"âŒ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    def conduct_interview(self):
        """[ìˆ˜ì •] í‰ê°€ ê²°ê³¼ëŠ” ë©´ì ‘ ì¢…ë£Œ í›„ ì¼ê´„ ì¶œë ¥"""
        if not self.rag_ready:
            print("\nâŒ RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë©´ì ‘ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        questions = self.generate_questions()
        if not questions:
            print("\nâŒ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        print("\n" + "=" * 70)
        print(f"ğŸ¢ {self.company_name} {self.job_title} ì§ë¬´ ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")
        print("ë©´ì ‘ì´ ì¢…ë£Œëœ í›„ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì´ ì œê³µë©ë‹ˆë‹¤.")
        print("=" * 70)

        interview_transcript = []

        for i, question in enumerate(questions, 1):
            print(f"\n--- [ì§ˆë¬¸ {i}/{len(questions)}] ---")
            print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {question}")
            answer = input("ğŸ’¬ ë‹µë³€: ")
            if answer.lower() in ['/quit', '/ì¢…ë£Œ']:
                break

            # [í•µì‹¬] í‰ê°€ëŠ” ìˆ˜í–‰í•˜ë˜, ê²°ê³¼ëŠ” ì¶œë ¥í•˜ì§€ ì•Šê³  ì €ì¥ë§Œ í•¨
            analysis = self.analyze_answer_with_rag(question, answer)

            follow_up_question = ""
            follow_up_answer = ""
            if "error" not in analysis:
                follow_up_question = self.generate_follow_up_question(question, answer, analysis)
                if follow_up_question:
                    print(f"\n--- [ê¼¬ë¦¬ ì§ˆë¬¸] ---")
                    print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {follow_up_question}")
                    follow_up_answer = input("ğŸ’¬ ë‹µë³€: ")

            # í˜„ì¬ ì§ˆë¬¸, ë‹µë³€, ë¶„ì„ ë‚´ìš©, ê¼¬ë¦¬ ì§ˆë¬¸/ë‹µë³€ì„ ëª¨ë‘ ê¸°ë¡
            interview_transcript.append({
                "question_num": i,
                "question": question,
                "answer": answer,
                "analysis": analysis,
                "follow_up_question": follow_up_question,
                "follow_up_answer": follow_up_answer
            })

        print("\nğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.")

        # [í•µì‹¬] ë©´ì ‘ ì¢…ë£Œ í›„, ì €ì¥ëœ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¼ê´„ ì¶œë ¥
        if interview_transcript:
            print("\n\n" + "#" * 70)
            print(" ë©´ì ‘ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸")
            print("#" * 70)

            # 1. ê°œë³„ ë‹µë³€ ë¶„ì„ ê²°ê³¼ë¶€í„° ìˆœì„œëŒ€ë¡œ ì¶œë ¥
            for item in interview_transcript:
                self.print_individual_analysis(item['analysis'], item['question_num'])

            # 2. ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥ (ëˆ„ë½ ë³´ì™„)
            report = self.generate_final_report(interview_transcript)
            self.print_final_report(report)

    def generate_final_report(self, transcript: list, resume_context: str = "") -> dict:
        """ë©´ì ‘ ì „ì²´ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n\n" + "#" * 70)
        print(" ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        print("#" * 70)

        try:
            # ë©´ì ‘ ì „ì²´ ëŒ€í™” ë‚´ìš©ê³¼ ê°œë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬
            conversation_summary = ""
            for item in transcript:
                q_num = item['question_num']
                analysis_assessment = (
                    item['analysis']
                    .get('content_analysis', {})
                    .get('strategic_insight', {})
                    .get('assessment', 'ë¶„ì„ ë¯¸ì™„ë£Œ')
                    if isinstance(item.get('analysis'), dict) else 'ë¶„ì„ ë¯¸ì™„ë£Œ'
                )
                conversation_summary += (
                    f"ì§ˆë¬¸ {q_num}: {item['question']}\n"
                    f"ë‹µë³€ {q_num}: {item['answer']}\n"
                    f"(ê°œë³„ ë¶„ì„ ìš”ì•½: {analysis_assessment})\n---\n"
                )

            report_prompt = f"""
ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì±„ìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì „ì²´ ë©´ì ‘ ëŒ€í™” ë° ê°œë³„ ë¶„ì„ ìš”ì•½ì„ ì¢…í•©í•˜ê³ , ì œê³µëœ ì´ë ¥ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì— ëŒ€í•œ 'ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ìë£Œ] ë©´ì ‘ ì „ì²´ ìš”ì•½:
{conversation_summary}
---
[ìë£Œ] ì§€ì›ì ì´ë ¥ì„œ ë‚´ìš©:
{resume_context if resume_context else "ì œê³µëœ ì´ë ¥ì„œ ë‚´ìš© ì—†ìŒ."}---
ë¦¬í¬íŠ¸ ì‘ì„± ì§€ì¹¨:
1) ì¢…í•© ì´í‰: ì§€ì›ìì˜ ì¼ê´€ì„±, ê°•ì , ì•½ì ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… í‰ê°€ë¥¼ ë‚´ë¦½ë‹ˆë‹¤.
2) í•µì‹¬ ì—­ëŸ‰ ë¶„ì„: {self.job_title} ì§ë¬´ì— í•„ìš”í•œ í•µì‹¬ ì—­ëŸ‰(ì˜ˆ: ë¬¸ì œ í•´ê²° ëŠ¥ë ¥, ë¹„ì¦ˆë‹ˆìŠ¤ ì´í•´ë„, ê¸°ìˆ  ì „ë¬¸ì„±) 3ê°€ì§€ë¥¼ ì‹ë³„í•˜ê³ , ë©´ì ‘ ì „ì²´ ë‚´ìš©ì„ ê·¼ê±°ë¡œ [ìµœìƒ], [ìƒ], [ì¤‘], [í•˜]ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ê° í‰ê°€ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
3) ì„±ì¥ ê°€ëŠ¥ì„±: ë©´ì ‘ ê³¼ì •ì—ì„œ ë³´ì¸ íƒœë„ë‚˜ ë‹µë³€ì˜ ê¹Šì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ ì ì¬ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
4) ì´ë ¥ì„œ í”¼ë“œë°±: ì œê³µëœ ì´ë ¥ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì§ë¬´ ì í•©ì„±, ê°•ì , ê°œì„ ì  ë“±ì— ëŒ€í•œ í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤.

ì‘ë‹µ í˜•ì‹(JSONë§Œ ë°˜í™˜):
{{
  "overall_summary": "ì¢…í•©ì ì¸ í‰ê°€ ìš”ì•½...",
  "core_competency_analysis": [
    {{"competency": "í•µì‹¬ ì—­ëŸ‰ 1", "assessment": "[í‰ê°€ ë“±ê¸‰]", "evidence": "íŒë‹¨ ê·¼ê±°..."}}
  ],
  "growth_potential": "ì§€ì›ìì˜ ì„±ì¥ ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì½”ë©˜íŠ¸...",
  "resume_feedback": "ì´ë ¥ì„œ ë‚´ìš©ì— ëŒ€í•œ í”¼ë“œë°±..."
}}
            """

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": report_prompt}],
                temperature=0.3,
                max_tokens=3000,
            )
            report_data = json.loads(extract_json_from_response(response.choices[0].message.content))
            return report_data

        except Exception as e:
            print(f"âŒ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return {}

    def print_final_report(self, report: dict):
        """ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ì¶œë ¥"""
        if not report:
            return

        print("\n\n" + "=" * 70)
        print(f"ğŸ… {self.company_name} {self.job_title} ì§€ì›ì ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸")
        print("=" * 70)

        print("\nâ–  ì´í‰ (Overall Summary)\n" + "-" * 50)
        print(report.get("overall_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ."))

        print("\nâ–  í•µì‹¬ ì—­ëŸ‰ ë¶„ì„ (Core Competency Analysis)\n" + "-" * 50)
        for comp in report.get("core_competency_analysis", []):
            print(f"  - {comp.get('competency', 'N/A')}: **{comp.get('assessment', 'N/A')}**")
            print(f"    - ê·¼ê±°: {comp.get('evidence', 'N/A')}")

        print("\nâ–  ì„±ì¥ ê°€ëŠ¥ì„± (Growth Potential)\n" + "-" * 50)
        print(f"  {report.get('growth_potential', 'N/A')}")

        if "resume_feedback" in report:
            print("\nâ–  ì´ë ¥ì„œ í”¼ë“œë°± (Resume Feedback)\n" + "-" * 50)
            print(f"  {report.get('resume_feedback', 'N/A')}")
        print("\n" + "=" * 70)


def main():
    try:
        target_container = 'interview-data'
        company_name = input("ë©´ì ‘ì„ ì§„í–‰í•  íšŒì‚¬ ì´ë¦„ (ì˜ˆ: SKí•˜ì´ë‹‰ìŠ¤): ")
        safe_company_name_for_index = unidecode(company_name.lower()).replace(' ', '-')
        index_name = f"{safe_company_name_for_index}-report-index"
        job_title = input("ì§€ì› ì§ë¬´ (ì˜ˆ: ì‚¬ì—…ë¶„ì„ê°€): ")

        print("\n" + "-" * 40)
        print(f"ëŒ€ìƒ ì»¨í…Œì´ë„ˆ: {target_container}")
        print(f"íšŒì‚¬ ì´ë¦„: {company_name}")
        print(f"AI Search ì¸ë±ìŠ¤: {index_name}")
        print("-" * 40)

        bot = RAGInterviewBot(
            company_name=company_name,
            job_title=job_title,
            container_name=target_container,
            index_name=index_name
        )
        bot.conduct_interview()

    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()
