import json
import traceback

from openai import AzureOpenAI
from unidecode import unidecode

from django.conf import settings

# RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from .new_azure_rag_llamaindex import AzureBlobRAGSystem
# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„í¬íŠ¸
from .tool_code import google_search
# [ìˆ˜ì •] INTERVIEWER_PERSONASë¥¼ prompt.pyì—ì„œ ì§ì ‘ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from ares.api.services.prompt import (
    INTERVIEWER_PERSONAS,
    prompt_interview_designer,
    DIFFICULTY_INSTRUCTIONS,
    prompt_resume_analyzer,
    prompt_rag_answer_analysis,
    prompt_rag_json_correction,
    prompt_rag_follow_up_question,
    prompt_rag_final_report,
)
from ares.api.utils.ai_utils import safe_extract_json


def _debug_print_raw_json(label: str, payload: str):
    """ë””ë²„ê¹… í¸ì˜ë¥¼ ìœ„í•œ ì›ë¬¸ ì¶œë ¥(ì„œë²„ ë¡œê·¸ì—ì„œ í™•ì¸). ê³¼í•˜ê²Œ ê¸¸ë©´ ì•/ë’¤ë§Œ."""
    try:
        head = payload[:800]
        tail = payload[-400:] if len(payload) > 1200 else ""
        print(f"\n--- {label} RAW JSON (len={len(payload)}) START ---\n{head}")
        if tail:
            print("\n... (snip) ...\n")
            print(tail)
        print(f"--- {label} RAW JSON END ---\n")
    except Exception:
        pass


class RAGInterviewBot:
    """[ìµœì¢…] í‰ê°€ ê²°ê³¼ë¥¼ ë©´ì ‘ ì¢…ë£Œ í›„ ì¼ê´„ ì œê³µí•˜ëŠ” ë©´ì ‘ ì‹œìŠ¤í…œ"""

    def __init__(
        self,
        company_name: str,
        job_title: str,
        container_name: str,
        index_name: str,
        difficulty: str = "normal",
        interviewer_mode: str = "team_lead",  # [ì¶”ê°€] ë©´ì ‘ê´€ ëª¨ë“œ íŒŒë¼ë¯¸í„°
        ncs_context: dict | None = None,
        jd_context: str = "",
        resume_context: str = "",
        research_context: str = "",
        **kwargs,
    ):
        print(f"ğŸ¤– RAG ì „ìš© ì‚¬ì—… ë¶„ì„ ë©´ì ‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë©´ì ‘ê´€: {interviewer_mode})...")
        self.company_name = company_name
        self.job_title = job_title
        self.difficulty = difficulty
        self.interviewer_mode = interviewer_mode  # [ì¶”ê°€] ë©´ì ‘ê´€ ëª¨ë“œ ì €ì¥
        self.ncs_context = ncs_context or {}
        self.jd_context = jd_context
        self.resume_context = resume_context
        self.research_context = research_context

        # [ì¶”ê°€] ì„ íƒëœ í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ self.personaì— ì €ì¥
        self.persona = INTERVIEWER_PERSONAS.get(self.interviewer_mode, INTERVIEWER_PERSONAS["team_lead"])

        # API ì •ë³´ ë¡œë“œ (Django settings ì‚¬ìš©)
        self.endpoint = getattr(settings, "AZURE_OPENAI_ENDPOINT", None)
        self.api_key = getattr(settings, "AZURE_OPENAI_KEY", None)
        self.api_version = (
            getattr(settings, "AZURE_OPENAI_API_VERSION", None)
            or getattr(settings, "API_VERSION", None)
            or "2024-08-01-preview"
        )
        self.model = (
            getattr(settings, "AZURE_OPENAI_MODEL", None)
            or getattr(settings, "AZURE_OPENAI_DEPLOYMENT", None)
            or "gpt-4o"
        )

        if not self.endpoint or not self.api_key:
            raise ValueError("Azure OpenAI endpoint/key is not set in Django settings.")

        self.client = AzureOpenAI(
            azure_endpoint=self.endpoint,
            api_key=self.api_key,
            api_version=self.api_version,
        )

        print("\nğŸ“Š Azure ì‚¬ì—… ë¶„ì„ RAG ì‹œìŠ¤í…œ ì—°ë™...")
        self.rag_system = None
        self.rag_ready = False
        try:
            self.rag_system = AzureBlobRAGSystem(container_name=container_name, index_name=index_name)

            blobs = list(self.rag_system.container_client.list_blobs())
            if not blobs:
                print(f"âš ï¸ ê²½ê³ : Azure Blob ì»¨í…Œì´ë„ˆ '{container_name}'ì— ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            print(f"âœ… Azure RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ. {len(blobs)}ê°œì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.")
            print("ğŸ”„ Azure AI Search ì¸ë±ìŠ¤ ìë™ ë™ê¸°í™” ì‹œì‘...")
            self.rag_system.sync_index(company_name_filter=self.company_name)
            self.rag_ready = True

        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨: {e}")

    def design_interview_plan(self) -> dict:
        """RAG ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë©´ì ‘ ê³„íš ìƒì„±"""
        if not self.rag_ready:
            return {}
        print(f"\nğŸ§  {self.company_name} ë§ì¶¤ ë©´ì ‘ ê³„íš ì„¤ê³„ ì¤‘ (ë‚œì´ë„: {self.difficulty}, ë©´ì ‘ê´€: {self.interviewer_mode})...")
        try:
            business_info = self.rag_system.query(
                f"{self.company_name}ì˜ í•µì‹¬ ì‚¬ì—…, ìµœê·¼ ì‹¤ì , ì£¼ìš” ë¦¬ìŠ¤í¬, ê·¸ë¦¬ê³  {self.job_title} ì§ë¬´ì™€ ê´€ë ¨ëœ íšŒì‚¬ ì •ë³´ì— ëŒ€í•´ ìš”ì•½í•´ì¤˜."
            )

            ncs_info = ""
            if self.ncs_context.get("ncs"):
                ncs_titles = [item.get("title") for item in self.ncs_context["ncs"] if item.get("title")]
                if ncs_titles:
                    ncs_info = f"\n\nNCS ì§ë¬´ ê´€ë ¨ ì •ë³´: {', '.join(ncs_titles)}."

            difficulty_instruction = DIFFICULTY_INSTRUCTIONS.get(self.difficulty, "")

            # [ìˆ˜ì •] í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ formatì— ì¶”ê°€
            prompt = prompt_interview_designer.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                question_style_guide=self.persona["question_style_guide"],
                company_name=self.company_name,
                job_title=self.job_title,
                difficulty_instruction=difficulty_instruction,
                business_info=business_info,
                jd_context=self.jd_context,
                resume_context=self.resume_context,
                research_context=self.research_context,
                ncs_info=ncs_info,
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=2000,
                temperature=0.8,
            )
            result = safe_extract_json(response.choices[0].message.content)
            print("âœ… êµ¬ì¡°í™” ë©´ì ‘ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ.")
            return result
        except Exception as e:
            print(f"âŒ ë©´ì ‘ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            return {}

    def analyze_resume_with_rag(self) -> dict:
        """RAGë¥¼ í™œìš©í•˜ì—¬ ì´ë ¥ì„œì™€ íšŒì‚¬ ì •ë³´ì˜ ì—°ê´€ì„± ë¶„ì„"""
        if not self.rag_ready or not self.resume_context:
            return {}
        print(f"\nğŸ“„ RAG ê¸°ë°˜ ì´ë ¥ì„œ ë¶„ì„ ì¤‘ (ë©´ì ‘ê´€: {self.interviewer_mode})...")
        try:
            business_info = self.rag_system.query(
                f"{self.company_name}ì˜ í•µì‹¬ ì‚¬ì—…, ìµœê·¼ ì‹¤ì , ì£¼ìš” ë¦¬ìŠ¤í¬, ê·¸ë¦¬ê³  {self.job_title} ì§ë¬´ì™€ ê´€ë ¨ëœ íšŒì‚¬ ì •ë³´ì— ëŒ€í•´ ìš”ì•½í•´ì¤˜."
            )

            # [ìˆ˜ì •] í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ formatì— ì¶”ê°€
            prompt = prompt_resume_analyzer.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                company_name=self.company_name,
                job_title=self.job_title,
                business_info=business_info,
                resume_context=self.resume_context,
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1500,
                temperature=0.5,
            )
            result = safe_extract_json(response.choices[0].message.content)
            print("âœ… ì´ë ¥ì„œ-íšŒì‚¬ ì—°ê´€ì„± ë¶„ì„ ì™„ë£Œ.")
            return result
        except Exception as e:
            print(f"âŒ ì´ë ¥ì„œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def analyze_answer_with_rag(self, question: str, answer: str) -> dict:
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (XAI ê¸°ë°˜, ì ìˆ˜ ì—†ìŒ)"""
        if not self.rag_ready:
            return {"error": "RAG ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„"}

        print(f"     (ë‹µë³€ ë¶„ì„ ì¤‘... ë©´ì ‘ê´€: {self.interviewer_mode})")

        try:
            web_result = google_search.search(queries=[f"{self.company_name} {answer}"])
            if not isinstance(web_result, str):
                web_result = json.dumps(web_result, ensure_ascii=False)[:2000]
        except Exception:
            web_result = "ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ"

        internal_check = self.rag_system.query(
            f"'{answer}'ë¼ëŠ” ì£¼ì¥ì— ëŒ€í•œ ì‚¬ì‹¤ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì•„ì¤˜."
        )

        # [ìˆ˜ì •] í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ formatì— ì¶”ê°€
        analysis_prompt = prompt_rag_answer_analysis.format(
            persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
            evaluation_focus=self.persona["evaluation_focus"],
            company_name=self.company_name,
            question=question,
            answer=answer,
            internal_check=internal_check,
            web_result=web_result,
        )

        raw_json = ""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Respond with ONLY a JSON object that strictly matches the intended structure. No prose, no code fences."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.2,
                max_tokens=2000,
            )
            raw_json = response.choices[0].message.content or ""

            result = safe_extract_json(raw_json)
            if result is not None:
                return result
            raise json.JSONDecodeError("Initial JSON parsing failed, attempting self-correction", raw_json, 0)

        except json.JSONDecodeError as e:
            _debug_print_raw_json("FIRST_PASS_FAILED", raw_json)
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ ({e}), AI ìê°€ êµì • ì‹œë„.")

            correction_prompt = prompt_rag_json_correction
            try:
                correction_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "Return ONLY valid JSON. No markdown or commentary."},
                        {"role": "user", "content": analysis_prompt},
                        {"role": "assistant", "content": raw_json},
                        {"role": "user", "content": correction_prompt}
                    ],
                    temperature=0.0,
                    max_tokens=2000,
                )
                corrected_raw = correction_response.choices[0].message.content or ""
                final_result = safe_extract_json(corrected_raw)

                if final_result is not None:
                    return final_result
                _debug_print_raw_json("CORRECTION_PASS_FAILED", corrected_raw)
                raise json.JSONDecodeError("Failed to parse AI response after self-correction", corrected_raw, 0)

            except Exception as e:
                print(f"âŒ ë‹µë³€ ë¶„ì„ ìµœì¢… ì‹¤íŒ¨: {e}")
                traceback.print_exc()
                return {"error": f"Failed to parse AI response: {e}"}

        except Exception as e:
            print(f"âŒ ë‹µë³€ ë¶„ì„ ì‹¤íŒ¨ (ì¼ë°˜ ì˜¤ë¥˜): {e}")
            traceback.print_exc()
            return {"error": f"Failed to analyze answer: {e}"}

    def print_individual_analysis(self, analysis: dict, question_num: str):
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ í˜•ì‹"""
        if "error" in analysis:
            print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
            return

        print("\n" + "=" * 70)
        print(f"ğŸ“Š [{question_num}] ë‹µë³€ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        print("=" * 70)

        print("\n" + "-" * 30)
        print("âœ… ì£¼ì¥ë³„ ì‚¬ì‹¤ í™•ì¸ (Fact-Checking)")
        fact_checks = analysis.get("fact_checking", [])
        if not fact_checks:
            print("  - í™•ì¸ëœ ì£¼ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for check in fact_checks:
                print(f'  - ì£¼ì¥: "{check.get("claim", "N/A")}"')
                print(f"    - ê²€ì¦: {check.get('verification', 'N/A')}")
                print(f"    - ê·¼ê±°: {check.get('evidence', 'N/A')}")

        print("\n" + "-" * 30)
        print("ğŸ“ ë‚´ìš© ë¶„ì„ (Content Analysis)")
        content = analysis.get("content_analysis", {})
        depth = content.get("analytical_depth", {})
        insight = content.get("strategic_insight", {})
        print(f"  - ë°ì´í„° ë¶„ì„ ê¹Šì´: {depth.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {depth.get('comment', 'N/A')}")
        print(f"  - ì „ëµì  í†µì°°ë ¥: {insight.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {insight.get('comment', 'N/A')}")

        print("\n" + "-" * 30)
        print("ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°± (Actionable Feedback)")
        feedback = analysis.get("actionable_feedback", {})
        strengths = feedback.get("strengths", [])
        suggestions = feedback.get("suggestions_for_improvement", [])
        if strengths:
            print("  - ê°•ì :")
            for s in strengths:
                print(f"    âœ“ {s}")
        if suggestions:
            print("  - ê°œì„  ì œì•ˆ:")
            for s in suggestions:
                print(f"    -> {s}")
        print("=" * 70)

    def generate_follow_up_question(self, original_question: str, answer: str, analysis: dict, stage: str, objective: str) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±"""
        try:
            suggestions = analysis.get("actionable_feedback", {}).get("suggestions_for_improvement", [])

            # [ìˆ˜ì •] í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ formatì— ì¶”ê°€
            prompt = prompt_rag_follow_up_question.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                company_name=self.company_name,
                original_question=original_question,
                answer=answer,
                suggestions=", ".join(suggestions),
                stage=stage,
                objective=objective,
            )
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=300
            )
            result = safe_extract_json(response.choices[0].message.content)
            return result.get("follow_up_question", "")
        except Exception as e:
            print(f"âŒ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    def conduct_interview(self):
        """êµ¬ì¡°í™”ëœ ë©´ì ‘ ê³„íšì— ë”°ë¼ ë©´ì ‘ ì§„í–‰"""
        if not self.rag_ready:
            print("\nâŒ RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë©´ì ‘ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ë©´ì ‘ ì‹œì‘ ì „, ì´ë ¥ì„œ ë¶„ì„ ì„ í–‰
        resume_analysis = self.analyze_resume_with_rag()

        interview_plan_data = self.design_interview_plan()
        if not interview_plan_data or "interview_plan" not in interview_plan_data:
            print("\nâŒ ë©´ì ‘ ê³„íšì„ ìˆ˜ë¦½í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        interview_plan = interview_plan_data.get("interview_plan", [])

        print("\n" + "=" * 70)
        print(f"ğŸ¢ {self.company_name} {self.job_title} ì§ë¬´ {self.interviewer_mode} ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")
        print("ë©´ì ‘ì€ ì´ 3ë‹¨ê³„ë¡œ êµ¬ì„±ë˜ë©°, ê° ë‹¨ê³„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.")
        print("ë©´ì ‘ì´ ì¢…ë£Œëœ í›„ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì´ ì œê³µë©ë‹ˆë‹¤.")
        print("=" * 70)

        interview_transcript = []
        question_counter = 0

        for i, stage_data in enumerate(interview_plan, 1):
            stage_name = stage_data.get("stage", f"ë‹¨ê³„ {i}")
            stage_objective = stage_data.get("objective", "N/A")
            questions = stage_data.get("questions", [])

            print(f"\n\n--- ë©´ì ‘ ë‹¨ê³„ {i}: {stage_name} ---")
            print(f"ğŸ¯ ì´ë²ˆ ë‹¨ê³„ì˜ ëª©í‘œ: {stage_objective}")

            for q_idx, question in enumerate(questions, 1):
                question_counter += 1
                question_id = f"{i}-{q_idx}"

                print(f"\n--- [ì§ˆë¬¸ {question_id}] ---")
                print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {question}")
                answer = input("ğŸ’¬ ë‹µë³€: ")
                if answer.lower() in ["/quit", "/ì¢…ë£Œ"]:
                    break

                analysis = self.analyze_answer_with_rag(question, answer)

                follow_up_question = ""
                follow_up_answer = ""
                if "error" not in analysis:
                    follow_up_question = self.generate_follow_up_question(
                        original_question=question,
                        answer=answer,
                        analysis=analysis,
                        stage=stage_name,
                        objective=stage_objective
                    )
                    if follow_up_question:
                        print("\n--- [ê¼¬ë¦¬ ì§ˆë¬¸] ---")
                        print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {follow_up_question}")
                        follow_up_answer = input("ğŸ’¬ ë‹µë³€: ")

                interview_transcript.append({
                    "question_id": question_id,
                    "stage": stage_name,
                    "objective": stage_objective,
                    "question": question,
                    "answer": answer,
                    "analysis": analysis,
                    "follow_up_question": follow_up_question,
                    "follow_up_answer": follow_up_answer
                })

            if answer.lower() in ["/quit", "/ì¢…ë£Œ"]:
                break

        print("\nğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.")

        if interview_transcript:
            print("\n\n" + "#" * 70)
            print(" ë©´ì ‘ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸")
            print("#" * 70)

            for item in interview_transcript:
                self.print_individual_analysis(item["analysis"], item["question_id"])

            report = self.generate_final_report(interview_transcript, interview_plan_data, resume_analysis)
            self.print_final_report(report)

    def generate_final_report(self, transcript: list, interview_plan: dict, resume_feedback_analysis: dict) -> dict:
        """ë©´ì ‘ ì „ì²´ ê¸°ë¡ê³¼ ê³„íš, ì´ë ¥ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n\n" + "#" * 70)
        print(f" ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... (ë©´ì ‘ê´€: {self.interviewer_mode})")
        print("#" * 70)

        try:
            conversation_summary = ""
            for item in transcript:
                q_id = item.get("question_id", "N/A")
                analysis_assessment = "ë¶„ì„ ë¯¸ì™„ë£Œ"
                if isinstance(item.get("analysis"), dict):
                    content_analysis = item["analysis"].get("content_analysis", {})
                    if isinstance(content_analysis, dict):
                         strategic_insight = content_analysis.get("strategic_insight", {})
                         if isinstance(strategic_insight, dict):
                            analysis_assessment = strategic_insight.get("assessment", "ë¶„ì„ ë¯¸ì™„ë£Œ")

                conversation_summary += (
                    f"ì§ˆë¬¸ {q_id} ({item.get('stage', 'N/A')}): {item.get('question', '')}\n"
                    f"ë‹µë³€ {q_id}: {item.get('answer', '')}\n"
                    f"(ê°œë³„ ë¶„ì„ ìš”ì•½: {analysis_assessment})\n---\n"
                )

            # [ìˆ˜ì •] í˜ë¥´ì†Œë‚˜ ì •ë³´ë¥¼ formatì— ì¶”ê°€
            report_prompt = prompt_rag_final_report.format(
                persona_description=self.persona["persona_description"].format(company_name=self.company_name, job_title=self.job_title),
                final_report_goal=self.persona["final_report_goal"],
                company_name=self.company_name,
                job_title=self.job_title,
                conversation_summary=conversation_summary,
                interview_plan=json.dumps(interview_plan, ensure_ascii=False),
                resume_feedback_analysis=json.dumps(resume_feedback_analysis, ensure_ascii=False),
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": report_prompt}],
                temperature=0.3,
                max_tokens=4000,
            )
            report_data = safe_extract_json(response.choices[0].message.content)
            return report_data

        except Exception as e:
            print(f"âŒ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return {}

    def print_final_report(self, report: dict):
        """ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ì¶œë ¥"""
        if not report:
            return

        print("\n\n" + "=" * 70)
        print(f"ğŸ… {self.company_name} {self.job_title} ì§€ì›ì ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ (ê´€ì : {self.interviewer_mode})")
        print("=" * 70)

        print("\nâ–  ë©´ì ‘ ê³„íš ë‹¬ì„±ë„ í‰ê°€\n" + "-" * 50)
        print(report.get("assessment_of_plan_achievement", "í‰ê°€ ì •ë³´ ì—†ìŒ."))

        print("\nâ–  ì´í‰ (Overall Summary)\n" + "-" * 50)
        print(report.get("overall_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ."))

        print("\nâ–  í•µì‹¬ ì—­ëŸ‰ ë¶„ì„ (Core Competency Analysis)\n" + "-" * 50)
        for comp in report.get("core_competency_analysis", []):
            print(f"  - {comp.get('competency', 'N/A')}: **{comp.get('assessment', 'N/A')}**")
            print(f"    - ê·¼ê±°: {comp.get('evidence', 'N/A')}")

        print("\nâ–  ì„±ì¥ ê°€ëŠ¥ì„± (Growth Potential)\n" + "-" * 50)
        print(f"  {report.get('growth_potential', 'N/A')}")

        if "resume_feedback" in report:
            print("\nâ–  ì´ë ¥ì„œ í”¼ë“œë°± (Resume Feedback)\n" + "-" * 50)
            feedback = report.get("resume_feedback", {})
            if isinstance(feedback, dict):
                print(f"  - ì§ë¬´ ì í•©ì„±: {feedback.get('job_fit_assessment', 'N/A')}")
                print(f"  - ê°•ì  ë° ê¸°íšŒ: {feedback.get('strengths_and_opportunities', 'N/A')}")
                print(f"  - ê°œì„ ì : {feedback.get('gaps_and_improvements', 'N/A')}")
            else:
                 print(f"  {feedback}")

        if "question_by_question_feedback" in report:
            print("\nâ–  ì§ˆë¬¸ë³„ ìƒì„¸ í”¼ë“œë°± (Question-by-Question Feedback)\n" + "-" * 50)
            for item in report.get("question_by_question_feedback", []):
                print(f"  - ì§ˆë¬¸: {item.get('question', 'N/A')}")
                print(f"    - ì§ˆë¬¸ ì˜ë„: {item.get('question_intent', 'N/A')}")
                evaluation = item.get("evaluation", {})
                if isinstance(evaluation, dict):
                    print(f"    - ì ìš©ëœ í”„ë ˆì„ì›Œí¬: {evaluation.get('applied_framework', 'N/A')}")
                    print(f"    - í”¼ë“œë°±: {evaluation.get('feedback', 'N/A')}")
                else:
                    print(f"    - í”¼ë“œë°±: {evaluation}")
                print("    " + "-" * 20)

        print("\n" + "=" * 70)


def main():
    try:
        target_container = "interview-data"
        company_name = input("ë©´ì ‘ì„ ì§„í–‰í•  íšŒì‚¬ ì´ë¦„ (ì˜ˆ: ê¸°ì•„): ")
        safe_company_name_for_index = unidecode(company_name.lower()).replace(" ", "-")
        index_name = f"{safe_company_name_for_index}-report-index"
        job_title = input("ì§€ì› ì§ë¬´ (ì˜ˆ: ìƒì‚° - ìƒì‚°ìš´ì˜ ë° ê³µì •ê¸°ìˆ ): ")
        difficulty = input("ë©´ì ‘ ë‚œì´ë„ (easy, normal, hard): ")
        # [ì¶”ê°€] main í•¨ìˆ˜ì—ì„œ ë©´ì ‘ê´€ ëª¨ë“œë¥¼ ì…ë ¥ë°›ìŒ
        interviewer_mode = input("ë©´ì ‘ê´€ ëª¨ë“œ (team_lead, executive): ")

        print("\n" + "-" * 40)
        print(f"ëŒ€ìƒ ì»¨í…Œì´ë„ˆ: {target_container}")
        print(f"íšŒì‚¬ ì´ë¦„: {company_name}")
        print(f"AI Search ì¸ë±ìŠ¤: {index_name}")
        print(f"ë‚œì´ë„: {difficulty}")
        print(f"ë©´ì ‘ê´€ ëª¨ë“œ: {interviewer_mode}") # [ì¶”ê°€]
        print("-" * 40)

        # [ìˆ˜ì •] RAGInterviewBot ìƒì„± ì‹œ interviewer_mode ì „ë‹¬
        bot = RAGInterviewBot(
            company_name=company_name,
            job_title=job_title,
            container_name=target_container,
            index_name=index_name,
            difficulty=difficulty,
            interviewer_mode=interviewer_mode
        )
        bot.conduct_interview()

    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()
