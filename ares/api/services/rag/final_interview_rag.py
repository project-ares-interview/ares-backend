import json
import sys
from openai import AzureOpenAI
from unidecode import unidecode
import re
import traceback

from django.conf import settings

# RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from .new_azure_rag_llamaindex import AzureBlobRAGSystem
# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„í¬íŠ¸
from .tool_code import google_search
from ares.api.services.prompt import (
    prompt_rag_question_generation,
    prompt_rag_answer_analysis,
    prompt_rag_json_correction,
    prompt_rag_follow_up_question,
    prompt_rag_final_report,
)
from ares.api.utils.ai_utils import safe_extract_json


def _debug_print_raw_json(label: str, payload: str):
    """ë””ë²„ê¹… í¸ì˜ë¥¼ ìœ„í•œ ì›ë¬¸ ì¶œë ¥(ì„œë²„ ë¡œê·¸ì—ì„œ í™•ì¸). ê³¼í•˜ê²Œ ê¸¸ë©´ ì•/ë’¤ë§Œ."""
    try:
        head = payload[:800]
        tail = payload[-400:] if len(payload) > 1200 else ""
        print(f"\n--- {label} RAW JSON (len={len(payload)}) START ---\n{head}")
        if tail:
            print("\n... (snip) ...\n")
            print(tail)
        print(f"--- {label} RAW JSON END ---\n")
    except Exception:
        pass


class RAGInterviewBot:
    """[ìµœì¢…] í‰ê°€ ê²°ê³¼ë¥¼ ë©´ì ‘ ì¢…ë£Œ í›„ ì¼ê´„ ì œê³µí•˜ëŠ” ë©´ì ‘ ì‹œìŠ¤í…œ"""

    def __init__(
        self,
        company_name: str,
        job_title: str,
        container_name: str,
        index_name: str,
        ncs_context: dict | None = None,
        jd_context: str = "",
        resume_context: str = "",
        research_context: str = "",
        **kwargs,
    ):
        print("ğŸ¤– RAG ì „ìš© ì‚¬ì—… ë¶„ì„ ë©´ì ‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self.company_name = company_name
        self.job_title = job_title
        self.ncs_context = ncs_context or {}
        self.jd_context = jd_context
        self.resume_context = resume_context
        self.research_context = research_context

        # API ì •ë³´ ë¡œë“œ (Django settings ì‚¬ìš©)
        self.endpoint = getattr(settings, 'AZURE_OPENAI_ENDPOINT', None)
        self.api_key = getattr(settings, 'AZURE_OPENAI_KEY', None)
        self.api_version = (
            getattr(settings, "AZURE_OPENAI_API_VERSION", None)
            or getattr(settings, "API_VERSION", None)
            or "2024-08-01-preview"
        )
        self.model = (
            getattr(settings, "AZURE_OPENAI_MODEL", None)
            or getattr(settings, "AZURE_OPENAI_DEPLOYMENT", None)
            or "gpt-4o"
        )

        if not self.endpoint or not self.api_key:
            raise ValueError("Azure OpenAI endpoint/key is not set in Django settings.")

        self.client = AzureOpenAI(
            azure_endpoint=self.endpoint,
            api_key=self.api_key,
            api_version=self.api_version,
        )

        print("\nğŸ“Š Azure ì‚¬ì—… ë¶„ì„ RAG ì‹œìŠ¤í…œ ì—°ë™...")
        self.rag_system = None
        self.rag_ready = False
        try:
            self.rag_system = AzureBlobRAGSystem(container_name=container_name, index_name=index_name)

            blobs = list(self.rag_system.container_client.list_blobs())
            if not blobs:
                print(f"âš ï¸ ê²½ê³ : Azure Blob ì»¨í…Œì´ë„ˆ '{container_name}'ì— ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            print(f"âœ… Azure RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ. {len(blobs)}ê°œì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.")
            print("ğŸ”„ Azure AI Search ì¸ë±ìŠ¤ ìë™ ë™ê¸°í™” ì‹œì‘...")
            self.rag_system.sync_index(company_name_filter=self.company_name)
            self.rag_ready = True

        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨: {e}")

    def generate_questions(self, num_questions: int = 3) -> list:
        """RAG ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì—… í˜„í™© ì‹¬ì¸µ ì§ˆë¬¸ ìƒì„±"""
        if not self.rag_ready:
            return []
        print(f"\nğŸ§  {self.company_name} ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì¤‘...")
        try:
            # RAG ì¿¼ë¦¬ë¥¼ ì§ë¬´ì™€ ê´€ë ¨ëœ íšŒì‚¬ ì •ë³´ì— ì´ˆì ì„ ë§ì¶”ë„ë¡ ìˆ˜ì •
            business_info = self.rag_system.query(
                f"{self.company_name}ì˜ í•µì‹¬ ì‚¬ì—…, ìµœê·¼ ì‹¤ì , ì£¼ìš” ë¦¬ìŠ¤í¬, ê·¸ë¦¬ê³  {self.job_title} ì§ë¬´ì™€ ê´€ë ¨ëœ íšŒì‚¬ ì •ë³´ì— ëŒ€í•´ ìš”ì•½í•´ì¤˜."
            )

            # NCS ì»¨í…ìŠ¤íŠ¸ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€í•˜ì—¬ ì§ë¬´ ê´€ë ¨ì„±ì„ ë†’ì„
            ncs_info = ""
            if self.ncs_context.get("ncs"):
                ncs_titles = [item.get("title") for item in self.ncs_context["ncs"] if item.get("title")]
                if ncs_titles:
                    ncs_info = f"\n\n[NCS ì§ë¬´ ê´€ë ¨ ì •ë³´]\nì´ ì§ë¬´ëŠ” ë‹¤ìŒ NCS ì—­ëŸ‰ê³¼ ê´€ë ¨ì´ ê¹ŠìŠµë‹ˆë‹¤: {', '.join(ncs_titles)}."

            prompt = prompt_rag_question_generation.format(
                company_name=self.company_name,
                job_title=self.job_title,
                num_questions=num_questions,
                business_info=business_info,
                jd_context=self.jd_context,
                resume_context=self.resume_context,
                research_context=self.research_context,
                ncs_info=ncs_info,
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.8,
            )
            result = safe_extract_json(response.choices[0].message.content)
            questions = result.get("questions", [])
            print(f"âœ… {len(questions)}ê°œì˜ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ.")
            return questions
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return [
                f"{self.company_name}ì˜ ì£¼ìš” ê²½ìŸì‚¬ì™€ ë¹„êµí–ˆì„ ë•Œ, ìš°ë¦¬ íšŒì‚¬ê°€ ê°€ì§„ í•µì‹¬ì ì¸ ê¸°ìˆ ì  ìš°ìœ„ëŠ” ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?"
            ]

    def analyze_answer_with_rag(self, question: str, answer: str) -> dict:
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (XAI ê¸°ë°˜, ì ìˆ˜ ì—†ìŒ)"""
        if not self.rag_ready:
            return {"error": "RAG ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„"}

        print("     (ë‹µë³€ ë¶„ì„ ì¤‘...)")

        try:
            # ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ì•ˆì „ ë³€í™˜
            web_result = google_search.search(queries=[f"{self.company_name} {answer}"])
            if not isinstance(web_result, str):
                web_result = json.dumps(web_result, ensure_ascii=False)[:2000]
        except Exception:
            web_result = "ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ"

        internal_check = self.rag_system.query(
            f"'{answer}'ë¼ëŠ” ì£¼ì¥ì— ëŒ€í•œ ì‚¬ì‹¤ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì•„ì¤˜."
        )

        analysis_prompt = prompt_rag_answer_analysis.format(
            question=question,
            answer=answer,
            internal_check=internal_check,
            web_result=web_result,
        )

        raw_json = ""
        try:
            # 1ì°¨: JSON í˜•íƒœ ìœ ë„
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Respond with ONLY a JSON object that strictly matches the intended structure. No prose, no code fences."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.2,
                max_tokens=2000,
            )
            raw_json = response.choices[0].message.content or ""
            
            result = safe_extract_json(raw_json)
            if result is not None:
                return result
            else:
                # safe_extract_jsonì´ Noneì„ ë°˜í™˜í–ˆì„ ê²½ìš°, ì¶”ê°€ ì²˜ë¦¬
                raise json.JSONDecodeError("Initial JSON parsing failed, attempting self-correction", raw_json, 0)
        
        except json.JSONDecodeError as e:
            _debug_print_raw_json("FIRST_PASS_FAILED", raw_json)
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ ({e}), AI ìê°€ êµì • ì‹œë„.")

            correction_prompt = prompt_rag_json_correction
            try:
                # 2ì°¨: ìê°€ êµì •
                correction_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "Return ONLY valid JSON. No markdown or commentary."},
                        {"role": "user", "content": analysis_prompt},
                        {"role": "assistant", "content": raw_json},
                        {"role": "user", "content": correction_prompt}
                    ],
                    temperature=0.0,
                    max_tokens=2000,
                )
                corrected_raw = correction_response.choices[0].message.content or ""
                final_result = safe_extract_json(corrected_raw)

                if final_result is not None:
                    return final_result
                else:
                    _debug_print_raw_json("CORRECTION_PASS_FAILED", corrected_raw)
                    raise json.JSONDecodeError("Failed to parse AI response after self-correction", corrected_raw, 0)

            except Exception as e:
                print(f"âŒ ë‹µë³€ ë¶„ì„ ìµœì¢… ì‹¤íŒ¨: {e}")
                traceback.print_exc()
                return {"error": f"Failed to parse AI response: {e}"}

        except Exception as e:
            print(f"âŒ ë‹µë³€ ë¶„ì„ ì‹¤íŒ¨ (ì¼ë°˜ ì˜¤ë¥˜): {e}")
            traceback.print_exc()
            return {"error": f"Failed to analyze answer: {e}"}

    def print_individual_analysis(self, analysis: dict, question_num: int):
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ í˜•ì‹"""
        if "error" in analysis:
            print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
            return

        print("\n" + "=" * 70)
        print(f"ğŸ“Š [ì§ˆë¬¸ {question_num}] ë‹µë³€ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        print("=" * 70)

        print("\n" + "-" * 30)
        print("âœ… ì£¼ì¥ë³„ ì‚¬ì‹¤ í™•ì¸ (Fact-Checking)")
        fact_checks = analysis.get("fact_checking", [])
        if not fact_checks:
            print("  - í™•ì¸ëœ ì£¼ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for check in fact_checks:
                print(f'  - ì£¼ì¥: "{check.get("claim", "N/A")}"')
                print(f"    - ê²€ì¦: {check.get('verification', 'N/A')}")
                print(f"    - ê·¼ê±°: {check.get('evidence', 'N/A')}")

        print("\n" + "-" * 30)
        print("ğŸ“ ë‚´ìš© ë¶„ì„ (Content Analysis)")
        content = analysis.get("content_analysis", {})
        depth = content.get("analytical_depth", {})
        insight = content.get("strategic_insight", {})
        print(f"  - ë°ì´í„° ë¶„ì„ ê¹Šì´: {depth.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {depth.get('comment', 'N/A')}")
        print(f"  - ì „ëµì  í†µì°°ë ¥: {insight.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {insight.get('comment', 'N/A')}")

        print("\n" + "-" * 30)
        print("ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°± (Actionable Feedback)")
        feedback = analysis.get("actionable_feedback", {})
        strengths = feedback.get("strengths", [])
        suggestions = feedback.get("suggestions_for_improvement", [])
        if strengths:
            print("  - ê°•ì :")
            for s in strengths:
                print(f"    âœ“ {s}")
        if suggestions:
            print("  - ê°œì„  ì œì•ˆ:")
            for s in suggestions:
                print(f"    -> {s}")
        print("=" * 70)

    def generate_follow_up_question(self, original_question: str, answer: str, analysis: dict) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±"""
        try:
            suggestions = analysis.get("actionable_feedback", {}).get("suggestions_for_improvement", [])
            prompt = prompt_rag_follow_up_question.format(
                original_question=original_question,
                answer=answer,
                suggestions=", ".join(suggestions),
            )
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=300
            )
            result = safe_extract_json(response.choices[0].message.content)
            return result.get("follow_up_question", "")
        except Exception as e:
            print(f"âŒ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    def conduct_interview(self):
        """[ìˆ˜ì •] í‰ê°€ ê²°ê³¼ëŠ” ë©´ì ‘ ì¢…ë£Œ í›„ ì¼ê´„ ì¶œë ¥"""
        if not self.rag_ready:
            print("\nâŒ RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë©´ì ‘ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        questions = self.generate_questions()
        if not questions:
            print("\nâŒ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        print("\n" + "=" * 70)
        print(f"ğŸ¢ {self.company_name} {self.job_title} ì§ë¬´ ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")
        print("ë©´ì ‘ì´ ì¢…ë£Œëœ í›„ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì´ ì œê³µë©ë‹ˆë‹¤.")
        print("=" * 70)

        interview_transcript = []

        for i, question in enumerate(questions, 1):
            print(f"\n--- [ì§ˆë¬¸ {i}/{len(questions)}] ---")
            print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {question}")
            answer = input("ğŸ’¬ ë‹µë³€: ")
            if answer.lower() in ["/quit", "/ì¢…ë£Œ"]:
                break

            # [í•µì‹¬] í‰ê°€ëŠ” ìˆ˜í–‰í•˜ë˜, ê²°ê³¼ëŠ” ì¶œë ¥í•˜ì§€ ì•Šê³  ì €ì¥ë§Œ í•¨
            analysis = self.analyze_answer_with_rag(question, answer)

            follow_up_question = ""
            follow_up_answer = ""
            if "error" not in analysis:
                follow_up_question = self.generate_follow_up_question(question, answer, analysis)
                if follow_up_question:
                    print(f"\n--- [ê¼¬ë¦¬ ì§ˆë¬¸] ---")
                    print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {follow_up_question}")
                    follow_up_answer = input("ğŸ’¬ ë‹µë³€: ")

            # í˜„ì¬ ì§ˆë¬¸, ë‹µë³€, ë¶„ì„ ë‚´ìš©, ê¼¬ë¦¬ ì§ˆë¬¸/ë‹µë³€ì„ ëª¨ë‘ ê¸°ë¡
            interview_transcript.append({
                "question_num": i,
                "question": question,
                "answer": answer,
                "analysis": analysis,
                "follow_up_question": follow_up_question,
                "follow_up_answer": follow_up_answer
            })

        print("\nğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.")

        # [í•µì‹¬] ë©´ì ‘ ì¢…ë£Œ í›„, ì €ì¥ëœ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¼ê´„ ì¶œë ¥
        if interview_transcript:
            print("\n\n" + "#" * 70)
            print(" ë©´ì ‘ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸")
            print("#" * 70)

            # 1. ê°œë³„ ë‹µë³€ ë¶„ì„ ê²°ê³¼ë¶€í„° ìˆœì„œëŒ€ë¡œ ì¶œë ¥
            for item in interview_transcript:
                self.print_individual_analysis(item["analysis"], item["question_num"])

            # 2. ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥ (ëˆ„ë½ ë³´ì™„)
            report = self.generate_final_report(interview_transcript)
            self.print_final_report(report)

    def generate_final_report(self, transcript: list, resume_context: str = "") -> dict:
        """ë©´ì ‘ ì „ì²´ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n\n" + "#" * 70)
        print(" ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        print("#" * 70)

        try:
            # ë©´ì ‘ ì „ì²´ ëŒ€í™” ë‚´ìš©ê³¼ ê°œë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬
            conversation_summary = ""
            for item in transcript:
                q_num = item["question_num"]
                analysis_assessment = (
                    item["analysis"]
                    .get("content_analysis", {})
                    .get("strategic_insight", {})
                    .get("assessment", "ë¶„ì„ ë¯¸ì™„ë£Œ")
                    if isinstance(item.get("analysis"), dict) else "ë¶„ì„ ë¯¸ì™„ë£Œ"
                )
                conversation_summary += (
                    f"ì§ˆë¬¸ {q_num}: {item['question']}\n"
                    f"ë‹µë³€ {q_num}: {item['answer']}\n"
                    f"(ê°œë³„ ë¶„ì„ ìš”ì•½: {analysis_assessment})\n---\n"
                )

            report_prompt = prompt_rag_final_report.format(
                conversation_summary=conversation_summary,
                resume_context=resume_context if resume_context else "ì œê³µëœ ì´ë ¥ì„œ ë‚´ìš© ì—†ìŒ.",
                job_title=self.job_title,
            )

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": report_prompt}],
                temperature=0.3,
                max_tokens=3000,
            )
            report_data = safe_extract_json(response.choices[0].message.content)
            return report_data

        except Exception as e:
            print(f"âŒ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()
            return {}

    def print_final_report(self, report: dict):
        """ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ì¶œë ¥"""
        if not report:
            return

        print("\n\n" + "=" * 70)
        print(f"ğŸ… {self.company_name} {self.job_title} ì§€ì›ì ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸")
        print("=" * 70)

        print("\nâ–  ì´í‰ (Overall Summary)\n" + "-" * 50)
        print(report.get("overall_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ."))

        print("\nâ–  í•µì‹¬ ì—­ëŸ‰ ë¶„ì„ (Core Competency Analysis)\n" + "-" * 50)
        for comp in report.get("core_competency_analysis", []):
            print(f"  - {comp.get('competency', 'N/A')}: **{comp.get('assessment', 'N/A')}**")
            print(f"    - ê·¼ê±°: {comp.get('evidence', 'N/A')}")

        print("\nâ–  ì„±ì¥ ê°€ëŠ¥ì„± (Growth Potential)\n" + "-" * 50)
        print(f"  {report.get('growth_potential', 'N/A')}")

        if "resume_feedback" in report:
            print("\nâ–  ì´ë ¥ì„œ í”¼ë“œë°± (Resume Feedback)\n" + "-" * 50)
            print(f"  {report.get('resume_feedback', 'N/A')}")
        print("\n" + "=" * 70)


def main():
    try:
        target_container = "interview-data"
        company_name = input("ë©´ì ‘ì„ ì§„í–‰í•  íšŒì‚¬ ì´ë¦„ (ì˜ˆ: SKí•˜ì´ë‹‰ìŠ¤): ")
        safe_company_name_for_index = unidecode(company_name.lower()).replace(" ", "-")
        index_name = f"{safe_company_name_for_index}-report-index"
        job_title = input("ì§€ì› ì§ë¬´ (ì˜ˆ: ì‚¬ì—…ë¶„ì„ê°€): ")

        print("\n" + "-" * 40)
        print(f"ëŒ€ìƒ ì»¨í…Œì´ë„ˆ: {target_container}")
        print(f"íšŒì‚¬ ì´ë¦„: {company_name}")
        print(f"AI Search ì¸ë±ìŠ¤: {index_name}")
        print("-" * 40)

        bot = RAGInterviewBot(
            company_name=company_name,
            job_title=job_title,
            container_name=target_container,
            index_name=index_name
        )
        bot.conduct_interview()

    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()


if __name__ == "__main__":
    main()