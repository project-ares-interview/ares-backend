# ares/api/services/rag/final_interview_rag.py
from __future__ import annotations

"""
RAG Interview Bot (Facade)

- Base(ê³µí†µ ì´ˆê¸°í™”/ì €ìˆ˜ì¤€ API), Planner(ê³„íš), Analyzer(í‰ê°€/ê¼¬ë¦¬ì§ˆë¬¸), Reporter(ìµœì¢… ë¦¬í¬íŠ¸)ë¥¼
  í•˜ë‚˜ì˜ íŒŒì‚¬ë“œ í´ë˜ìŠ¤ë¡œ ë¬¶ì–´ Django Viewì—ì„œ ì‚¬ìš©í•˜ê¸° ì‰½ê²Œ í•©ë‹ˆë‹¤.

ì£¼ì˜:
- PlannerëŠ” {"interview_plan":[...]} í˜•íƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
- FacadeëŠ” ì–¸ì œë‚˜ "í‘œì¤€ ìŠ¤í‚¤ë§ˆ" ìƒíƒœ(self.plan)ì— ë³´ê´€í•˜ê¸° ìœ„í•´ normalizeë¥¼ ì ìš©í•©ë‹ˆë‹¤.
"""

import json
import random
from typing import Any, Dict, List, Optional

from ares.api.services.prompts import (
    prompt_identifier,
    prompt_extractor,
    prompt_scorer,
    prompt_coach,
    prompt_model_answer,
    prompt_intent_classifier,
    prompt_rag_answer_analysis,
)
from ares.api.services.company_data import get_company_description
from .bot.base import RAGBotBase
from .bot.planner import InterviewPlanner
from .bot.analyzer import AnswerAnalyzer
from .bot.reporter import ReportGenerator
from .bot.base import RAGBotBase
from .bot.planner import InterviewPlanner
from .bot.analyzer import AnswerAnalyzer
from .bot.reporter import ReportGenerator
from .bot.utils import (
    normalize_interview_plan,
    extract_first_main_question,
    _truncate,
)

class RAGInterviewBot:
    def __init__(
        self,
        company_name: str,
        job_title: str,
        difficulty: str = "normal",
        interviewer_mode: str = "team_lead",
        ncs_context: Optional[dict] = None,
        jd_context: str = "",
        resume_context: str = "",
        research_context: str = "",
        **kwargs,
    ):
        self.base = RAGBotBase(
            company_name=company_name,
            job_title=job_title,
            difficulty=difficulty,
            interviewer_mode=interviewer_mode,
            ncs_context=ncs_context,
            jd_context=jd_context,
            resume_context=resume_context,
            research_context=research_context,
            **kwargs,
        )
        self.planner = InterviewPlanner(self.base)
        self.analyzer = AnswerAnalyzer(self.base)
        self.reporter = ReportGenerator(self.base)

        # í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³´ê´€ë˜ëŠ” í˜„ì¬ ê³„íš
        # {"icebreakers":[...], "stages":[{title, questions:[{id,text,followups:[]}, ...]}]}
        self.plan: Dict[str, Any] = {"icebreakers": [], "stages": []}
        self.transcript: List[Dict[str, Any]] = []

    # -----------------------------
    # Plan (ì„¤ê³„)
    # -----------------------------
    def design_interview_plan(self) -> Dict[str, Any]:
        """
        Plannerì˜ ê²°ê³¼({"interview_plan":[...]})ë¥¼ ë°›ì•„ ì›ë³¸ê³¼ ì •ê·œí™”ëœ ë²„ì „ì„ ëª¨ë‘ í¬í•¨í•˜ì—¬ ë°˜í™˜
        """
        raw_plan = self.planner.design_interview_plan()  # e.g., {"interview_plan": [...], "icebreakers": [...]}
        
        # normalize_interview_plan í•¨ìˆ˜ê°€ ì•„ì´ìŠ¤ë¸Œë ˆì´ì»¤ ë¶„ë¦¬/ì²˜ë¦¬ë¥¼ ëª¨ë‘ ë‹´ë‹¹
        normalized_plan = normalize_interview_plan(raw_plan or {})

        # self.planì—ëŠ” ì •ê·œí™”ëœ ê³„íšì„ ì €ì¥í•˜ì—¬ ê¸°ì¡´ ë¡œì§ í˜¸í™˜ì„± ìœ ì§€
        self.plan = normalized_plan

        # Viewì—ì„œ ë‘ ê°€ì§€ ë²„ì „ì„ ëª¨ë‘ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ dict í˜•íƒœë¡œ ë°˜í™˜
        return {
            "raw_v2_plan": raw_plan,
            "normalized_plan": normalized_plan
        }

    def _get_opening_statement(self) -> str:
        """ë©´ì ‘ê´€ ëª¨ë“œì™€ í…œí”Œë¦¿ ì¡°í•©ì— ë”°ë¼ ë™ì ì¸ ì²« ì¸ì‚¬ë§ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        
        # --- 1. ê¸°ë³¸ ì¸ì‚¬ í…œí”Œë¦¿ ---
        greeting_templates = [
            f"ì•ˆë…•í•˜ì„¸ìš”, {self.base.company_name} {self.base.job_title} ì§ë¬´ ë©´ì ‘ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.",
            f"ë°˜ê°‘ìŠµë‹ˆë‹¤. {self.base.company_name} {self.base.job_title} ì§ë¬´ ë©´ì ‘ì— ì°¸ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.",
            f"{self.base.company_name} {self.base.job_title} ì§ë¬´ ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ê·€í•œ ì‹œê°„ ë‚´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.",
        ]
        
        # --- 2. ë©´ì ‘ê´€ ì†Œê°œ í…œí”Œë¦¿ (ëª¨ë“œë³„) ---
        mode_templates = {
            "team_lead": [
                "ì €ëŠ” í•´ë‹¹ ì§ë¬´ì˜ íŒ€ì¥ì…ë‹ˆë‹¤.",
                "ì˜¤ëŠ˜ ì‹¤ë¬´ ì—­ëŸ‰ì— ëŒ€í•´ í•¨ê»˜ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆŒ íŒ€ì¥ì…ë‹ˆë‹¤.",
                "ì €ëŠ” ì§€ì›í•˜ì‹  íŒ€ì˜ ë¦¬ë”ë¡œì„œ, ì˜¤ëŠ˜ ë©´ì ‘ì„ ì§„í–‰í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.",
            ],
            "executive": [
                "ì €ëŠ” ì„ì› ë©´ì ‘ì„ ë‹´ë‹¹í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                "ì˜¤ëŠ˜ ìµœì¢… ë©´ì ‘ì„ ì§„í–‰í•  ì„ì›ì…ë‹ˆë‹¤.",
                "ìš°ë¦¬ ì¡°ì§ê³¼ì˜ ì í•©ì„±ì„ í™•ì¸í•˜ê¸° ìœ„í•´ ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì—¬í•œ ì„ì›ì…ë‹ˆë‹¤.",
            ],
            "default": [
                "ì˜¤ëŠ˜ ë©´ì ‘ì„ ì§„í–‰í•  ë©´ì ‘ê´€ì…ë‹ˆë‹¤.",
            ]
        }
        
        # --- 3. í™˜ì˜ ë° ë¶„ìœ„ê¸° ì¡°ì„± í…œí”Œë¦¿ ---
        welcome_templates = [
            "ì˜¤ëŠ˜ ë©´ì ‘ì€ í¸ì•ˆí•œ ë¶„ìœ„ê¸°ì—ì„œ ì§„í–‰ë  ì˜ˆì •ì´ë‹ˆ, ê¸´ì¥ í‘¸ì‹œê³  ë³¸ì¸ì˜ ê²½í—˜ì„ ì†”ì§í•˜ê²Œ ë§ì”€í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.",
            "ì´ ìë¦¬ëŠ” í‰ê°€ì˜ ì‹œê°„ì´ë¼ê¸°ë³´ë‹¤, ì„œë¡œì— ëŒ€í•´ ì•Œì•„ê°€ëŠ” ê³¼ì •ì´ë¼ ìƒê°í•´ì£¼ì‹œë©´ ì¢‹ê² ìŠµë‹ˆë‹¤. í¸ì•ˆí•˜ê²Œ ì„í•´ì£¼ì„¸ìš”.",
            "ì§€ì›ìë‹˜ê»˜ì„œ ê°€ì§„ ì—­ëŸ‰ê³¼ ê²½í—˜ì„ ì¶©ë¶„íˆ ë“¤ì„ ìˆ˜ ìˆë„ë¡ ê²½ì²­í•˜ê² ìŠµë‹ˆë‹¤. ì†”ì§í•˜ê³  í¸ì•ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.",
            "ë‹µë³€ì´ ì¡°ê¸ˆ ê¸¸ì–´ì ¸ë„ ê´œì°®ìœ¼ë‹ˆ, ë³¸ì¸ì˜ ìƒê°ì„ ì¶©ë¶„íˆ ë§ì”€í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.",
        ]

        # --- 4. í…œí”Œë¦¿ ë¬´ì‘ìœ„ ì¡°í•© ---
        base_greeting = random.choice(greeting_templates)
        
        introduction_pool = mode_templates.get(self.base.interviewer_mode, mode_templates["default"])
        mode_specific_line = random.choice(introduction_pool)
        
        warm_welcome = random.choice(welcome_templates)
        
        # ìµœì¢… ì¸ì‚¬ë§ ì¡°í•©
        return f"{base_greeting} {mode_specific_line} {warm_welcome}"

    def get_first_question(self) -> Dict[str, Any]:
        """
        ì¸ì‚¬ë§ê³¼ í•¨ê»˜ ë™ì ìœ¼ë¡œ ìƒì„±ëœ ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹ ì§ˆë¬¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ í´ë°± ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        opening_statement = self._get_opening_statement()
        icebreaker_text = ""

        try:
            # í…œí”Œë¦¿ ê¸°ë°˜ì˜ ê°€ë²¼ìš´ ì§ˆë¬¸ì„ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©
            icebreaker_text = random.choice(ICEBREAK_TEMPLATES_KO)
        except Exception:
            # í…œí”Œë¦¿ ì‚¬ìš© ì‹¤íŒ¨ ì‹œ LLM í˜¸ì¶œë¡œ í´ë°±
            try:
                icebreaker_text = make_icebreak_question_llm_or_template(self.base._chat_json)
            except Exception:
                # LLM í˜¸ì¶œë„ ì‹¤íŒ¨í•˜ë©´ ìµœì¢… í´ë°±
                icebreaker_text = "ì˜¤ëŠ˜ ë©´ì ‘ ë³´ëŸ¬ ì˜¤ì‹œëŠ” ê¸¸ì€ ì–´ë– ì…¨ë‚˜ìš”?"

        if icebreaker_text:
            full_question = f"{opening_statement} {icebreaker_text}"
            return {"id": "icebreaker-template-1", "question": full_question}

        # ì•„ì´ìŠ¤ë¸Œë ˆì´ì»¤ ìƒì„±ì— ì™„ì „íˆ ì‹¤íŒ¨í•œ ê²½ìš°, ì²« ë²ˆì§¸ ë©”ì¸ ì§ˆë¬¸ìœ¼ë¡œ í´ë°±
        qtext, qid = extract_first_main_question(self.plan or {})
        if not qtext:
            return {}  # ê³„íšì´ ë¹„ì–´ìˆëŠ” ê·¹ë‹¨ì ì¸ ê²½ìš°
        
        full_question = f"{opening_statement} {qtext}"
        return {"id": qid or "main-1-1", "question": full_question}

    # -----------------------------
    # Intent Classification
    # -----------------------------
    def classify_user_intent(self, question: str, answer: str) -> str:
        """Classifies the user's intent."""
        prompt = prompt_intent_classifier.format(question=question, answer=answer)
        result = self.base._chat_json(prompt, temperature=0.0)
        return result.get("intent", "ANSWER")

    # -----------------------------
    # Analyze (ë¶„ì„/í‰ê°€/ê¼¬ë¦¬ì§ˆë¬¸)
    # -----------------------------
    def analyze_answer_with_rag(self, question: str, answer: str, stage: str, question_item: Optional[Dict] = None) -> dict:
        """
        Analyzes the candidate's answer using a multi-step RAG pipeline.
        """
        print(f"[INFO] ë‹µë³€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: ì§ˆë¬¸: {question[:50]}...\në‹µë³€: {answer[:50]}...")
        if not self.base.rag_ready:
            print("[WARNING] analyze_answer: RAG system is not ready.")
            return {"error": "RAG system is not ready."}

        # --- ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ---
        persona_desc = self.base.persona.get("persona_description", "")
        eval_focus = self.base.persona.get("evaluation_focus", "")
        ncs_details = json.dumps(self.base.ncs_context, ensure_ascii=False)
        
        evaluation_criteria = ""
        if question_item:
            rubric = question_item.get("rubric")
            expected = question_item.get("expected_points")
            criteria_text = "\n[í‰ê°€ ê¸°ì¤€]\n"
            if rubric:
                criteria_text += f"- Rubric: {json.dumps(rubric, ensure_ascii=False)}\n"
            if expected:
                criteria_text += f"- Expected Points: {json.dumps(expected, ensure_ascii=False)}\n"
            evaluation_criteria = criteria_text

        # --- íŒŒì´í”„ë¼ì¸ 1: ê¸°ë³¸ ë¶„ì„ (í”¼ë“œë°±, ì‚¬ì‹¤ í™•ì¸) ---
        print("  [1/4] ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰...")
        analysis_prompt = prompt_rag_answer_analysis.format(
            persona_description=persona_desc,
            evaluation_focus=eval_focus,
            question=question,
            answer=answer,
            evaluation_criteria=evaluation_criteria,
            internal_check="(ë‚´ë¶€ ìë£Œ ê²€ì¦ ì •ë³´ ì—†ìŒ)",
            web_result="(ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"
        )
        base_analysis = self.base._chat_json(prompt=analysis_prompt, temperature=0.2)

        # --- íŒŒì´í”„ë¼ì¸ 2: ì ìˆ˜ ì±„ì  ---
        print("  [2/4] ì ìˆ˜ ì±„ì  ìˆ˜í–‰...")
        framework = question_item.get("question_type", "COMPETENCY").upper() if question_item else "COMPETENCY"
        scorer_prompt = prompt_scorer.format(
            persona_description=persona_desc,
            evaluation_focus=eval_focus,
            framework_name=framework,
            role=self.base.job_title,
            retrieved_ncs_details=ncs_details,
            # Hallucination ë°©ì§€ë¥¼ ìœ„í•´ ì›ë³¸ ë‹µë³€ ì „ë‹¬
            user_answer=answer 
        )
        scoring_result = self.base._chat_json(prompt=scorer_prompt, temperature=0.1)

        # --- íŒŒì´í”„ë¼ì¸ 3: ì½”ì¹­ (ê°•ì /ê°œì„ ì ) ---
        print("  [3/4] ì½”ì¹­ ìƒì„± ìˆ˜í–‰...")
        coach_prompt = prompt_coach.format(
            persona_description=persona_desc,
            scoring_reason=scoring_result.get("scoring_reason", ""),
            user_answer=answer,
            resume_context=self.base.resume_context,
            ideal_candidate_profile=get_company_description(self.base.company_name),
            retrieved_ncs_details=ncs_details,
            company_name=self.base.company_name
        )
        coaching_result = self.base._chat_json(prompt=coach_prompt, temperature=0.3)

        # --- íŒŒì´í”„ë¼ì¸ 4: ëª¨ë²” ë‹µì•ˆ ìƒì„± ---
        print("  [4/4] ëª¨ë²” ë‹µì•ˆ ìƒì„± ìˆ˜í–‰...")
        model_answer_prompt = prompt_model_answer.format(
            persona_description=persona_desc,
            retrieved_ncs_details=ncs_details,
            user_answer=answer,
            resume_context=self.base.resume_context
        )
        model_answer_result = self.base._chat_json(prompt=model_answer_prompt, temperature=0.3)

        # --- ìµœì¢… ê²°ê³¼ ì·¨í•© ---
        final_result = {
            "question_id": question_item.get("id") if question_item else "unknown",
            "question": question,
            "question_intent": question_item.get("objective") if question_item else "N/A",
            "answer": answer,
            **base_analysis,
            "scoring": scoring_result,
            "coaching": coaching_result,
            "model_answer": model_answer_result,
        }
        
        # ëŒ€í™”ë¡ì— í˜„ì¬ í„´ ê¸°ë¡ ì¶”ê°€
        self.transcript.append({
            "turn": len(self.transcript) + 1,
            "question": question,
            "answer": answer,
            "analysis_summary": {
                "feedback": base_analysis.get("feedback"),
                "scoring_reason": scoring_result.get("scoring_reason")
            }
        })
        
        print(f"[INFO] ë‹µë³€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ.")
        return final_result

    def generate_follow_up_question(
        self,
        original_question: str,
        answer: str,
        analysis: Dict,
        stage: str,
        objective: str,
        question_item: Optional[Dict] = None,
        *,
        limit: int = 3,
        **kwargs,
    ) -> List[str]:
        """
        ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„±(FSM/ë·°ì—ì„œ í˜¸ì¶œ). íŒŒë¼ë¯¸í„°ëª…ì€ limit ì‚¬ìš©.
        """
        return self.analyzer.generate_follow_up_question(
            original_question=original_question,
            answer=answer,
            analysis=analysis,
            transcript=self.transcript,
            stage=stage,
            objective=objective,
            question_item=question_item,
            limit=limit,
            **kwargs,
        )

    # -----------------------------
    # Report (ìµœì¢… ë¦¬í¬íŠ¸)
    # -----------------------------
    def build_final_report(
        self, 
        transcript: List[Dict[str, Any]], 
        structured_scores: List[Dict[str, Any]],
        interview_plan: Optional[Dict[str, Any]] = None,
        full_resume_analysis: Optional[Dict[str, Any]] = None,
        full_contexts: Optional[Dict[str, str]] = None
    ) -> Dict[str, Any]:
        return self.reporter.build_report(
            transcript=transcript, 
            structured_scores=structured_scores,
            interview_plan=interview_plan,
            full_resume_analysis=full_resume_analysis,
            full_contexts=full_contexts
        )

    # -----------------------------
    # (ì„ íƒ) CLI ì‹œì—°ìš© ì›Œí¬í”Œë¡œìš°
    # -----------------------------
    def conduct_interview(self):
        """
        ë¡œì»¬ CLI í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨ ì›Œí¬í”Œë¡œìš°.
        Djangoì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, ë””ë²„ê¹… ëª©ì ìœ¼ë¡œ ìœ ì§€.
        """
        print("\nğŸ¤– RAG Interview Bot Facade Initializing (Interviewer: {})...".format(self.base.interviewer_mode))

        plan_std = self.design_interview_plan()  # í‘œì¤€ ìŠ¤í‚¤ë§ˆ {icebreakers, stages}
        if not plan_std or not plan_std.get("stages"):
            print("\nâŒ Could not create an interview plan.")
            return

        first = self.get_first_question()
        if not first:
            print("\nâš ï¸ ì²« ì§ˆë¬¸ì„ ì°¾ì§€ ëª»í•˜ì—¬ í´ë°± ë¬¸êµ¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            first = {"id": "FALLBACK-1", "question": "ê°€ë²¼ìš´ ì•„ì´ìŠ¤ë¸Œë ˆì´í‚¹ìœ¼ë¡œ ì‹œì‘í•´ë³¼ê²Œìš”. ìµœê·¼ì— ì¬ë¯¸ìˆê²Œ ë³¸ ì½˜í…ì¸ ê°€ ìˆë‚˜ìš”?"}

        print(f"\n[Q] {first['question']}")
        user_answer = input("[A] ")  # CLIì—ì„œë§Œ ì‚¬ìš©
        analysis = self.analyze_answer(first["question"], user_answer, role=self.base.job_title)
        print("\n[ANALYSIS]\n", json.dumps(analysis, ensure_ascii=False, indent=2))
