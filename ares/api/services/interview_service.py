# ares/api/services/interview_service.py
# =========================================================
# ë©´ì ‘ ì§ˆë¬¸/ê¼¬ë¦¬ì§ˆë¬¸/STAR-C í‰ê°€ + (ì„ íƒ) NCS ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
# - ncs_query ë¹„ì—ˆì„ ë•Œ meta.role/division/companyë¡œ ìë™ ëŒ€ì²´
# - NCS ëª¨ë“ˆ ë° í•¨ìˆ˜ callable ê°€ë“œ
# - CLI í…ŒìŠ¤íŠ¸ ì§„ì…ì  / ë¡œê·¸ ë””ë²„ê·¸ í† ê¸€
# =========================================================

from __future__ import annotations

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import time, re, json, argparse, sys

from ares.api.utils.ai_utils import chat
from ares.api.utils.common_utils import get_logger

# ğŸ” NCS í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰/ì»¨í…ìŠ¤íŠ¸ ì£¼ì… (ì„ íƒ)
#   - env: AZURE_SEARCH_ENDPOINT / AZURE_SEARCH_KEY / NCS_INDEX í•„ìš”
try:
    from ares.api.utils import search_utils as ncs  # ëª¨ë“ˆ ë‹¨ì¼ import
except Exception:
    ncs = None

_log = get_logger("interview")

__all__ = [
    "make_outline",
    "generate_main_question_ondemand",
    "generate_followups",
    "score_answer_starc",
]

# =========================
# ì„¤ì •/ìœ í‹¸
# =========================
@dataclass
class GenConfig:
    temperature_outline: float = 0.4
    temperature_main: float = 0.5
    temperature_follow: float = 0.3
    temperature_score: float = 0.2

    max_tokens_outline: int = 220
    max_tokens_main: int = 160
    max_tokens_follow: int = 260
    max_tokens_score: int = 520

    context_max_chars: int = 10000
    answer_max_chars: int = 6000

    ncs_top_outline: int = 6
    ncs_top_main: int = 6
    ncs_top_follow: int = 4
    ncs_top_score: int = 4
    ncs_ctx_max_len: int = 1800

    # ì‹ ê·œ: ì‹¤ë¬´ í¸ì˜
    max_follow_k: int = 8          # ê¼¬ë¦¬ì§ˆë¬¸ 1íšŒ ìµœëŒ€ ìƒì„± ê°œìˆ˜
    debug_log_prompts: bool = False  # ëŒ€ìš©ëŸ‰ í”„ë¡¬í”„íŠ¸ ë¡œê¹… í† ê¸€

CFG = GenConfig()

def _safe_strip(s: str) -> str:
    return (s or "").strip()

def _normalize_lines(text: str) -> List[str]:
    lines = []
    for raw in (text or "").splitlines():
        l = raw.strip()
        if not l:
            continue
        l = re.sub(r"^[\-\â€¢\d\.\)\(]+\s*", "", l)
        if l:
            lines.append(l)
    return lines

def _dedup_preserve_order(items: List[str]) -> List[str]:
    seen, out = set(), []
    for it in items:
        key = re.sub(r"\s+", " ", it).strip().lower()
        if key and key not in seen:
            seen.add(key); out.append(it)
    return out

def _too_similar(a: str, b: str, thresh: float = 0.6) -> bool:
    ta = set(re.findall(r"[ê°€-í£A-Za-z0-9]+", (a or "").lower()))
    tb = set(re.findall(r"[ê°€-í£A-Za-z0-9]+", (b or "").lower()))
    if not ta or not tb:
        return False
    inter, union = len(ta & tb), len(ta | tb)
    return (inter / max(1, union)) >= thresh

def _not_too_long(s: str, max_chars: int) -> str:
    s = s or ""
    return s if len(s) <= max_chars else s[:max_chars]

def _first_sentence(s: str) -> str:
    """ì—¬ëŸ¬ ì¤„/ì—¬ëŸ¬ ë¬¸ì¥ì¼ ë•Œ ì²« ë¬¸ì¥ë§Œ."""
    s = _safe_strip(s)
    # ì¤„ ê¸°ì¤€ ìš°ì„ 
    s = s.splitlines()[0] if "\n" in s else s
    # ë¬¸ì¥ ì¢…ê²°ë¶€ ê¸°ì¤€(ë¬¼ìŒí‘œ/ë§ˆì¹¨í‘œ)ë¡œ 1ë¬¸ì¥ë§Œ
    m = re.search(r"(.+?[\.?!ï¼Ÿ])(\s|$)", s)
    return m.group(1).strip() if m else s

def _ensure_question_mark(s: str) -> str:
    s = _safe_strip(s)
    return s if s.endswith("?") or s.endswith("ï¼Ÿ") else (s + "?") if s else s

def _safe_chat(
    msgs: List[Dict[str, str]],
    temperature: float,
    max_tokens: int,
    fallback: str = "",
    retries: int = 2,
    backoff: float = 0.8
) -> str:
    last_err = None
    for i in range(retries + 1):
        try:
            out = chat(msgs, temperature=temperature, max_tokens=max_tokens)
            return out or fallback
        except Exception as e:
            last_err = e
            _log.warning(f"chat() ì‹¤íŒ¨, ì¬ì‹œë„ {i}/{retries}: {e}")
            time.sleep(backoff * (2 ** i))
    _log.error(f"chat() ìµœì¢… ì‹¤íŒ¨: {last_err}")
    return fallback

# =========================
# (ì„ íƒ) NCS ì»¨í…ìŠ¤íŠ¸ ì£¼ì…
# =========================
def _resolve_ncs_query(ncs_query: Optional[str], meta: Optional[dict]) -> str:
    q = (ncs_query or "").strip()
    if not q and meta:
        # role â†’ division â†’ company ìˆœìœ¼ë¡œ ëŒ€ì²´
        q = (meta.get("role") or meta.get("division") or meta.get("company") or "").strip()
    # ê³µë°±ë¿ì´ë©´ ë¬´ì‹œ
    return q if q else ""

def _build_ncs_ctx(query: Optional[str], top: int, max_len: int) -> str:
    """
    NCS ì¸ë±ìŠ¤ê°€ ìˆì„ ë•Œë§Œ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„±. ì‹¤íŒ¨/ë¯¸ì„¤ì •ì´ë©´ ë¹ˆ ë¬¸ìì—´.
    """
    if not ncs:
        return ""
    if not (hasattr(ncs, "search_ncs_hybrid") and callable(getattr(ncs, "search_ncs_hybrid"))):
        return ""
    if not (hasattr(ncs, "format_ncs_context") and callable(getattr(ncs, "format_ncs_context"))):
        return ""

    q = (query or "").strip()
    if not q:
        return ""

    try:
        hits = ncs.search_ncs_hybrid(q, top=top)
        ctx = ncs.format_ncs_context(hits, max_len=max_len) or ""
        _log.info(f"NCS ì»¨í…ìŠ¤íŠ¸: hits={len(hits)}, query='{q[:60]}'")
        return ctx
    except Exception as e:
        _log.warning(f"NCS ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return ""

# =========================
# ì „ë¬¸í™” í”„ë¡¬í”„íŠ¸ (SYS)
# =========================
SYS_OUTLINE = (
    "ë„ˆëŠ” Fortune 500 ì œì¡°Â·IT ê¸°ì—…ì˜ ì‹œë‹ˆì–´ ë©´ì ‘ê´€ì´ë‹¤. "
    "ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ 'ì„¹ì…˜ ì•„ì›ƒë¼ì¸'ë§Œ ì‘ì„±í•œë‹¤. "
    "ê·œì¹™: (1) ë¶ˆë¦¿/ë²ˆí˜¸ ê¸ˆì§€ (2) í•œ ì¤„ì— í•˜ë‚˜ (3) 8~24ì (4) ì¤‘ë³µÂ·ìœ ì‚¬ ê¸ˆì§€. "
    "ì œì¡°/ì„¤ë¹„/ë°˜ë„ì²´ ì»¨í…ìŠ¤íŠ¸ë©´ OEE, TPM, MTBF/MTTR, FDC/ì˜ˆì§€ë³´ì „ ê³ ë ¤."
)

SYS_MAIN_Q = (
    "ë„ˆëŠ” ëŒ€ê¸°ì—… ê¸°ìˆ ì§ ë©´ì ‘ê´€ì´ë‹¤. ìƒˆë¡œìš´ ì£¼ì œì˜ 'ë©”ì¸ ì§ˆë¬¸' 1ê°œë§Œ ì‘ì„±í•œë‹¤. "
    "ì œì•½: (1) ì´ë¯¸ í•œ ì§ˆë¬¸ê³¼ ì¤‘ë³µ ê¸ˆì§€ (2) í•œêµ­ì–´ í•œ ë¬¸ì¥ (3) ëì€ ë¬¼ìŒí‘œ (4) 70ì ì´ë‚´. "
    "ë‚œì´ë„: ì‰¬ì›€=ê²½í—˜ ê°œìš”, ë³´í†µ=ì—­í• Â·ê²°ê³¼ ìˆ˜ì¹˜, ì–´ë ¤ì›€=ê°€ì„¤/ë¦¬ìŠ¤í¬/ì‚¬í›„í•™ìŠµ. "
    "ì œì¡°/ì„¤ë¹„/ë°˜ë„ì²´ë©´ OEE/TPM/MTBF/MTTR/ë¶ˆëŸ‰ë¥ /ê°€ë™ë¥ Â·FDC/ì˜ˆì§€ë³´ì „ ì§€í‘œ ê³ ë ¤."
)

SYS_FOLLOW = (
    "ë„ˆëŠ” ì§‘ìš”í•œ ì‹œë‹ˆì–´ ë©´ì ‘ê´€ì´ë‹¤. ë©”ì¸ ì§ˆë¬¸Â·ë‹µë³€ì„ ë°”íƒ•ìœ¼ë¡œ 'íŒŒê³ ë“œëŠ” ê¼¬ë¦¬ì§ˆë¬¸' kê°œë¥¼ ë§Œë“ ë‹¤. "
    "ì¹´í…Œê³ ë¦¬ ë¶„ì‚°: [ì§€í‘œ/ìˆ˜ì¹˜], [ë³¸ì¸ì—­í• /ì˜ì‚¬ê²°ì •], [ë¦¬ìŠ¤í¬/ëŒ€ì•ˆ], [í˜‘ì—…/ê°ˆë“±], [í•™ìŠµ/íšŒê³ ]. "
    "ê·œì¹™: (1) í•œêµ­ì–´ í•œ ë¬¸ì¥ (2) 60ì ì´ë‚´ (3) ì¤‘ë³µ ê¸ˆì§€ (4) 'ìˆ˜ì¹˜/ê¸°ê°„/ë²”ìœ„' í¬í•¨ ì‹œë„. "
    "ê¸ˆì§€ì–´: 'ì—´ì‹¬íˆ', 'ë§ì´', 'ìµœëŒ€í•œ', 'ì¤‘ìš”í–ˆë‹¤'."
)

SYS_STARC = (
    "ë„ˆëŠ” ì‹œë‹ˆì–´ ë©´ì ‘ê´€ì´ë‹¤. STAR-C(ìƒí™©Â·ê³¼ì œÂ·í–‰ë™Â·ê²°ê³¼Â·ì„±ì°°)ë¡œ í‰ê°€í•œë‹¤. "
    "JSONë§Œ ì¶œë ¥. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ê¸ˆì§€.\n"
    '{ "scores":{"S":0-5,"T":0-5,"A":0-5,"R":0-5,"C":0-5}, '
    '"weighted_total":number, "grade":"A|B|C|D", '
    '"comments":{"S":"","T":"","A":"","R":"","C":""}, '
    '"summary":["- ê°•ì  ...","- ë³´ì™„ì  ...","- ì¶”ê°€ ì œì•ˆ ..."] }\n'
    "Aâ‰¥22.5, Bâ‰¥18.0, Câ‰¥13.0, else D."
)

# =========================
# ë©”íƒ€ ì£¼ì…
# =========================
def _inject_company_ctx(prompt: str, meta: dict | None) -> str:
    if not meta:
        return prompt
    def _s(x): return (x or "").strip()
    comp = _s(meta.get("company",""))
    div  = _s(meta.get("division",""))
    role = _s(meta.get("role",""))
    loc  = _s(meta.get("location",""))
    kpis = ", ".join([_s(x) for x in meta.get("jd_kpis",[]) if _s(x)])[:200]
    skills = ", ".join([_s(x) for x in meta.get("skills",[]) if _s(x)])[:200]
    ctx = (f"[íšŒì‚¬ ì»¨í…ìŠ¤íŠ¸]\n"
           f"- íšŒì‚¬: {comp or 'ë¯¸ìƒ'} | ë¶€ì„œ/ì§ë¬´: {div or '-'} / {role or '-'} | ê·¼ë¬´ì§€: {loc or '-'}\n"
           f"- KPI: {kpis or '-'} | ìŠ¤í‚¬: {skills or '-'}\n\n")
    return ctx + prompt

# =========================
# USR ë¹Œë” (+ NCS ì»¨í…ìŠ¤íŠ¸)
# =========================
def _outline_usr(context: str, n: int, meta: dict | None, ncs_ctx: str) -> str:
    p = (f"[ì»¨í…ìŠ¤íŠ¸]\n{_not_too_long(context, CFG.context_max_chars)}\n\n")
    if ncs_ctx:
        p += f"[NCS ì»¨í…ìŠ¤íŠ¸]\n{ncs_ctx}\n\n"
    p += (f"ìš”êµ¬ì‚¬í•­:\n- ì„¹ì…˜ {n}ê°œ\n- í•œêµ­ì–´, ë¶ˆë¦¿ ì—†ìŒ\n- ê° ì¤„ 8~24ì, ëª…ì‚¬í˜• ìœ„ì£¼\n"
          "ì¶œë ¥: ì„¹ì…˜ëª…ë§Œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë‚˜ì—´")
    return _inject_company_ctx(p, meta)

def _main_usr(context: str, prev: List[str], difficulty: str, meta: dict | None, ncs_ctx: str) -> str:
    prev_block = "\n".join([f"- {q}" for q in (prev or [])]) or "- (ì—†ìŒ)"
    p = (f"[ì»¨í…ìŠ¤íŠ¸]\n{_not_too_long(context, 8000)}\n\n")
    if ncs_ctx:
        p += f"[NCS ì»¨í…ìŠ¤íŠ¸]\n{ncs_ctx}\n\n"
    p += (f"[ì´ë¯¸ í•œ ì§ˆë¬¸]\n{prev_block}\n\n"
          f"[ë‚œì´ë„]\n{difficulty}\n\n"
          "ì¶œë ¥: ë©”ì¸ ì§ˆë¬¸ í•œ ë¬¸ì¥ë§Œ(70ì ì´ë‚´, ëì€ ë¬¼ìŒí‘œ). ì¤‘ë³µ/ìœ ì‚¬ ê¸ˆì§€.")
    return _inject_company_ctx(p, meta)

def _follow_usr(main_q: str, answer: str, k: int, meta: dict | None, ncs_ctx: str) -> str:
    p = (f"[ë©”ì¸ ì§ˆë¬¸]\n{_safe_strip(main_q)}\n\n"
         f"[ì§€ì›ì ë‹µë³€]\n{_not_too_long(_safe_strip(answer), CFG.answer_max_chars)}\n\n")
    if ncs_ctx:
        p += f"[NCS ì»¨í…ìŠ¤íŠ¸]\n{ncs_ctx}\n\n"
    p += (f"ìš”êµ¬: ê¼¬ë¦¬ì§ˆë¬¸ {k}ê°œ, ì„œë¡œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒì„±.\n"
          "ì¶œë ¥: ì¤„ë°”ê¿ˆìœ¼ë¡œ ì§ˆë¬¸ë§Œ ë‚˜ì—´")
    return _inject_company_ctx(p, meta)

def _starc_usr(q: str, a: str, meta: dict | None, ncs_ctx: str) -> str:
    p = (f"[ì§ˆë¬¸]\n{_safe_strip(q)}\n\n"
         f"[ë‹µë³€]\n{_safe_strip(a)}\n\n")
    if ncs_ctx:
        p += f"[NCS ì»¨í…ìŠ¤íŠ¸]\n{ncs_ctx}\n\n"
    p += "ì¶œë ¥: JSONë§Œ."
    return _inject_company_ctx(p, meta)

# =========================
# 1) ì„¹ì…˜ ì•„ì›ƒë¼ì¸
# =========================
def make_outline(context: str, n: int = 5, meta: dict | None = None, ncs_query: str | None = None) -> List[str]:
    ncs_query = _resolve_ncs_query(ncs_query, meta)
    ncs_ctx = _build_ncs_ctx(ncs_query, CFG.ncs_top_outline, CFG.ncs_ctx_max_len)
    msgs = [
        {"role": "system", "content": SYS_OUTLINE},
        {"role": "user", "content": _outline_usr(context, n, meta, ncs_ctx)},
    ]
    if CFG.debug_log_prompts:
        try:
            _log.debug("=== make_outline prompt ===\n" + json.dumps(msgs, ensure_ascii=False, indent=2))
        except Exception:
            pass

    out = _safe_chat(
        msgs,
        temperature=CFG.temperature_outline,
        max_tokens=CFG.max_tokens_outline,
        fallback=""
    )
    lines = _dedup_preserve_order(_normalize_lines(out))
    if not lines:
        lines = ["ë¬¸ì œí•´ê²°", "í˜‘ì—…", "í’ˆì§ˆ", "ë¦¬ìŠ¤í¬", "ê³ ê°ì§‘ì°©"]
    return lines[:n]

# =========================
# 2) ë©”ì¸ ì§ˆë¬¸ ìƒì„± (ì˜¨ë””ë§¨ë“œ 1ê°œ)
# =========================
def generate_main_question_ondemand(
    context: str,
    prev_questions: List[str],
    difficulty: str = "ë³´í†µ",
    meta: dict | None = None,
    ncs_query: str | None = None
) -> str:
    ncs_query = _resolve_ncs_query(ncs_query, meta)
    ncs_ctx = _build_ncs_ctx(ncs_query, CFG.ncs_top_main, CFG.ncs_ctx_max_len)
    msgs = [
        {"role": "system", "content": SYS_MAIN_Q},
        {"role": "user", "content": _main_usr(context, prev_questions, difficulty, meta, ncs_ctx)},
    ]
    if CFG.debug_log_prompts:
        try:
            _log.debug("=== generate_main_question_ondemand prompt ===\n" + json.dumps(msgs, ensure_ascii=False, indent=2))
        except Exception:
            pass

    out = _safe_chat(
        msgs,
        temperature=CFG.temperature_main,
        max_tokens=CFG.max_tokens_main,
        fallback="í•´ë‹¹ ì§ë¬´ ê´€ë ¨ í•µì‹¬ ê²½í—˜ì„ í•œ ê°€ì§€ ì‚¬ë¡€ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
    )
    q = _first_sentence(out)
    # ìœ ì‚¬ì„± ì²´í¬
    for pq in prev_questions or []:
        if _too_similar(q, pq):
            q = "ì´ì „ ì§ˆë¬¸ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ë‹¤ë¥¸ í•µì‹¬ ê²½í—˜ì„ í•œ ê°€ì§€ ì„ íƒí•´ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
            break
    q = _ensure_question_mark(q)
    return q

# =========================
# 3) ê¼¬ë¦¬ì§ˆë¬¸ ìƒì„± (í•˜ìœ„í˜¸í™˜ ì§€ì›)
# =========================
def generate_followups(
    main_q: Optional[str] = None,
    answer: Optional[str] = None,
    k: int = 3,
    main_index: Optional[int] = None,
    meta: Optional[dict] = None,
    ncs_query: Optional[str] = None,
    **legacy_kwargs,  # â† ì˜ˆì „ í˜¸ì¶œ ë°©ì‹(language, difficulty, ncs_context, based_on_answer, modes ë“±)
) -> List[str]:
    """
    í•˜ìœ„í˜¸í™˜ ì¸ì ë§¤í•‘:
      - based_on_answer -> answer
      - ncs_context(list[dict] or list[str]) -> ncs_ctx ë¬¸ìì—´ë¡œ ë³‘í•©
      - modes -> ì¹´í…Œê³ ë¦¬ íŒíŠ¸(í˜„ì¬ëŠ” ë‹¤ì–‘ì„± í™•ë³´ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©)
      - language/difficulty -> í”„ë¡¬í”„íŠ¸ íŠœë‹ íŒíŠ¸(í˜„ì¬ëŠ” ê°•ì œ ê·œì¹™ì€ ì•„ë‹˜)
    """
    # k ê°€ë“œ
    if k <= 0:
        return []
    if k > CFG.max_follow_k:
        k = CFG.max_follow_k

    # ---- í•˜ìœ„í˜¸í™˜ ë§¤í•‘ ----
    if answer is None and "based_on_answer" in legacy_kwargs:
        answer = legacy_kwargs.get("based_on_answer") or ""

    # ì˜ˆì „ ì½”ë“œê°€ ncs_context(ë¦¬ìŠ¤íŠ¸/ë”•íŠ¸ë“¤)ë¥¼ ì§ì ‘ ë„£ì–´ì¤„ ë•Œë¥¼ ì§€ì›
    legacy_ncs_ctx = legacy_kwargs.get("ncs_context")
    ncs_ctx_from_list = ""
    if legacy_ncs_ctx:
        try:
            # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
            if isinstance(legacy_ncs_ctx, list) and all(isinstance(x, str) for x in legacy_ncs_ctx):
                ncs_ctx_from_list = "\n".join(f"- {x}" for x in legacy_ncs_ctx if x.strip())
            # ë”•íŠ¸ ë¦¬ìŠ¤íŠ¸: {"code","title","desc"} í˜•íƒœ
            elif isinstance(legacy_ncs_ctx, list) and all(isinstance(x, dict) for x in legacy_ncs_ctx):
                buf = []
                for it in legacy_ncs_ctx:
                    code = (it.get("code") or it.get("ncs_code") or "").strip()
                    title = (it.get("title") or it.get("ncs_title") or "").strip()
                    desc = (it.get("desc") or it.get("summary") or it.get("description") or "").strip()
                    line = " / ".join([x for x in [code, title, desc] if x])
                    if line:
                        buf.append(f"- {line}")
                ncs_ctx_from_list = "\n".join(buf)
        except Exception:
            ncs_ctx_from_list = ""

    # modes íŒíŠ¸(í˜„ì¬ëŠ” ë‹¤ì–‘ì„±ë§Œ ìœ ë„)
    modes_hint = legacy_kwargs.get("modes") or []
    if isinstance(modes_hint, (list, tuple)):
        modes_hint = [str(m).strip() for m in modes_hint if str(m).strip()]
    else:
        modes_hint = []

    # ì–¸ì–´/ë‚œì´ë„ íŒíŠ¸ (í•„ìš”ì‹œ íŠœë‹ìš©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥)
    lang_hint = (legacy_kwargs.get("language") or "").lower().strip()
    diff_hint = (legacy_kwargs.get("difficulty") or "").strip()

    # ---- NCS ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½(ì‹ ê·œ + í•˜ìœ„í˜¸í™˜ ë³‘í•©) ----
    ncs_query = _resolve_ncs_query(ncs_query, meta)
    ncs_ctx_from_search = _build_ncs_ctx(ncs_query, CFG.ncs_top_follow, CFG.ncs_ctx_max_len)
    # ìš°ì„ ìˆœìœ„: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ + (ìˆìœ¼ë©´) í˜¸ì¶œìê°€ ì§ì ‘ ì¤€ ë¦¬ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸
    if ncs_ctx_from_search and ncs_ctx_from_list:
        ncs_ctx = ncs_ctx_from_search + "\n" + ncs_ctx_from_list
    else:
        ncs_ctx = ncs_ctx_from_search or ncs_ctx_from_list

    # ë©”ì¸ ì§ˆë¬¸ ì—†ì„ ë•Œ ë°©ì–´ì  ê¸°ë³¸ê°’
    if not main_q:
        main_q = "ì´ì „ ì£¼ì œì— ëŒ€í•´ ë” ê¹Šì´ íŒŒê³ ë“¤ê¸° ìœ„í•œ ì¶”ê°€ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”."

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    sys_prompt = SYS_FOLLOW
    if lang_hint == "en":
        # ì˜ì–´ë¡œë„ ì“¸ ìˆ˜ ìˆê²Œ ì•„ì£¼ ê°€ë³ê²Œ ì „í™˜(ì„ íƒ)
        sys_prompt = sys_prompt.replace("í•œêµ­ì–´", "ì˜ì–´")

    user_prompt = _follow_usr(main_q, answer or "", k, meta, ncs_ctx)
    if modes_hint:
        user_prompt += "\n[ì¹´í…Œê³ ë¦¬ íŒíŠ¸]\n- " + ", ".join(modes_hint)

    msgs = [
        {"role": "system", "content": sys_prompt},
        {"role": "user", "content": user_prompt},
    ]
    if CFG.debug_log_prompts:
        try:
            _log.debug("=== generate_followups prompt ===\n" + json.dumps(msgs, ensure_ascii=False, indent=2))
        except Exception:
            pass

    out = _safe_chat(
        msgs,
        temperature=CFG.temperature_follow,
        max_tokens=CFG.max_tokens_follow,
        fallback=""
    )
    lines = _dedup_preserve_order(_normalize_lines(out))
    if not lines:
        lines = [
            "í•µì‹¬ ì§€í‘œì™€ ê¸°ì¤€ì„ /ê¸°ê°„ì„ ìˆ˜ì¹˜ë¡œ ëª…í™•íˆ ì œì‹œí•´ ì£¼ì‹œê² ì–´ìš”?",
            "ë³¸ì¸ ê³ ìœ  ì˜ì‚¬ê²°ì •ê³¼ ì„ íƒ ê·¼ê±°ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ì–´ìš”?",
            "ì£¼ìš” ë¦¬ìŠ¤í¬ì™€ ëŒ€ë¹„ ëŒ€ì•ˆ(í”ŒëœB/C)ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"
        ][:k]
    lines = lines[:k]

    if main_index is not None:
        prefix = str(int(main_index))
        lines = [f"{prefix}-{i+1}. {q.strip()}" for i, q in enumerate(lines)]
    return lines


# =========================
# 4) STAR-C í‰ê°€ (ê°€ì¤‘í•©/ë“±ê¸‰ í¬í•¨)
# =========================
def score_answer_starc(
    q: str,
    a: str,
    meta: dict | None = None,
    ncs_query: str | None = None
) -> Dict[str, Any]:
    ncs_query = _resolve_ncs_query(ncs_query, meta)
    ncs_ctx = _build_ncs_ctx(ncs_query, CFG.ncs_top_score, CFG.ncs_ctx_max_len)
    msgs = [
        {"role": "system", "content": SYS_STARC},
        {"role": "user", "content": _starc_usr(q, a, meta, ncs_ctx)},
    ]
    if CFG.debug_log_prompts:
        try:
            _log.debug("=== score_answer_starc prompt ===\n" + json.dumps(msgs, ensure_ascii=False, indent=2))
        except Exception:
            pass

    raw = _safe_chat(
        msgs,
        temperature=CFG.temperature_score,
        max_tokens=CFG.max_tokens_score,
        fallback=""
    ).strip()

    result: Dict[str, Any] = {
        "scores": {}, "weighted_total": None, "grade": None,
        "comments": {}, "summary": []
    }
    try:
        data = json.loads(raw)
        if isinstance(data.get("scores"), dict):
            result["scores"] = data["scores"]
        if "weighted_total" in data:
            result["weighted_total"] = data["weighted_total"]
        if "grade" in data:
            result["grade"] = data["grade"]
        if isinstance(data.get("comments"), dict):
            result["comments"] = data["comments"]
        if isinstance(data.get("summary"), list):
            result["summary"] = data["summary"]

        # ê°€ì¤‘í•© ì—†ìœ¼ë©´ ê³„ì‚°
        if result["scores"] and result["weighted_total"] is None:
            S = float(result["scores"].get("S", 0))
            T = float(result["scores"].get("T", 0))
            A = float(result["scores"].get("A", 0))
            R = float(result["scores"].get("R", 0))
            C = float(result["scores"].get("C", 0))
            weighted = S*1.0 + T*1.0 + A*1.2 + R*1.2 + C*0.8
            result["weighted_total"] = round(weighted, 2)

        # ë“±ê¸‰ ì—†ìœ¼ë©´ ì‚°ì •
        if result["grade"] is None and result["weighted_total"] is not None:
            wt = result["weighted_total"]
            if wt >= 22.5: grade = "A"
            elif wt >= 18.0: grade = "B"
            elif wt >= 13.0: grade = "C"
            else: grade = "D"
            result["grade"] = grade

        if not result["summary"]:
            result["summary"] = [
                "- ê°•ì : í•µì‹¬ KPI/ì—­í•  ì¼ë¶€ ì œì‹œ",
                "- ë³´ì™„ì : ìˆ˜ì¹˜/ê¸°ê°„/ê·œëª¨ êµ¬ì²´í™” ë¶€ì¡±",
                "- ì¶”ê°€ ì œì•ˆ: ê²°ê³¼-ì›ì¸ ì—°ê²° ê°•í™” ë° ì‚¬í›„ í•™ìŠµ ê³„íš ëª…ì‹œ"
            ]
    except Exception as e:
        _log.warning(f"STAR-C JSON íŒŒì‹± ì‹¤íŒ¨: {e} | raw={raw[:800]}")
        result["summary"] = [raw or "í‰ê°€ ìƒì„± ì‹¤íŒ¨"]

    return result

# =========================
# CLI í…ŒìŠ¤íŠ¸ ì§„ì…ì 
# =========================
def _cli():
    p = argparse.ArgumentParser(description="Interview service quick test")
    sub = p.add_subparsers(dest="cmd", required=True)

    p_out = sub.add_parser("outline")
    p_out.add_argument("--ctx", required=True)
    p_out.add_argument("--n", type=int, default=5)

    p_main = sub.add_parser("mainq")
    p_main.add_argument("--ctx", required=True)
    p_main.add_argument("--prev", default="")
    p_main.add_argument("--difficulty", default="ë³´í†µ")

    p_follow = sub.add_parser("follow")
    p_follow.add_argument("--mainq", required=True)
    p_follow.add_argument("--answer", required=True)
    p_follow.add_argument("--k", type=int, default=3)
    p_follow.add_argument("--index", type=int)

    p_score = sub.add_parser("score")
    p_score.add_argument("--q", required=True)
    p_score.add_argument("--a", required=True)

    args = p.parse_args()
    meta = {}  # í•„ìš” ì‹œ metadata_service.build_meta_from_inputsë¡œ êµ¬ì„±

    if args.cmd == "outline":
        print("\n".join(make_outline(args.ctx, n=args.n, meta=meta)))
    elif args.cmd == "mainq":
        prev = [x.strip() for x in args.prev.split("||") if x.strip()]
        print(generate_main_question_ondemand(args.ctx, prev, difficulty=args.difficulty, meta=meta))
    elif args.cmd == "follow":
        print("\n".join(generate_followups(args.mainq, args.answer, k=args.k, main_index=args.index, meta=meta)))
    elif args.cmd == "score":
        print(json.dumps(score_answer_starc(args.q, args.a, meta=meta), ensure_ascii=False, indent=2))

if __name__ == "__main__":
    try:
        _cli()
    except Exception as e:
        _log.error(f"interview_service CLI ì‹¤íŒ¨: {e}")
        sys.exit(1)
