# ares/api/utils/text_utils.py
"""
í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬/ë³´ì • ìœ í‹¸ë¦¬í‹° ëª¨ìŒ

ì£¼ìš” ê¸°ëŠ¥
- ì•ˆì „í•œ strip, ë¼ì¸ ì •ê·œí™”, ì¤‘ë³µ ì œê±°, ìœ ì‚¬ë„ íŒë‹¨
- ì²« ë¬¸ì¥ ì¶”ì¶œ, ë¬¼ìŒí‘œ ë³´ì¥
- ğŸ”§ ì •ì œ ê²°ê³¼ê°€ ì¤‘ê°„ì— ëŠê¸´ ê²½ìš° RAW ì›ë¬¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ê¼¬ë¦¬ë¥¼ ì´ì–´ë¶™ì´ëŠ” ensure_full_text()

ì‚¬ìš© ì˜ˆ:
    safe = ensure_full_text(refined_resume_context, raw_resume_context)
"""

from __future__ import annotations
import re
from typing import List, Optional


# ---------------------------
# ê¸°ë³¸ ì „ì²˜ë¦¬ ìœ í‹¸
# ---------------------------
def safe_strip(s: str) -> str:
    return (s or "").strip()


def normalize_lines(text: str) -> List[str]:
    """
    - ê³µë°± ë¼ì¸ ì œê±°
    - ë¶ˆë¦¿/ë²ˆí˜¸ ì ‘ë‘ ì œê±°: -, â€¢, ìˆ«ì., ), ] ë“±
    """
    lines: List[str] = []
    for raw in (text or "").splitlines():
        l = raw.strip()
        if not l:
            continue
        l = re.sub(r"^[\-â€¢\d\.\)\(\]]+\s*", "", l)
        if l:
            lines.append(l)
    return lines


def dedup_preserve_order(items: List[str]) -> List[str]:
    """
    ê³µë°±/ëŒ€ì†Œë¬¸ì/ì—°ì† ê³µë°± ë¬´ì‹œí•˜ê³  ìˆœì„œ ìœ ì§€ ì¤‘ë³µ ì œê±°
    """
    seen, out = set(), []
    for it in items:
        key = re.sub(r"\s+", " ", it).strip().lower()
        if key and key not in seen:
            seen.add(key)
            out.append(it)
    return out


def too_similar(a: str, b: str, thresh: float = 0.6) -> bool:
    """
    í† í° Jaccard ìœ ì‚¬ë„(ì•„ì£¼ ëŸ¬í”„)ë¡œ ìœ ì‚¬ì„± íŒë‹¨
    """
    ta = set(re.findall(r"[\uac00-\ud7a3A-Za-z0-9]+", (a or "").lower()))
    tb = set(re.findall(r"[\uac00-\ud7a3A-Za-z0-9]+", (b or "").lower()))
    if not ta or not tb:
        return False
    inter, union = len(ta & tb), len(ta | tb)
    return (inter / max(1, union)) >= thresh


def not_too_long(s: str, max_chars: int) -> str:
    s = s or ""
    return s if len(s) <= max_chars else s[:max_chars]


def first_sentence(s: str) -> str:
    """ì—¬ëŸ¬ ì¤„/ì—¬ëŸ¬ ë¬¸ì¥ì¼ ë•Œ ì²« ë¬¸ì¥ë§Œ."""
    s = safe_strip(s)
    s = s.splitlines()[0] if "\n" in s else s
    m = re.search(r"(.+?[\.\?!\uff1f])(\s|$)", s)
    return m.group(1).strip() if m else s


def ensure_question_mark(s: str) -> str:
    s = safe_strip(s)
    return s if s.endswith("?") or s.endswith("ï¼Ÿ") else (s + "?") if s else s


# ---------------------------
# ëŠê¹€/ë¯¸ì™„ ë³´ì • ë³´ì¡° ìœ í‹¸
# ---------------------------
_SENT_END_RE = re.compile(r"[\.!?ã€‚\?!]\s*$")
_KO_CONNECTIVES_RE = re.compile(
    r"(ìœ¼ë¡œ|ë¡œ|ê³ |ë©°|ì§€ë§Œ|ê·¸ë¦¬ê³ |ë˜í•œ|ë•Œë¬¸ì—|ìœ„í•´|í•˜ë©°|í•˜ë©´ì„œ|ì¸ë°|ì¸ë°ë„|ì´ì§€ë§Œ|ì¸ë°ìš”|ê±°ë“ ìš”|ì´ë¼ê³ )$"
)
_CODE_FENCE = "```"


def _balance_code_fences(s: str) -> str:
    """
    ë°±í‹± ì½”ë“œíœìŠ¤ ê°œìˆ˜ê°€ í™€ìˆ˜ë©´ ë‹«ì•„ì¤Œ.
    """
    if not s:
        return s
    fences = s.count(_CODE_FENCE)
    if fences % 2 == 1:
        s += "\n" + _CODE_FENCE
    return s


def _close_open_lists(s: str) -> str:
    """
    ë§ˆí¬ë‹¤ìš´ ë¦¬ìŠ¤íŠ¸ê°€ ì–´ìƒ‰í•˜ê²Œ ëë‚˜ëŠ” ê²½ìš° ê°œí–‰ í•˜ë‚˜ ì¶”ê°€ ì •ë„ë¡œ ì™„ì¶©.
    """
    return (s or "").rstrip() + "\n"


def _looks_truncated(s: str) -> bool:
    """
    - ë¬¸ì¥ ì¢…ë£Œë¶€í˜¸ ì—†ì´ ì—°ê²°ì–´/ì¡°ì‚¬ë¡œ ëë‚˜ë©´ ëŠê¸´ ê±¸ë¡œ ê°„ì£¼
    - ì½”ë“œíœìŠ¤ê°€ ì—´ë¦¬ê³  ë‹«íˆì§€ ì•Šì€ ê²½ìš°ë„ ëŠê¹€ìœ¼ë¡œ ê°„ì£¼
    """
    if not s:
        return False
    tail = s.strip()[-40:]
    if s.count(_CODE_FENCE) % 2 == 1:
        return True
    if not _SENT_END_RE.search(tail) and _KO_CONNECTIVES_RE.search(tail):
        return True
    # ê´„í˜¸/ë”°ì˜´í‘œ ëŒ€ì¶© ê· í˜• ì²´í¬(ì™„ë²½X)
    opens = s.count("(") + s.count("[") + s.count("{") + s.count("â€œ") + s.count('"')
    closes = s.count(")") + s.count("]") + s.count("}") + s.count("â€") + s.count('"')
    return opens > closes


def _ensure_sentence_end(s: str) -> str:
    """
    ëì´ ë„ˆë¬´ í—ˆì „í•˜ë©´ ë§ˆì¹¨í‘œ í•˜ë‚˜ ì¶”ê°€ (ì½”ë“œíœìŠ¤/í—¤ë” ì œì™¸)
    """
    t = s.rstrip()
    if not t:
        return t
    if t.endswith(_CODE_FENCE):
        return t
    if re.search(r"(#|\*|-|\d+\.)\s*$", t):
        return t
    if not _SENT_END_RE.search(t[-8:]):
        return t + "."
    return t


def _find_anchor_in_raw(refined: str, raw: str, window: int) -> int:
    """
    refined ëë¶€ë¶„(window)ì„ anchorë¡œ í•˜ì—¬ rawì—ì„œ ë§ˆì§€ë§‰ ë“±ì¥ ìœ„ì¹˜ë¥¼ ì°¾ìŒ.
    ì—†ìœ¼ë©´ -1 ë°˜í™˜.
    """
    if not refined or not raw:
        return -1
    anchor = refined[-window:].splitlines()[-1].strip()
    if not anchor:
        return -1
    return raw.rfind(anchor)


def _truncate_at_sentence_boundary(s: str, max_len: int) -> str:
    """
    tailì„ ë„ˆë¬´ ê¸¸ê²Œ ë¶™ì´ì§€ ì•Šë„ë¡ ë¬¸ì¥ ê²½ê³„ ë˜ëŠ” ê¸¸ì´ ì œí•œì—ì„œ ìë¥¸ë‹¤.
    """
    s = s[: max_len]
    # ê°€ì¥ ë§ˆì§€ë§‰ ë¬¸ì¥ë¶€í˜¸ ìœ„ì¹˜ê¹Œì§€ ìë¥´ê¸°
    m = list(re.finditer(r"[\.!?ã€‚\?!]", s))
    if m:
        cut = m[-1].end()
        return s[:cut]
    return s


# ---------------------------
# ê³µê°œ: ëŠê¹€ ë³´ì • + RAW ë¨¸ì§€
# ---------------------------
def ensure_full_text(
    refined: str,
    raw: str,
    *,
    tail_window: int = 400,
    tail_limit: int = 2000
) -> str:
    """
    ì •ì œ í…ìŠ¤íŠ¸(refined)ê°€ ë¯¸ì™„ì„±ìœ¼ë¡œ ëë‚˜ë©´ RAWì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ê¼¬ë¦¬ë¥¼ ì´ì–´ë¶™ì¸ë‹¤.

    ë™ì‘:
    1) ê¸°ë³¸ ì •ë¦¬: ë¦¬ìŠ¤íŠ¸/ì½”ë“œíœìŠ¤ ê· í˜• ë³´ì •
    2) ëŠê¹€ ê°ì§€(_looks_truncated)
    3) ëŠê¹€ ì‹œ RAWì—ì„œ refinedì˜ ë§ë¯¸(anchor)ë¥¼ ì°¾ì•„ ê·¸ ì´í›„ tailì„ ìµœëŒ€ tail_limitê¹Œì§€ ë¶™ì„
       - tailì€ ë¬¸ì¥ ê²½ê³„ ìš°ì„ ìœ¼ë¡œ ì˜ë¼ì„œ ë¶™ì„
    4) ë§ˆì§€ë§‰ ë§ˆë¬´ë¦¬(ë§ˆì¹¨í‘œ/ì½”ë“œíœìŠ¤ ê· í˜•) ë³´ì •

    ë°˜í™˜: ë³´ì •ëœ í…ìŠ¤íŠ¸
    """
    refined = refined or ""
    raw = raw or ""

    out = _close_open_lists(refined)
    out = _balance_code_fences(out)

    if _looks_truncated(out) and len(raw) > len(out):
        pos = _find_anchor_in_raw(out, raw, tail_window)
        if pos != -1:
            tail = raw[pos + len(out[-tail_window:].splitlines()[-1].strip()):]
            tail = _truncate_at_sentence_boundary(tail.strip(), tail_limit)
            if tail:
                # ê³µë°± ì¡°ì • í›„ ë¶™ì„
                sep = "" if out.endswith("\n") or tail.startswith("\n") else " "
                out = out + sep + tail

    out = _ensure_sentence_end(out)
    out = _balance_code_fences(out)
    return out


# ëª¨ë“ˆ ì™¸ë¶€ì—ì„œ ì‰½ê²Œ ì°¾ë„ë¡ export ëª©ë¡ì— ëª…ì‹œ (ì„ íƒ)
__all__ = [
    "safe_strip",
    "normalize_lines",
    "dedup_preserve_order",
    "too_similar",
    "not_too_long",
    "first_sentence",
    "ensure_question_mark",
    "ensure_full_text",
]
