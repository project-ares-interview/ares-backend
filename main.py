# main.py â€” ì™„ì „ ëª¨ë“ˆí™” ë²„ì „ (dotenvx ì‹¤í–‰ ì „ì œ) [STT í…ìŠ¤íŠ¸ í‘œì‹œ ë°˜ì˜]
import os, time
from typing import List, Dict, Any, Optional
import gradio as gr

# ê³µìš©/ì…ìˆ˜
from ares.api.utils.common_utils import ts as _ts, ensure_dir as _ensure_dir, LOG_ROOT
from ares.api.utils.file_utils import (
    collect_context, virtual_append, join_texts, auto_split_resume_cover
)
from ares.api.utils.state_utils import (
    history_labels, ensure_plan, add_main_turn, add_follow_turn
)

# AI/ë©´ì ‘/ë¬¸ì„œë¶„ì„/ìŒì„±
from ares.api.services.interview_service import (
    make_outline, generate_main_question_ondemand, question_for_section,
    generate_followups, analyze_answer_star_c, generate_company_specific_questions
)
from ares.api.services.resume_service import (
    analyze_resume_or_cover, compare_documents, analyze_research_alignment
)
from ares.api.services.speech_service import stt_from_file, tts_play


# -------- Handlers (UI ë¡œì§) --------
def on_ingest_inputs(jd_files, jd_paste, doc_files, doc_paste, research_files, research_paste):
    progress = gr.Progress(track_tqdm=True)
    progress(0.02, desc="ìë£Œ íŒŒì‹± ì‹œì‘")

    # JD
    progress(0.15, desc="JD í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    jd_ctx, jd_map = collect_context(jd_files)
    if jd_paste and jd_paste.strip():
        virtual_append(jd_map, "JD(ë¶™ì—¬ë„£ê¸°).txt", jd_paste)
        jd_ctx = join_texts(jd_ctx, f"# [JD(ë¶™ì—¬ë„£ê¸°)]\n{jd_paste}")

    # ì§€ì›ì„œ
    progress(0.45, desc="ì§€ì›ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    doc_ctx, doc_map = collect_context(doc_files)
    if doc_paste and doc_paste.strip():
        virtual_append(doc_map, "ì§€ì›ì„œ(ë¶™ì—¬ë„£ê¸°).txt", doc_paste)
        doc_ctx = join_texts(doc_ctx, f"# [ì§€ì›ì„œ(ë¶™ì—¬ë„£ê¸°)]\n{doc_paste}")

    # ìë™ ë¶„í•  (ë¶™ì—¬ë„£ê¸° ë¬¸ì„œëŠ” ì œì™¸ + ìµœì†Œ 2ê°œ ìƒì´í•œ ê²°ê³¼ì¼ ë•Œë§Œ ë°˜ì˜)
    progress(0.6, desc="ì§€ì›ì„œ ìë™ ë¶„í• ")
    exp = dict(doc_map)
    for name, text in list(doc_map.items()):
        if "ë¶™ì—¬ë„£ê¸°" in name:
            continue
        v = auto_split_resume_cover(name, text)
        if v and len(v) >= 2 and any(k != name for k in v.keys()):
            exp.update(v)
    doc_map = exp

    # ë¦¬ì„œì¹˜
    progress(0.8, desc="ë¦¬ì„œì¹˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ")
    research_ctx, research_map = collect_context(research_files)
    if research_paste and research_paste.strip():
        virtual_append(research_map, "ë¦¬ì„œì¹˜(ë¶™ì—¬ë„£ê¸°).txt", research_paste)
        research_ctx = join_texts(research_ctx, f"# [ë¦¬ì„œì¹˜(ë¶™ì—¬ë„£ê¸°)]\n{research_paste}")

    progress(1.0, desc="íŒŒì‹± ì™„ë£Œ")

    names = sorted(list(doc_map.keys()))
    status_msg = (
        f"âœ… íŒŒì‹± ì™„ë£Œ\n"
        f"- JD ë¬¸ì„œ: {len(jd_map)}ê°œ / ì§€ì›ì„œ ë¬¸ì„œ: {len(doc_map)}ê°œ / ë¦¬ì„œì¹˜ ë¬¸ì„œ: {len(research_map)}ê°œ\n"
        f"- ê°€ìƒë¬¸ì„œ ìë™ ìƒì„±: {'ìˆìŒ' if any('#' in n for n in names) else 'ì—†ìŒ'}"
    )
    return (
        jd_ctx, jd_map, doc_ctx, doc_map, research_ctx, research_map,
        status_msg,
        gr.update(choices=names), gr.update(choices=names, value=[])
    )


def on_run_all_analyses(doc_map: Dict[str,str], jd_ctx: str, research_ctx: str, doc_multi: List[str]):
    progress = gr.Progress()
    progress(0.02, desc="ë¶„ì„ ì¤€ë¹„")
    names_all = [n for n, v in doc_map.items() if (v or "").strip()]
    virtual_pref = [n for n in names_all if ("#ì´ë ¥ì„œ" in n or "#ìì†Œì„œ" in n)]
    targets = doc_multi if doc_multi else (virtual_pref if len(virtual_pref) >= 1 else names_all[:3])

    # 1) ì‹¬ì¸µ ë¶„ì„
    progress(0.18, desc="ì‹¬ì¸µ ë¶„ì„")
    deep_results = []
    if targets:
        total = len(targets)
        for i, name in enumerate(targets, start=1):
            progress(0.18 + 0.35*(i/total), desc=f"ì‹¬ì¸µ ë¶„ì„â€¦ ({i}/{total})")
            txt = doc_map.get(name, "")
            if txt.strip():
                deep = analyze_resume_or_cover(txt, jd_text=jd_ctx)
                deep_results.append(f"## [{name}] ì‹¬ì¸µ ë¶„ì„\n{deep}\n")
    deep_out = "\n\n".join(deep_results) if deep_results else "ë¶„ì„ ê°€ëŠ¥í•œ ì§€ì›ì„œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    # 2) êµì°¨ ë¶„ì„
    progress(0.58, desc="êµì°¨ ë¶„ì„")
    cmp_out = "êµì°¨ ë¶„ì„ì€ ìµœì†Œ 2ê°œ ë¬¸ì„œê°€ í•„ìš”í•©ë‹ˆë‹¤."
    if len(targets) >= 2:
        named = {n: doc_map.get(n, "") for n in targets}
        named = {k:v for k,v in named.items() if v.strip()}
        if len(named) >= 2:
            cmp_out = compare_documents(named)

    # 3) ì •í•©ì„±
    progress(0.82, desc="ì •í•©ì„± ì ê²€")
    doc_concat = "\n\n".join([f"[{n}]\n{doc_map[n]}" for n in targets if (doc_map.get(n,"").strip())])[:16000]
    aln_out = "JD/ì§€ì›ì„œ/ë¦¬ì„œì¹˜ ì„¸ ê°€ì§€ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."
    if (jd_ctx or "").strip() and doc_concat.strip() and (research_ctx or "").strip():
        aln_out = analyze_research_alignment(jd_ctx, doc_concat, research_ctx)

    progress(1.0, desc="ì™„ë£Œ")
    results = {"ì‹¬ì¸µ ë¶„ì„": deep_out, "êµì°¨ ë¶„ì„": cmp_out, "ì •í•©ì„± ì ê²€": aln_out}
    choices = [k for k,v in results.items() if (v or "").strip()]
    default_key = choices[0] if choices else "ì‹¬ì¸µ ë¶„ì„"
    return results, gr.update(choices=choices, value=default_key), results.get(default_key, "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


def on_select_analysis_view(results: Dict[str, str], selected_key: str):
    """ë¶„ì„ ê²°ê³¼ ì„ íƒ ë³€ê²½ ì‹œ í•´ë‹¹ ë³¸ë¬¸ ë°˜í™˜"""
    if not results:
        return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    if not selected_key:
        for v in results.values():
            if (v or "").strip():
                return v
        return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    return results.get(selected_key, "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


def _use_research_ctx(research_bias: bool, research_ctx: str) -> bool:
    return bool(research_bias and (research_ctx or "").strip())


def on_start_interview(mode, outline_k, difficulty, use_tts, voice, research_bias,
                       history, plan, jd_ctx_state, doc_ctx_state, research_ctx_state):
    progress = gr.Progress()
    progress(0.1, desc="ë©´ì ‘ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±")

    plan = ensure_plan(plan)
    plan["mode"] = mode
    plan["difficulty"] = difficulty

    base_context = join_texts("## [ê³µê³ /JD]\n"+(jd_ctx_state or ""), "## [ì§€ì›ì„œ]\n"+(doc_ctx_state or ""), limit=22000)
    full_context = join_texts(base_context, "## [ì§€ì›ì ë¦¬ì„œì¹˜]\n"+(research_ctx_state or ""), limit=24000)
    use_research = _use_research_ctx(research_bias, research_ctx_state)
    ctx = full_context if use_research else base_context

    progress(0.6, desc="ì²« ì§ˆë¬¸ ìƒì„±")
    prev_qs = [h["q"] for h in (history or [])]

    if mode == "í”„ë¦¬í”Œëœ":
        if not plan.get("question_bank"):
            seed = (generate_company_specific_questions(ctx, (research_ctx_state or ""), [], difficulty)
                    if use_research else generate_main_question_ondemand(ctx, [], difficulty))
            plan["question_bank"] = [seed] if isinstance(seed, str) else (seed or [])
            plan["bank_cursor"] = 0
        if plan["bank_cursor"] >= len(plan["question_bank"]):
            return ("ì¤€ë¹„ëœ ì§ˆë¬¸ì´ ëë‚¬ìŠµë‹ˆë‹¤.", "", gr.update(choices=[], value=None),
                    history, plan, None, gr.update(choices=history_labels(history), value=(history[-1]["id"] if history else None) if history else None))
        q_text = plan["question_bank"][plan["bank_cursor"]]
        plan["bank_cursor"] += 1

    elif mode == "í˜¼í•©í˜•(ì¶”ì²œ)":
        if not plan.get("outline"):
            plan["outline"] = make_outline(ctx, n=int(outline_k))
            plan["cursor"] = 0
        if plan["cursor"] >= len(plan["outline"]):
            return ("ì¤€ë¹„ëœ ì„¹ì…˜ì´ ëë‚¬ìŠµë‹ˆë‹¤.", "", gr.update(choices=[], value=None),
                    history, plan, None, gr.update(choices=history_labels(history), value=(history[-1]["id"] if history else None) if history else None))
        section = plan["outline"][plan["cursor"]]
        q_text = question_for_section(ctx, section, prev_qs, difficulty)
        plan["cursor"] += 1  # ìƒì„± í›„ ì¦ê°€

    else:  # ì˜¨ë””ë§¨ë“œ
        q_text = (generate_company_specific_questions(ctx, (research_ctx_state or ""), prev_qs, difficulty)
                  if use_research else generate_main_question_ondemand(ctx, prev_qs, difficulty))
        if isinstance(q_text, list):
            q_text = q_text[0] if q_text else "ì ì ˆí•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    qid = add_main_turn(history, plan, q_text)
    tts_path = tts_play(q_text, voice) if use_tts else None

    progress(1.0, desc="ì™„ë£Œ")
    return (f"{qid}. {q_text}", "", gr.update(choices=[], value=None),
            history, plan, tts_path, gr.update(choices=history_labels(history), value=qid))


def on_answer(ans_text, ans_audio, followup_mode, speak_fb, voice, history, plan):
    """
    - ìŒì„± íŒŒì¼(ans_audio)ì´ ìˆìœ¼ë©´ STTë¥¼ ìš°ì„  ì ìš©í•˜ì—¬ ì¸ì‹ í…ìŠ¤íŠ¸ë¥¼ answer_boxì—ë„ í‘œì‹œ.
    - ëª¨ë“  return íŠœí”Œ ë§ˆì§€ë§‰ í•­ëª©ìœ¼ë¡œ 'answer_boxì— ë„£ì„ í…ìŠ¤íŠ¸'ë¥¼ ì¶”ê°€í•˜ì—¬ UIë¥¼ ê°±ì‹ .
    """
    if not history:
        return (
            "ë¨¼ì € 'ì²« ì§ˆë¬¸ ìƒì„±'ì„ ëˆŒëŸ¬ ë©´ì ‘ì„ ì‹œì‘í•˜ì„¸ìš”.",
            "", gr.update(choices=[], value=None), history, plan, None,
            gr.update(choices=[], value=None),
            ans_text  # answer_box ê·¸ëŒ€ë¡œ ìœ ì§€
        )

    # ìš°ì„  í…ìŠ¤íŠ¸ ë°•ìŠ¤ ê°’
    a = (ans_text or "").strip()

    # ìŒì„±ì´ ìˆìœ¼ë©´ STTë¥¼ ìš°ì„  ì ìš©
    stt_text = ""
    if ans_audio:
        stt_text = stt_from_file(ans_audio) or ""
        if stt_text.strip():
            a = stt_text.strip()

    if not a:
        return (
            "ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.", "", gr.update(choices=[], value=None),
            history, plan, None,
            gr.update(choices=history_labels(history), value=(history[-1]["id"] if history else None)),
            stt_text or ans_text  # STT ì‹¤íŒ¨ë©´ ê¸°ì¡´ í…ìŠ¤íŠ¸ ìœ ì§€
        )

    # ê¸°ë¡/ë¶„ì„
    cur = history[-1]
    cur["a"] = a

    fb = analyze_answer_star_c(cur["q"], a)
    fus = generate_followups(cur["q"], a, mode=followup_mode)
    cur["feedback"] = fb
    cur["followups"] = fus

    tts_path = tts_play(fb, voice) if speak_fb else None

    return (
        fb, "\n".join(fus),
        gr.update(choices=fus, value=(fus[0] if fus else None)),
        history, plan, tts_path,
        gr.update(choices=history_labels(history), value=cur["id"]),
        a  # answer_boxì— í‘œì‹œí•  ìµœì¢… í…ìŠ¤íŠ¸(STT ê²°ê³¼ ë˜ëŠ” ì…ë ¥ í…ìŠ¤íŠ¸)
    )


def on_next_followup(selected_followup, use_tts, voice, history, plan):
    if not history:
        return "", "", gr.update(choices=[], value=None), history, plan, None, gr.update(choices=[], value=None)
    q = (selected_followup or "").strip()
    if not q:
        last = history[-1].get("followups", [])
        if not last:
            return "ë” ì´ìƒ ì´ì–´ê°ˆ ê¼¬ë¦¬ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.", "", gr.update(choices=[], value=None), history, plan, None, gr.update(choices=history_labels(history), value=history[-1]["id"])
        q = last[0]
    qid = add_follow_turn(history, plan, q)
    tts_path = tts_play(q, voice) if use_tts else None
    return (f"{qid}. {q}", "", gr.update(choices=[], value=None),
            history, plan, tts_path,
            gr.update(choices=history_labels(history), value=qid))


def on_next_main(jd_ctx, doc_ctx, research_ctx, research_bias, use_tts, voice, history, plan):
    plan = ensure_plan(plan)
    mode = plan.get("mode","ì˜¨ë””ë§¨ë“œ")
    difficulty = plan.get("difficulty","ë³´í†µ")

    base_context = join_texts("## [ê³µê³ /JD]\n"+(jd_ctx or ""), "## [ì§€ì›ì„œ]\n"+(doc_ctx or ""), limit=22000)
    full_context = join_texts(base_context, "## [ì§€ì›ì ë¦¬ì„œì¹˜]\n"+(research_ctx or ""), limit=24000)
    use_research = _use_research_ctx(research_bias, research_ctx)
    ctx = full_context if use_research else base_context
    prev_qs = [h["q"] for h in (history or [])]

    if mode == "í”„ë¦¬í”Œëœ":
        if plan.get("bank_cursor", 0) >= len(plan.get("question_bank", [])):
            return ("ì¤€ë¹„ëœ ì§ˆë¬¸ì´ ëë‚¬ìŠµë‹ˆë‹¤.", "", gr.update(choices=[], value=None),
                    history, plan, None, gr.update(choices=history_labels(history), value=(history[-1]["id"] if history else None) if history else None))
        q_text = plan["question_bank"][plan["bank_cursor"]]
        plan["bank_cursor"] += 1

    elif mode == "í˜¼í•©í˜•(ì¶”ì²œ)":
        if not plan.get("outline"):
            plan["outline"] = make_outline(ctx, n=5)
            plan["cursor"] = 0
        if plan["cursor"] >= len(plan["outline"]):
            return ("ì¤€ë¹„ëœ ì„¹ì…˜ì´ ëë‚¬ìŠµë‹ˆë‹¤.", "", gr.update(choices=[], value=None),
                    history, plan, None, gr.update(choices=history_labels(history), value=(history[-1]["id"] if history else None) if history else None))
        section = plan["outline"][plan["cursor"]]
        q_text = question_for_section(ctx, section, prev_qs, difficulty)
        plan["cursor"] += 1

    else:  # ì˜¨ë””ë§¨ë“œ
        q_text = (generate_company_specific_questions(ctx, (research_ctx or ""), prev_qs, difficulty)
                  if use_research else generate_main_question_ondemand(ctx, prev_qs, difficulty))
        if isinstance(q_text, list):
            q_text = q_text[0] if q_text else "ì ì ˆí•œ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    qid = add_main_turn(history, plan, q_text)
    tts_path = tts_play(q_text, voice) if use_tts else None
    return (f"{qid}. {q_text}", "", gr.update(choices=[], value=None),
            history, plan, tts_path,
            gr.update(choices=history_labels(history), value=qid))


def on_select_history(sel_id, history):
    if not sel_id or not history:
        return "", "", "", ""
    idx = next((i for i,h in enumerate(history) if h["id"]==sel_id), None)
    if idx is None: return "", "", "", ""
    t = history[idx]
    fus = "\n".join([f"- {x}" for x in t.get("followups", [])])
    view_q = f"{t['id']}. {t.get('q','')}"
    return view_q, t.get("a",""), t.get("feedback",""), fus


def on_finish(history, analysis_results=None):
    if not history and not analysis_results:
        return "ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œ ë¶„ì„/ë©´ì ‘ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”.", ""

    lines = [f"# ìµœì¢… ë¦¬í¬íŠ¸\n- ìƒì„± ì‹œê°: {_ts()}\n"]

    if analysis_results:
        lines.append("\n## ğŸ§  ë¬¸ì„œ ë¶„ì„ ê²°ê³¼\n")
        for key in ["ì‹¬ì¸µ ë¶„ì„", "êµì°¨ ë¶„ì„", "ì •í•©ì„± ì ê²€"]:
            val = (analysis_results or {}).get(key, "")
            if val and val.strip():
                lines.append(f"### {key}\n{val}\n")

    if history:
        lines.append(f"\n## ğŸ¤ ë©´ì ‘ ê¸°ë¡ (ì´ {len(history)}í„´)\n")
        for t in history:
            lines.append(f"### {t['id']}  {'(ë©”ì¸)' if t['type']=='main' else '(ê¼¬ë¦¬)'}\n{t['q']}\n")
            lines.append(f"- **ë‹µë³€**\n{t['a']}\n")
            lines.append(f"- **í”¼ë“œë°±(STAR+C)**\n{t['feedback']}\n")
            if t.get("followups"):
                lines.append("  - **í•´ë‹¹ í„´ì˜ ê¼¬ë¦¬ì§ˆë¬¸ í›„ë³´**\n" + "\n".join([f"    - {x}" for x in t['followups']]) + "\n")
            lines.append("---\n")

    content = "\n".join(lines)
    _ensure_dir(LOG_ROOT)
    path = os.path.join(LOG_ROOT, f"report_{int(time.time())}.md")
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return f"âœ… ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\nê²½ë¡œ: `{path}`", content


# -------- Gradio UI --------
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– í•œí ì¤€ë¹„: ë¬¸ì„œ ì ê²€ â†’ ë©´ì ‘ ì—°ìŠµ â†’ ìµœì¢… ë¦¬í¬íŠ¸")
    history_state   = gr.State(value=[])
    plan_state      = gr.State(value={})
    jd_ctx_state    = gr.State(value=""); jd_filemap_state = gr.State(value={})
    doc_ctx_state   = gr.State(value=""); doc_filemap_state = gr.State(value={})
    research_ctx_state = gr.State(value=""); research_filemap_state = gr.State(value={})
    analysis_results_state = gr.State(value={"ì‹¬ì¸µ ë¶„ì„":"", "êµì°¨ ë¶„ì„":"", "ì •í•©ì„± ì ê²€":""})

    with gr.Tabs():
        with gr.Tab("1) ë¬¸ì„œ ì ê²€"):
            with gr.Row():
                with gr.Column(scale=2):
                    jd_files = gr.File(label="ê³µê³ /JD ì—…ë¡œë“œ", file_count="multiple", type="filepath")
                    jd_paste = gr.Textbox(label="(ì„ íƒ) JD ë¶™ì—¬ë„£ê¸°", lines=5)
                    doc_files = gr.File(label="ì§€ì›ì„œ ì—…ë¡œë“œ", file_count="multiple", type="filepath")
                    doc_paste = gr.Textbox(label="(ì„ íƒ) ì§€ì›ì„œ ë¶™ì—¬ë„£ê¸°", lines=5)
                    research_files = gr.File(label="ë¦¬ì„œì¹˜ ì—…ë¡œë“œ", file_count="multiple", type="filepath")
                    research_paste = gr.Textbox(label="(ì„ íƒ) ë¦¬ì„œì¹˜ ë¶™ì—¬ë„£ê¸°", lines=5)
                    ingest_btn = gr.Button("â‘  ìë£Œ ë¶ˆëŸ¬ì˜¤ê¸° / íŒŒì‹±", variant="primary")
                with gr.Column(scale=1):
                    status_md = gr.Markdown("íŒŒì‹± ìƒíƒœê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
            gr.Markdown("---")
            gr.Markdown("### ë¬¸ì„œ ë¶„ì„ â€” ì¼ê´„ ì‹¤í–‰ & ë·°")
            doc_multi = gr.Dropdown(choices=[], value=[], multiselect=True, label="(ì„ íƒ) ëŒ€ìƒ ë¬¸ì„œ")
            run_all_btn = gr.Button("â‘¡ ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰", variant="primary")
            analysis_view = gr.Dropdown(choices=[], value=None, label="ë¶„ì„ ê²°ê³¼ ë³´ê¸°")
            analysis_md = gr.Markdown(label="ê²°ê³¼ ë³¸ë¬¸")

        with gr.Tab("2) ë©´ì ‘ ì—°ìŠµ"):
            with gr.Row():
                with gr.Column(scale=1):
                    mode_dd = gr.Dropdown(choices=["ì˜¨ë””ë§¨ë“œ","í”„ë¦¬í”Œëœ","í˜¼í•©í˜•(ì¶”ì²œ)"], value="í˜¼í•©í˜•(ì¶”ì²œ)", label="ì§ˆë¬¸ ëª¨ë“œ")
                    outline_k = gr.Slider(3, 8, value=5, step=1, label="ì„¹ì…˜/ë¬¸í•­ ìˆ˜(í˜¼í•©í˜•)")
                    difficulty_dd = gr.Dropdown(choices=["ì‰¬ì›€","ë³´í†µ","ì–´ë ¤ì›€"], value="ë³´í†µ", label="ë‚œì´ë„")
                    followup_mode = gr.Radio(choices=["evidence","why","how","risk"], value="evidence", label="ê¼¬ë¦¬ì§ˆë¬¸ ë°©í–¥")
                    use_tts = gr.Checkbox(label="ì§ˆë¬¸ TTS", value=False)
                    speak_feedback = gr.Checkbox(label="í”¼ë“œë°± TTS", value=False)
                    tts_voice = gr.Dropdown(choices=["ko-KR-HyunsuNeural","ko-KR-SunHiNeural","ko-KR-InJoonNeural"], value="ko-KR-HyunsuNeural", label="TTS ìŒì„±")
                    research_bias = gr.Checkbox(label="ë¦¬ì„œì¹˜ ë°˜ì˜", value=True)
                    start_btn = gr.Button("ì²« ì§ˆë¬¸ ìƒì„± â–¶", variant="primary")
                with gr.Column(scale=2):
                    question_box = gr.Textbox(label="í˜„ì¬ ì§ˆë¬¸(ë²ˆí˜¸ ìë™)", interactive=False, lines=3)
                    answer_box   = gr.Textbox(label="ë‚˜ì˜ ë‹µë³€ (í…ìŠ¤íŠ¸)", lines=5)
                    answer_audio = gr.Audio(sources=["microphone","upload"], type="filepath", label="ë˜ëŠ” ìŒì„±ìœ¼ë¡œ")
                    ans_btn      = gr.Button("ë‹µë³€ ì œì¶œ â†’ STARC + ê¼¬ë¦¬ì§ˆë¬¸", variant="primary")
            with gr.Row():
                with gr.Column(scale=2):
                    feedback_md  = gr.Markdown(label="STARC í”¼ë“œë°±")
                    followups_md = gr.Textbox(label="ê¼¬ë¦¬ì§ˆë¬¸(ëª©ë¡)", interactive=False, lines=3)
                    followup_sel = gr.Radio(choices=[], label="ì´ì–´ê°ˆ ê¼¬ë¦¬ì§ˆë¬¸ ì„ íƒ", interactive=True)
                    next_fu_btn   = gr.Button("ì„ íƒ ê¼¬ë¦¬ì§ˆë¬¸ìœ¼ë¡œ ì§„í–‰")
                with gr.Column(scale=1):
                    tts_q  = gr.Audio(label="ì§ˆë¬¸ ìŒì„±", interactive=False)
                    tts_fb = gr.Audio(label="í”¼ë“œë°± ìŒì„±", interactive=False)
                    next_main_btn = gr.Button("ìƒˆ ë©”ì¸ ì§ˆë¬¸ ì§„í–‰")

            gr.Markdown("---")
            history_dd = gr.Dropdown(choices=[], value=None, label="í„´ ì„ íƒ")
            view_q = gr.Textbox(label="ì§ˆë¬¸", interactive=False)
            view_a = gr.Textbox(label="ë‹µë³€", interactive=False)
            view_fb = gr.Textbox(label="í”¼ë“œë°±", interactive=False)
            view_fus = gr.Textbox(label="ê¼¬ë¦¬ì§ˆë¬¸ í›„ë³´", interactive=False)

        with gr.Tab("3) ìµœì¢… ë¦¬í¬íŠ¸"):
            finish_btn = gr.Button("ë¦¬í¬íŠ¸ ìƒì„±", variant="primary")
            finish_out_msg = gr.Markdown(label="ë¦¬í¬íŠ¸ ìƒì„± ê²°ê³¼")
            finish_out_md  = gr.Markdown(label="ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°")

    # Bindings
    ingest_btn.click(
        fn=on_ingest_inputs,
        inputs=[jd_files, jd_paste, doc_files, doc_paste, research_files, research_paste],
        outputs=[jd_ctx_state, jd_filemap_state, doc_ctx_state, doc_filemap_state, research_ctx_state, research_filemap_state,
                 status_md, doc_multi, doc_multi]
    )
    run_all_btn.click(
        fn=on_run_all_analyses,
        inputs=[doc_filemap_state, jd_ctx_state, research_ctx_state, doc_multi],
        outputs=[analysis_results_state, analysis_view, analysis_md]
    )
    analysis_view.change(
        fn=on_select_analysis_view,
        inputs=[analysis_results_state, analysis_view],
        outputs=[analysis_md]
    )
    start_btn.click(
        fn=on_start_interview,
        inputs=[mode_dd, outline_k, difficulty_dd, use_tts, tts_voice, research_bias,
                history_state, plan_state, jd_ctx_state, doc_ctx_state, research_ctx_state],
        outputs=[question_box, answer_box, followup_sel, history_state, plan_state, tts_q, history_dd]
    )
    ans_btn.click(
        fn=on_answer,
        inputs=[answer_box, answer_audio, followup_mode, speak_feedback, tts_voice, history_state, plan_state],
        # âœ… ë§ˆì§€ë§‰ì— answer_boxë¥¼ ì¶”ê°€ë¡œ ê°±ì‹ (ì´ 8ê°œ ì¶œë ¥)
        outputs=[feedback_md, followups_md, followup_sel, history_state, plan_state, tts_fb, history_dd, answer_box]
    )
    next_fu_btn.click(
        fn=on_next_followup,
        inputs=[followup_sel, use_tts, tts_voice, history_state, plan_state],
        outputs=[question_box, answer_box, followup_sel, history_state, plan_state, tts_q, history_dd]
    )
    # research_biasë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
    next_main_btn.click(
        fn=on_next_main,
        inputs=[jd_ctx_state, doc_ctx_state, research_ctx_state, research_bias, use_tts, tts_voice, history_state, plan_state],
        outputs=[question_box, answer_box, followup_sel, history_state, plan_state, tts_q, history_dd]
    )
    history_dd.change(
        fn=on_select_history,
        inputs=[history_dd, history_state],
        outputs=[view_q, view_a, view_fb, view_fus]
    )
    finish_btn.click(
        fn=on_finish,
        inputs=[history_state, analysis_results_state],
        outputs=[finish_out_msg, finish_out_md]
    )

if __name__ == "__main__":
    demo.launch()
