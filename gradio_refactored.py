# gradio_refactored.py
# REFACTORED VERSION

import os, time, json
from typing import List, Dict, Any
import gradio as gr

# ê³µìš©/ì…ìˆ˜
from ares.api.utils.common_utils import ts as _ts, ensure_dir as _ensure_dir, LOG_ROOT
from ares.api.utils.file_utils import collect_context, virtual_append, join_texts, auto_split_resume_cover
from ares.api.utils.state_utils import history_labels, ensure_plan, add_main_turn, add_follow_turn

# ğŸ”¹ NCS ìš”ì•½/ì»¨í…ìŠ¤íŠ¸
from ares.api.services.ncs_service import summarize_top_ncs
from ares.api.utils.search_utils import search_ncs_hybrid, format_ncs_context

# AI/ë©´ì ‘/ë¬¸ì„œë¶„ì„/ìŒì„±
from ares.api.services.interview_service import (
    make_outline, generate_main_question_ondemand, generate_followups, score_answer_starc, AIGenerationError
)
from ares.api.services.resume_service import (
    analyze_resume_or_cover, compare_documents, analyze_research_alignment
)
from ares.api.services.speech_service import stt_from_file, tts_play

# ğŸ”¹ ìˆ˜ë™ ë©”íƒ€ í—¬í¼
from ares.api.services.metadata_service import build_meta_from_inputs


# ====== ë³´ì¡° ìœ í‹¸ ====== 
def _format_starc_report(d: Dict[str, Any]) -> str:
    if not d: return "í‰ê°€ ìƒì„± ì‹¤íŒ¨"
    scores = d.get("scores", {})
    wt = d.get("weighted_total"); grade = d.get("grade")
    comments = d.get("comments", {}); summary = d.get("summary", [])
    lines = ["### STARC í‰ê°€ ìš”ì•½"]
    if scores:
        lines.append(f"- ì ìˆ˜: S={scores.get('S',0)}, T={scores.get('T',0)}, A={scores.get('A',0)}, R={scores.get('R',0)}, C={scores.get('C',0)}")
    if wt is not None: lines.append(f"- ê°€ì¤‘í•©: **{wt}**")
    if grade: lines.append(f"- ë“±ê¸‰: **{grade}**")
    if comments:
        lines.append("- ì½”ë©˜íŠ¸:")
        for k in ["S","T","A","R","C"]:
            if comments.get(k): lines.append(f"  - {k}: {comments[k]}")
    if summary: 
        lines.append("- ìš”ì•½:"); lines.extend(summary)
    return "\n".join(lines)

def _use_research_ctx(research_bias: bool, research_ctx: str) -> bool:
    return bool(research_bias and (research_ctx or "").strip())

def _apply_meta_resume(meta: Dict[str, Any] | None, func, *args, **kwargs):
    try:
        return func(*args, meta=meta, **kwargs)
    except TypeError: # êµ¬ë²„ì „ í˜¸í™˜
        return func(*args, **kwargs)
    except AIGenerationError as e:
        gr.Warning(f"AI ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return f"ì˜¤ë¥˜: {e}"

# ğŸ”¸ ë©”íƒ€ì—ì„œ NCS ê²€ìƒ‰ì–´ ë¹Œë“œ
def _ncs_query_from_meta(meta: Dict[str, Any] | None) -> str:
    if not meta: return ""
    role = (meta.get("role") or "").strip()
    skills = meta.get("skills") or []
    kpis = meta.get("jd_kpis") or []
    parts: List[str] = []
    if role: parts.append(role)
    if skills: parts.append(", ".join([s for s in skills if s]))
    if kpis: parts.append(", ".join([k for k in kpis if k]))
    q = ", ".join([p for p in parts if p]).strip()
    return q or "ì„¤ë¹„ ì •ë¹„, ì˜ˆë°©ë³´ì „, ì‚°ì—…ì•ˆì „"

def _build_ncs_report(meta: Dict[str, Any] | None, jd_ctx: str, top: int = 6) -> str:
    try:
        job_title = ((meta or {}).get("role") or "").strip() or "ì„¤ë¹„ ê´€ë¦¬"
        jd_snip = (jd_ctx or "")[:4000]

        agg = summarize_top_ncs(job_title, jd_snip, top=top) or []
        hits = search_ncs_hybrid(f"{job_title}\n{jd_snip}", top=top)
        ctx_lines = format_ncs_context(hits, max_len=1000)

        if not agg and not ctx_lines: return ""

        lines = [f"## ğŸ§© NCS ìš”ì•½ (Top {top})", f"- ì§ˆì˜: `{job_title}`", ""]
        for i, it in enumerate(agg, 1):
            title = (it.get("ability_name") or it.get("ability_code") or f"Ability-{i}")
            lines.append(f"**{i}. {title}**")
            els = it.get("elements") or []
            if els:
                lines.append("  - ìš”ì†Œ: " + ", ".join(els[:5]))
            samples = it.get("criteria_samples") or []
            for s in samples[:3]:
                lines.append(f"  - ê¸°ì¤€: {s}")

        if ctx_lines:
            lines.append("<details><summary>NCS ì»¨í…ìŠ¤íŠ¸(ì›ë¬¸ ì¼ë¶€)</summary>\n\n")
            lines.append(ctx_lines)
            lines.append("\n</details>\n")

        return "\n".join(lines).strip()
    except Exception as e:
        gr.Warning(f"NCS ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""


# ====== Handlers ====== 
# NOTE: ì•„ë˜ í•¸ë“¤ëŸ¬ë“¤ì˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì€ í–¥í›„ ë³„ë„ì˜ Service Layerë¡œ ë¶„ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
# =======================

def on_ingest_inputs(jd_files, jd_paste, doc_files, doc_paste, research_files, research_paste):
    progress = gr.Progress(track_tqdm=True)
    progress(0.05, desc="ìë£Œ íŒŒì‹±")

    jd_ctx, jd_map = collect_context(jd_files)
    if jd_paste and jd_paste.strip():
        virtual_append(jd_map, "JD(ë¶™ì—¬ë„£ê¸°).txt", jd_paste)
        jd_ctx = join_texts(jd_ctx, f"# [JD(ë¶™ì—¬ë„£ê¸°)]\n{jd_paste}")

    doc_ctx, doc_map = collect_context(doc_files)
    if doc_paste and doc_paste.strip():
        virtual_append(doc_map, "ì§€ì›ì„œ(ë¶™ì—¬ë„£ê¸°).txt", doc_paste)
        doc_ctx = join_texts(doc_ctx, f"# [ì§€ì›ì„œ(ë¶™ì—¬ë„£ê¸°)]\n{doc_paste}")

    exp = dict(doc_map)
    for name, text in list(doc_map.items()):
        if "ë¶™ì—¬ë„£ê¸°" in name: continue
        v = auto_split_resume_cover(name, text)
        if v and len(v) >= 2 and any(k != name for k in v.keys()): exp.update(v)
    doc_map = exp

    research_ctx, research_map = collect_context(research_files)
    if research_paste and research_paste.strip():
        virtual_append(research_map, "ë¦¬ì„œì¹˜(ë¶™ì—¬ë„£ê¸°).txt", research_paste)
        research_ctx = join_texts(research_ctx, f"# [ë¦¬ì„œì¹˜(ë¶™ì—¬ë„£ê¸°)]\n{research_paste}")

    progress(1.0, desc="ì™„ë£Œ")

    names = sorted(list(doc_map.keys()))
    status_msg = (
        f"âœ… íŒŒì‹± ì™„ë£Œ\n"
        f"- JD ë¬¸ì„œ: {len(jd_map)}ê°œ / ì§€ì›ì„œ ë¬¸ì„œ: {len(doc_map)}ê°œ / ë¦¬ì„œì¹˜ ë¬¸ì„œ: {len(research_map)}ê°œ\n"
        f"- ê°€ìƒë¬¸ì„œ ìë™ ìƒì„±: {'ìˆìŒ' if any('#' in n for n in names) else 'ì—†ìŒ'}"
    )
    return (
        jd_ctx, jd_map, doc_ctx, doc_map, research_ctx, research_map,
        status_msg,
        gr.update(choices=names), gr.update(choices=names, value=[])
    )

def on_confirm_meta_manual(company, division, role, location, kpi_csv, skills_csv):
    meta = build_meta_from_inputs(company, role, division, location, kpi_csv, skills_csv)
    if not meta:
        return None, "âš ï¸ íšŒì‚¬ëª…ê³¼ ì§ë¬´ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."
    return meta, "âœ… ë©”íƒ€ë°ì´í„°ë¥¼ ìˆ˜ë™ ì…ë ¥ìœ¼ë¡œ í™•ì •í–ˆìŠµë‹ˆë‹¤."

def on_run_all_analyses(doc_map: Dict[str,str], jd_ctx: str, research_ctx: str, doc_multi: List[str], meta: Dict[str,Any] | None):
    progress = gr.Progress()
    progress(0.05, desc="ë¶„ì„ ì¤€ë¹„")
    names_all = [n for n, v in doc_map.items() if (v or "").strip()]
    virtual_pref = [n for n in names_all if ("#ì´ë ¥ì„œ" in n or "#ìì†Œì„œ" in n)]
    targets = doc_multi if doc_multi else (virtual_pref if len(virtual_pref) >= 1 else names_all[:3])

    deep_results = []
    if targets:
        total = len(targets)
        for i, name in enumerate(targets, start=1):
            progress(0.05 + 0.4*(i/total), desc=f"ì‹¬ì¸µ ë¶„ì„â€¦ ({i}/{total})")
            txt = doc_map.get(name, "")
            if txt.strip():
                deep = _apply_meta_resume(meta, analyze_resume_or_cover, txt, jd_text=jd_ctx)
                deep_results.append(f"## [{name}] ì‹¬ì¸µ ë¶„ì„\n{deep}\n")
    deep_out = "\n\n".join(deep_results) if deep_results else "ë¶„ì„ ê°€ëŠ¥í•œ ì§€ì›ì„œ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."

    progress(0.6, desc="êµì°¨ ë¶„ì„")
    cmp_out = "êµì°¨ ë¶„ì„ì€ ìµœì†Œ 2ê°œ ë¬¸ì„œê°€ í•„ìš”í•©ë‹ˆë‹¤."
    if len(targets) >= 2:
        named = {n: (doc_map.get(n, "") or "") for n in targets}
        named = {k:v for k,v in named.items() if v.strip()}
        if len(named) >= 2:
            cmp_out = _apply_meta_resume(meta, compare_documents, named)

    progress(0.85, desc="ì •í•©ì„± ì ê²€")
    doc_concat = "\n\n".join([f"[{n}]\n{doc_map[n]}" for n in targets if (doc_map.get(n,"").strip())])[:16000]
    aln_out = "JD/ì§€ì›ì„œ/ë¦¬ì„œì¹˜ ì„¸ ê°€ì§€ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤."
    if (jd_ctx or "").strip() and doc_concat.strip() and (research_ctx or "").strip():
        aln_out = _apply_meta_resume(meta, analyze_research_alignment, jd_ctx, doc_concat)

    ncs_md = _build_ncs_report(meta, jd_ctx, top=6)

    progress(1.0, desc="ì™„ë£Œ")
    results = {"ì‹¬ì¸µ ë¶„ì„": deep_out, "êµì°¨ ë¶„ì„": cmp_out, "ì •í•©ì„± ì ê²€": aln_out}
    if ncs_md:
        results["NCS ìš”ì•½"] = ncs_md

    choices = [k for k,v in results.items() if (v or "").strip()]
    default_key = choices[0] if choices else "ì‹¬ì¸µ ë¶„ì„"
    return results, gr.update(choices=choices, value=default_key), results.get(default_key, "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

def on_select_analysis_view(results: Dict[str, str], selected_key: str):
    if not results: return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    if not selected_key:
        for v in results.values():
            if (v or "").strip(): return v
        return "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    return results.get(selected_key, "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

def on_start_interview(mode, outline_k, difficulty, use_tts, voice, research_bias,
                       history, plan, jd_ctx_state, doc_ctx_state, research_ctx_state, meta):
    try:
        progress = gr.Progress()
        progress(0.1, desc="ë©´ì ‘ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±")

        plan = ensure_plan(plan)
        plan["mode"] = mode; plan["difficulty"] = difficulty

        base_context = join_texts("## [ê³µê³ /JD]\n"+(jd_ctx_state or ""), "## [ì§€ì›ì„œ]\n"+(doc_ctx_state or ""), limit=22000)
        full_context = join_texts(base_context, "## [ì§€ì›ì ë¦¬ì„œì¹˜]\n"+(research_ctx_state or ""), limit=24000)
        ctx = full_context if _use_research_ctx(research_bias, research_ctx_state) else base_context

        ncs_query = _ncs_query_from_meta(meta)

        progress(0.6, desc="ì²« ì§ˆë¬¸ ìƒì„±")
        prev_qs = [h["q"] for h in (history or [])]
        q_text = ""

        if mode == "í”„ë¦¬í”Œëœ":
            if not plan.get("question_bank"):
                seed = generate_main_question_ondemand(ctx, [], difficulty, meta=meta, ncs_query=ncs_query)
                plan["question_bank"] = [seed] if isinstance(seed, str) else (seed or [])
                plan["bank_cursor"] = 0
            if plan["bank_cursor"] >= len(plan["question_bank"]):
                gr.Info("ì¤€ë¹„ëœ ì§ˆë¬¸ì´ ëë‚¬ìŠµë‹ˆë‹¤.")
                return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update())
            q_text = plan["question_bank"][plan["bank_cursor"]]; plan["bank_cursor"] += 1

        elif mode == "í˜¼í•©í˜•(ì¶”ì²œ)":
            if not plan.get("outline"):
                plan["outline"] = make_outline(ctx, n=int(outline_k), meta=meta, ncs_query=ncs_query)
                plan["cursor"] = 0
            if plan["cursor"] >= len(plan["outline"]):
                gr.Info("ì¤€ë¹„ëœ ì„¹ì…˜ì´ ëë‚¬ìŠµë‹ˆë‹¤.")
                return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update())
            section = plan["outline"][plan["cursor"]]
            ctx_with_section = join_texts(ctx, f"## [ì§„í–‰ ì„¹ì…˜]\n{section}", limit=24000)
            q_text = generate_main_question_ondemand(ctx_with_section, prev_qs, difficulty, meta=meta, ncs_query=ncs_query)
            plan["cursor"] += 1

        else:  # ì˜¨ë””ë§¨ë“œ
            q_text = generate_main_question_ondemand(ctx, prev_qs, difficulty, meta=meta, ncs_query=ncs_query)

        qid = add_main_turn(history, plan, q_text)
        tts_path = tts_play(q_text, voice) if use_tts else None

        progress(1.0, desc="ì™„ë£Œ")
        return (f"{qid}. {q_text}", "", gr.update(choices=[], value=None),
                history, plan, tts_path, gr.update(choices=history_labels(history), value=qid))

    except AIGenerationError as e:
        gr.Warning(f"AI ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update())

def on_answer(ans_text, ans_audio, speak_fb, voice, history, plan, meta):
    if not history:
        gr.Warning("ë¨¼ì € 'ì²« ì§ˆë¬¸ ìƒì„±'ì„ ëˆŒëŸ¬ ë©´ì ‘ì„ ì‹œì‘í•˜ì„¸ìš”.")
        return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update(), ans_text)

    a = (ans_text or "").strip()
    stt_text = ""
    if ans_audio:
        stt_text = stt_from_file(ans_audio) or ""
        if stt_text.strip(): a = stt_text.strip()
    if not a:
        gr.Warning("ë‹µë³€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update(), stt_text or ans_text)

    try:
        ncs_query = _ncs_query_from_meta(meta)
        cur = history[-1]; cur["a"] = a

        starc = score_answer_starc(cur["q"], a, meta=meta, ncs_query=ncs_query)
        fb_md = _format_starc_report(starc)
        fus = generate_followups(cur["q"], a, k=3, main_index=cur["id"], meta=meta, ncs_query=ncs_query)

        cur["feedback"] = fb_md
        cur["followups"] = fus

        tts_path = tts_play(fb_md, voice) if speak_fb else None

        return (fb_md, "\n".join(fus), 
                gr.update(choices=fus, value=(fus[0] if fus else None)), 
                history, plan, tts_path,
                gr.update(choices=history_labels(history), value=cur["id"]),
                a)
    except AIGenerationError as e:
        gr.Warning(f"AI ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update(), a)

def on_next_followup(selected_followup, use_tts, voice, history, plan):
    if not history:
        return "", "", gr.update(choices=[], value=None), history, plan, None, gr.update(choices=[], value=None)
    q = (selected_followup or "").strip()
    if not q:
        last = history[-1].get("followups", [])
        if not last:
            gr.Info("ë” ì´ìƒ ì´ì–´ê°ˆ ê¼¬ë¦¬ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return gr.update(), gr.update(), gr.update(), history, plan, None, gr.update()
        q = last[0]
    
    qid = add_follow_turn(history, plan, q)
    tts_path = tts_play(q, voice) if use_tts else None
    return (f"{qid}. {q}", "", gr.update(choices=[], value=None),
            history, plan, tts_path,
            gr.update(choices=history_labels(history), value=qid))

def on_next_main(jd_ctx, doc_ctx, research_ctx, research_bias, use_tts, voice, history, plan, meta):
    try:
        plan = ensure_plan(plan)
        mode = plan.get("mode","ì˜¨ë””ë§¨ë“œ"); difficulty = plan.get("difficulty","ë³´í†µ")

        base_context = join_texts("## [ê³µê³ /JD]\n"+(jd_ctx or ""), "## [ì§€ì›ì„œ]\n"+(doc_ctx or ""), limit=22000)
        full_context = join_texts(base_context, "## [ì§€ì›ì ë¦¬ì„œì¹˜]\n"+(research_ctx or ""), limit=24000)
        ctx = full_context if _use_research_ctx(research_bias, research_ctx) else base_context
        prev_qs = [h["q"] for h in (history or [])]
        ncs_query = _ncs_query_from_meta(meta)
        q_text = ""

        if mode == "í”„ë¦¬í”Œëœ":
            if plan.get("bank_cursor", 0) >= len(plan.get("question_bank", [])):
                gr.Info("ì¤€ë¹„ëœ ì§ˆë¬¸ì´ ëë‚¬ìŠµë‹ˆë‹¤.")
                return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update())
            q_text = plan["question_bank"][plan["bank_cursor"]]; plan["bank_cursor"] += 1
        elif mode == "í˜¼í•©í˜•(ì¶”ì²œ)":
            if not plan.get("outline"):
                plan["outline"] = make_outline(ctx, n=5, meta=meta, ncs_query=ncs_query)
                plan["cursor"] = 0
            if plan["cursor"] >= len(plan["outline"]):
                gr.Info("ì¤€ë¹„ëœ ì„¹ì…˜ì´ ëë‚¬ìŠµë‹ˆë‹¤.")
                return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update())
            section = plan["outline"][plan["cursor"]]
            ctx_with_section = join_texts(ctx, f"## [ì§„í–‰ ì„¹ì…˜]\n{section}", limit=24000)
            q_text = generate_main_question_ondemand(ctx_with_section, prev_qs, difficulty, meta=meta, ncs_query=ncs_query)
            plan["cursor"] += 1
        else:
            q_text = generate_main_question_ondemand(ctx, prev_qs, difficulty, meta=meta, ncs_query=ncs_query)

        qid = add_main_turn(history, plan, q_text)
        tts_path = tts_play(q_text, voice) if use_tts else None
        return (f"{qid}. {q_text}", "", gr.update(choices=[], value=None),
                history, plan, tts_path,
                gr.update(choices=history_labels(history), value=qid))
    except AIGenerationError as e:
        gr.Warning(f"AI ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return (gr.update(), gr.update(), gr.update(), history, plan, None, gr.update())

def on_select_history(sel_id, history):
    if not sel_id or not history: return "", "", "", ""
    idx = next((i for i,h in enumerate(history) if h["id"]==sel_id), None)
    if idx is None: return "", "", "", ""
    t = history[idx]
    fus = "\n".join([f"- {x}" for x in t.get("followups", [])])
    view_q = f"{t['id']}. {t.get('q','')}"
    return view_q, t.get("a",""), t.get("feedback",""), fus

def on_finish(history, analysis_results=None):
    if not history and not analysis_results:
        return "ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¬¸ì„œ ë¶„ì„/ë©´ì ‘ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”.", ""
    lines = [f"# ìµœì¢… ë¦¬í¬íŠ¸\n- ìƒì„± ì‹œê°: {_ts()}\n"]
    if analysis_results:
        lines.append("\n## ğŸ§  ë¬¸ì„œ ë¶„ì„ ê²°ê³¼\n")
        for key, val in (analysis_results or {}).items():
            if val and str(val).strip():
                lines.append(f"### {key}\n{val}\n")
    if history:
        lines.append(f"\n## ğŸ¤ ë©´ì ‘ ê¸°ë¡ (ì´ {len(history)}í„´)\n")
        for t in history:
            lines.append(f"### {t['id']}  {'ë©”ì¸' if t['type']=='main' else 'ê¼¬ë¦¬'}\n{t['q']}\n")
            lines.append(f"- **ë‹µë³€**\n{t.get('a','')}\n")
            lines.append(f"- **í”¼ë“œë°±(STAR+C)**\n{t.get('feedback','')}\n")
            if t.get("followups"):
                lines.append("  - **í•´ë‹¹ í„´ì˜ ê¼¬ë¦¬ì§ˆë¬¸ í›„ë³´**\n" + "\n".join([f"    - {x}" for x in t['followups']]) + "\n")
            lines.append("---\n")
    content = "\n".join(lines)
    _ensure_dir(LOG_ROOT)
    path = os.path.join(LOG_ROOT, f"report_{int(time.time())}.md")
    with open(path, "w", encoding="utf-8") as f:
        f.write(content)
    return f"âœ… ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\nê²½ë¡œ: `{path}`", content


# ====== Gradio UI ====== 
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– í•œí ì¤€ë¹„: ë¬¸ì„œ ì ê²€ â†’ ë©´ì ‘ ì—°ìŠµ â†’ ìµœì¢… ë¦¬í¬íŠ¸")
    history_state   = gr.State(value=[])
    plan_state      = gr.State(value={})
    jd_ctx_state    = gr.State(value=""); jd_filemap_state = gr.State(value={})
    doc_ctx_state   = gr.State(value=""); doc_filemap_state = gr.State(value={})
    research_ctx_state = gr.State(value=""); research_filemap_state = gr.State(value={})
    analysis_results_state = gr.State(value={"ì‹¬ì¸µ ë¶„ì„":"", "êµì°¨ ë¶„ì„":"", "ì •í•©ì„± ì ê²€":"", "NCS ìš”ì•½": ""})
    meta_state = gr.State(value=None)

    with gr.Tabs():
        with gr.Tab("1) ë¬¸ì„œ ì ê²€"):
            with gr.Row():
                with gr.Column(scale=2):
                    jd_files = gr.File(label="ê³µê³ /JD ì—…ë¡œë“œ", file_count="multiple", type="filepath")
                    jd_paste = gr.Textbox(label="(ì„ íƒ) JD ë¶™ì—¬ë„£ê¸°", lines=5)
                    doc_files = gr.File(label="ì§€ì›ì„œ ì—…ë¡œë“œ", file_count="multiple", type="filepath")
                    doc_paste = gr.Textbox(label="(ì„ íƒ) ì§€ì›ì„œ ë¶™ì—¬ë„£ê¸°", lines=5)
                    research_files = gr.File(label="ë¦¬ì„œì¹˜ ì—…ë¡œë“œ", file_count="multiple", type="filepath")
                    research_paste = gr.Textbox(label="(ì„ íƒ) ë¦¬ì„œì¹˜ ë¶™ì—¬ë„£ê¸°", lines=5)
                    ingest_btn = gr.Button("â‘  ìë£Œ ë¶ˆëŸ¬ì˜¤ê¸° / íŒŒì‹±", variant="primary")
                with gr.Column(scale=1):
                    status_md = gr.Markdown("íŒŒì‹± ìƒíƒœê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
            gr.Markdown("---")
            with gr.Row():
                with gr.Column(scale=2):
                    gr.Markdown("### ë¬¸ì„œ ë¶„ì„ â€” ì¼ê´„ ì‹¤í–‰ & ë·°")
                    doc_multi = gr.Dropdown(choices=[], value=[], multiselect=True, label="(ì„ íƒ) ëŒ€ìƒ ë¬¸ì„œ")
                    run_all_btn = gr.Button("â‘¡ ë¬¸ì„œ ë¶„ì„ ì‹¤í–‰", variant="primary")
                    analysis_view = gr.Dropdown(choices=[], value=None, label="ë¶„ì„ ê²°ê³¼ ë³´ê¸°")
                    analysis_md = gr.Markdown(label="ê²°ê³¼ ë³¸ë¬¸")
                with gr.Column(scale=1):
                    gr.Markdown("### íšŒì‚¬/ì§ë¬´ ë©”íƒ€ë°ì´í„° (ì§ì ‘ ì…ë ¥)")
                    company_tb  = gr.Textbox(label="íšŒì‚¬ëª… *", placeholder="ì˜ˆ) ì‚¼ì„±ì „ì", lines=1)
                    division_tb = gr.Textbox(label="ë¶€ì„œ/ë³¸ë¶€ (ì„ íƒ)", placeholder="ì˜ˆ) DSë¶€ë¬¸ ë©”ëª¨ë¦¬ì‚¬ì—…ë¶€", lines=1)
                    role_tb     = gr.Textbox(label="ì§ë¬´ *", placeholder="ì˜ˆ) ì„¤ë¹„ ìœ ì§€ë³´ìˆ˜", lines=1)
                    location_tb = gr.Textbox(label="ê·¼ë¬´ì§€ (ì„ íƒ)", placeholder="ì˜ˆ) í™”ì„±/í‰íƒ", lines=1)
                    kpi_tb      = gr.Textbox(label="í•µì‹¬ KPI (ì‰¼í‘œ êµ¬ë¶„, ì„ íƒ)", placeholder="ì˜ˆ) OEE, MTBF, MTTR", lines=1)
                    skills_tb   = gr.Textbox(label="ì£¼ìš” ìŠ¤í‚¬ (ì‰¼í‘œ êµ¬ë¶„, ì„ íƒ)", placeholder="ì˜ˆ) TPM, FDC, ì˜ˆì§€ë³´ì „", lines=1)
                    confirm_meta_btn = gr.Button("ë©”íƒ€ í™•ì •", variant="secondary")
                    meta_status_md = gr.Markdown("ë©”íƒ€ ìƒíƒœ: ì•„ì§ í™•ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        with gr.Tab("2) ë©´ì ‘ ì—°ìŠµ"):
            with gr.Row():
                with gr.Column(scale=1):
                    mode_dd = gr.Dropdown(choices=["ì˜¨ë””ë§¨ë“œ","í”„ë¦¬í”Œëœ","í˜¼í•©í˜•(ì¶”ì²œ)"], value="í˜¼í•©í˜•(ì¶”ì²œ)", label="ì§ˆë¬¸ ëª¨ë“œ")
                    outline_k = gr.Slider(3, 8, value=5, step=1, label="ì„¹ì…˜/ë¬¸í•­ ìˆ˜(í˜¼í•©í˜•)")
                    difficulty_dd = gr.Dropdown(choices=["ì‰¬ì›€","ë³´í†µ","ì–´ë ¤ì›€"], value="ë³´í†µ", label="ë‚œì´ë„")
                    use_tts = gr.Checkbox(label="ì§ˆë¬¸ TTS", value=False)
                    speak_feedback = gr.Checkbox(label="í”¼ë“œë°± TTS", value=False)
                    tts_voice = gr.Dropdown(choices=["ko-KR-HyunsuNeural","ko-KR-SunHiNeural","ko-KR-InJoonNeural"], value="ko-KR-HyunsuNeural", label="TTS ìŒì„±")
                    research_bias = gr.Checkbox(label="ë¦¬ì„œì¹˜ ë°˜ì˜", value=True)
                    start_btn = gr.Button("ì²« ì§ˆë¬¸ ìƒì„± â–¶", variant="primary")
                with gr.Column(scale=2):
                    question_box = gr.Textbox(label="í˜„ì¬ ì§ˆë¬¸(ë²ˆí˜¸ ìë™)", interactive=False, lines=3)
                    answer_box   = gr.Textbox(label="ë‚˜ì˜ ë‹µë³€ (í…ìŠ¤íŠ¸)", lines=5)
                    answer_audio = gr.Audio(sources=["microphone","upload"], type="filepath", label="ë˜ëŠ” ìŒì„±ìœ¼ë¡œ")
                    ans_btn      = gr.Button("ë‹µë³€ ì œì¶œ â†’ STARC + ê¼¬ë¦¬ì§ˆë¬¸", variant="primary")
            with gr.Row():
                with gr.Column(scale=2):
                    feedback_md  = gr.Markdown(label="STARC í”¼ë“œë°±")
                    followups_md = gr.Textbox(label="ê¼¬ë¦¬ì§ˆë¬¸(ëª©ë¡)", interactive=False, lines=3)
                    followup_sel = gr.Radio(choices=[], label="ì´ì–´ê°ˆ ê¼¬ë¦¬ì§ˆë¬¸ ì„ íƒ", interactive=True)
                    next_fu_btn   = gr.Button("ì„ íƒ ê¼¬ë¦¬ì§ˆë¬¸ìœ¼ë¡œ ì§„í–‰")
                with gr.Column(scale=1):
                    tts_q  = gr.Audio(label="ì§ˆë¬¸ ìŒì„±", interactive=False)
                    tts_fb = gr.Audio(label="í”¼ë“œë°± ìŒì„±", interactive=False)
                    next_main_btn = gr.Button("ìƒˆ ë©”ì¸ ì§ˆë¬¸ ì§„í–‰")

            gr.Markdown("---")
            history_dd = gr.Dropdown(choices=[], value=None, label="í„´ ì„ íƒ")
            view_q = gr.Textbox(label="ì§ˆë¬¸", interactive=False)
            view_a = gr.Textbox(label="ë‹µë³€", interactive=False)
            view_fb = gr.Textbox(label="í”¼ë“œë°±", interactive=False)
            view_fus = gr.Textbox(label="ê¼¬ë¦¬ì§ˆë¬¸ í›„ë³´", interactive=False)

        with gr.Tab("3) ìµœì¢… ë¦¬í¬íŠ¸"):
            finish_btn = gr.Button("ë¦¬í¬íŠ¸ ìƒì„±", variant="primary")
            finish_out_msg = gr.Markdown(label="ë¦¬í¬íŠ¸ ìƒì„± ê²°ê³¼")
            finish_out_md  = gr.Markdown(label="ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°")

    # Bindings
    ingest_btn.click(
        fn=on_ingest_inputs,
        inputs=[jd_files, jd_paste, doc_files, doc_paste, research_files, research_paste],
        outputs=[jd_ctx_state, jd_filemap_state, doc_ctx_state, doc_filemap_state, research_ctx_state, research_filemap_state,
                 status_md, doc_multi, doc_multi]
    )
    confirm_meta_btn.click(
        fn=on_confirm_meta_manual,
        inputs=[company_tb, division_tb, role_tb, location_tb, kpi_tb, skills_tb],
        outputs=[meta_state, meta_status_md]
    )
    run_all_btn.click(
        fn=on_run_all_analyses,
        inputs=[doc_filemap_state, jd_ctx_state, research_ctx_state, doc_multi, meta_state],
        outputs=[analysis_results_state, analysis_view, analysis_md]
    )
    analysis_view.change(
        fn=on_select_analysis_view,
        inputs=[analysis_results_state, analysis_view],
        outputs=[analysis_md]
    )
    start_btn.click(
        fn=on_start_interview,
        inputs=[mode_dd, outline_k, difficulty_dd, use_tts, tts_voice, research_bias,
                history_state, plan_state, jd_ctx_state, doc_ctx_state, research_ctx_state, meta_state],
        outputs=[question_box, answer_box, followup_sel, history_state, plan_state, tts_q, history_dd]
    )
    ans_btn.click(
        fn=on_answer,
        inputs=[answer_box, answer_audio, speak_feedback, tts_voice, history_state, plan_state, meta_state],
        outputs=[feedback_md, followups_md, followup_sel, history_state, plan_state, tts_fb, history_dd, answer_box]
    )
    next_fu_btn.click(
        fn=on_next_followup,
        inputs=[followup_sel, use_tts, tts_voice, history_state, plan_state],
        outputs=[question_box, answer_box, followup_sel, history_state, plan_state, tts_q, history_dd]
    )
    next_main_btn.click(
        fn=on_next_main,
        inputs=[jd_ctx_state, doc_ctx_state, research_ctx_state, research_bias, use_tts, tts_voice, history_state, plan_state, meta_state],
        outputs=[question_box, answer_box, followup_sel, history_state, plan_state, tts_q, history_dd]
    )
    history_dd.change(
        fn=on_select_history,
        inputs=[history_dd, history_state],
        outputs=[view_q, view_a, view_fb, view_fus]
    )
    finish_btn.click(
        fn=on_finish,
        inputs=[history_state, analysis_results_state],
        outputs=[finish_out_msg, finish_out_md]
    )

if __name__ == "__main__":
    # Gradio ì„œë²„ ì‹¤í–‰
    share = os.environ.get("GRADIO_SHARE", "0") == "1"
    demo.launch(share=share)
